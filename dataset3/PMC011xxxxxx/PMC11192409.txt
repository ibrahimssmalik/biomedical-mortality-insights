
==== Front
PLoS One
PLoS One
plos
PLOS ONE
1932-6203
Public Library of Science San Francisco, CA USA

PONE-D-23-33769
10.1371/journal.pone.0300056
Research Article
Biology and Life Sciences
Agriculture
Crop Science
Crops
Biology and Life Sciences
Cell Biology
Cellular Structures and Organelles
Chloroplasts
Chlorophyll
Biology and Life Sciences
Cell Biology
Plant Cell Biology
Chloroplasts
Chlorophyll
Biology and Life Sciences
Plant Science
Plant Cell Biology
Chloroplasts
Chlorophyll
Biology and Life Sciences
Cell Biology
Cellular Types
Plant Cells
Chloroplasts
Chlorophyll
Biology and Life Sciences
Cell Biology
Plant Cell Biology
Plant Cells
Chloroplasts
Chlorophyll
Biology and Life Sciences
Plant Science
Plant Cell Biology
Plant Cells
Chloroplasts
Chlorophyll
Physical Sciences
Materials Science
Materials
Pigments
Organic Pigments
Chlorophyll
Biology and Life Sciences
Plant Science
Plant Anatomy
Leaves
Biology and Life Sciences
Physiology
Plant Physiology
Plant Defenses
Plant Resistance to Abiotic Stress
Drought Adaptation
Biology and Life Sciences
Plant Science
Plant Physiology
Plant Defenses
Plant Resistance to Abiotic Stress
Drought Adaptation
Biology and Life Sciences
Plant Science
Plant Pathology
Plant Resistance to Abiotic Stress
Drought Adaptation
Biology and Life Sciences
Ecology
Plant Ecology
Plant-Environment Interactions
Plant Resistance to Abiotic Stress
Drought Adaptation
Ecology and Environmental Sciences
Ecology
Plant Ecology
Plant-Environment Interactions
Plant Resistance to Abiotic Stress
Drought Adaptation
Biology and Life Sciences
Plant Science
Plant Ecology
Plant-Environment Interactions
Plant Resistance to Abiotic Stress
Drought Adaptation
Computer and Information Sciences
Artificial Intelligence
Machine Learning
Support Vector Machines
Physical Sciences
Mathematics
Applied Mathematics
Algorithms
Machine Learning Algorithms
Research and Analysis Methods
Simulation and Modeling
Algorithms
Machine Learning Algorithms
Computer and Information Sciences
Artificial Intelligence
Machine Learning
Machine Learning Algorithms
Engineering and Technology
Remote Sensing
Computer and Information Sciences
Artificial Intelligence
Machine Learning
Remote sensing estimation of sugar beet SPAD based on un-manned aerial vehicle multispectral imagery
Remote sensing estimation of sugar beet SPAD based on UAV multispectral imagery
Gao Weishi Conceptualization Project administration Resources Writing – original draft Writing – review & editing 1
Zeng WanYing Formal analysis Writing – original draft Writing – review & editing 2
https://orcid.org/0009-0009-1434-8925
Li Sizhong Formal analysis Writing – original draft Writing – review & editing 1 *
Zhang Liming Conceptualization Project administration Resources Supervision Writing – original draft Writing – review & editing 1
Wang Wei Data curation Investigation Methodology 3
https://orcid.org/0000-0002-2812-0747
Song Jikun Data curation Investigation Methodology 4
Wu Hao Data curation Investigation Methodology 3
1 Institute of Economic Crops, Xinjiang Academy of Agricultural Sciences, Urumqi, China
2 College of Agronomy, Xinjiang Agricultural University, Urumqi, China
3 Anyang Institute of Technology, AnYang, China
4 Cotton Research Institute, Chinese Academy of Agricultural Sciences, AnYang, China
Ali Habib Editor
Khwaja Fareed University of Engineering & Information Technology, PAKISTAN
Competing Interests: The authors have declared that no competing interests exist.

* E-mail: xjnkylsz@163.com
2024
21 6 2024
19 6 e030005616 10 2023
21 2 2024
© 2024 Gao et al
2024
Gao et al
https://creativecommons.org/licenses/by/4.0/ This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.

Accurate, non-destructive and cost-effective estimation of crop canopy Soil Plant Analysis De-velopment(SPAD) is crucial for precision agriculture and cultivation management. Unmanned aerial vehicle (UAV) platforms have shown tremendous potential in predicting crop canopy SPAD. This was because they can rapidly and accurately acquire remote sensing spectral data of the crop canopy in real-time. In this study, a UAV equipped with a five-channel multispectral camera (Blue, Green, Red, Red_edge, Nir) was used to acquire multispectral images of sugar beets. These images were then combined with five machine learning models, namely K-Nearest Neighbor, Lasso, Random Forest, RidgeCV and Support Vector Machine (SVM), as well as ground measurement data to predict the canopy SPAD of sugar beets. The results showed that under both normal irrigation and drought stress conditions, the SPAD values in the normal ir-rigation treatment were higher than those in the water-limited treatment. Multiple vegetation indices showed a significant correlation with SPAD, with the highest correlation coefficient reaching 0.60. Among the SPAD prediction models, different models showed high estimation accuracy under both normal irrigation and water-limited conditions. The SVM model demon-strated a good performance with a correlation coefficient (R2) of 0.635, root mean square error (Rmse) of 2.13, and relative error (Re) of 0.80% for the prediction and testing values under normal irrigation. Similarly, for the prediction and testing values under drought stress, the SVM model exhibited a correlation coefficient (R2) of 0.609, root mean square error (Rmse) of 2.71, and rela-tive error (Re) of 0.10%. Overall, the SVM model showed good accuracy and stability in the pre-diction model, greatly facilitating high-throughput phenotyping research of sugar beet canopy SPAD.

Key Research and development task 2022B02002 Gao Weishi National Sugar Industry Technology System Project CARS-170108 Gao Weishi Henan Provincial Science and Technology Tackling Project 232102111132 Wang Wei This research was funded by Key Research and development task special project of Xin-jiang(2022B02002); National Sugar Industry Technology System Project (CARS-170108); Henan Provincial Science and Technology Tackling Project(232102111132). Data AvailabilityAll relevant data are within the paper and its Supporting information files.
Data Availability

All relevant data are within the paper and its Supporting information files.
==== Body
pmc1 Introduction

As one of the important sugar crops in China, sugar beet belonged to Amaranthaceae family and genus Beta [1], which was a biennial herb that undergoes nutritive growth in the first year and reproductive growth in the second year after vernalisation. The rapid growth period of leaf tufts of sugar beet was from the beginning of the shedding of the root primordial cortex to the time when the daily growth of leaf tufts reaches the highest value, and the chlorophyll in this period provides abundant nutrients for sugar metabolism in the later underground part, and also photosynthesis reaches the highest level [2]. Chloro-phyll content is a highly significant indicator for photosynthesis and growth development in crops. It is a crucial pigment present in the chloroplasts of green plants and plays a major role in capturing energy during photosynthesis [3]. Its content was an important in-dicator of plant nutrient stress, nitrogen status, growth senescence and other stages, which is important for dynamic monitoring of vegetation growth and rapid diagnosis of fertiliser application. SPAD can directly reflect the relative content of chlorophyll in the leaves [4, 5]. Therefore, the study of SPAD content of sugar beet is of great significance for the growth of sugar beet. UAV remote sensing provides a new solution for the canopy traits of crops [6] and this study focuses with the SPAD prediction of sugar beet based on multispectral im-ages from UAV remote sensing [7].

In recent years, with the rapid development of multi-source sensors, big data and ar-tificial intelligence technologies, UAV remote sensing of agriculture has been developing rapidly in both breadth and depth [8, 9]. Compared with traditional orbital and satellite remote sensing, drones are more convenient and flexible, and because of the relatively economic cost, they have become the favoured object in the majority of research [10, 11]. In addition, the sensors carried by UAVs are also very diverse, such as infrared sensors, hy-perspectral sensors, multispectral sensors, etc [12, 13]. Due to the long processing time of multispectral and scientific research to achieve high-throughput phenotypic prediction, it has become a hotspot for large-scale crop canopy trait research. At present, many re-searchers use hyperspectral for the estimation of vegetation chlorophyll content has been a large number of studies. Hunt et al [14] constructed the vegetation index GNDVI through the multispectral images obtained by UAV, and inverted the leaf area index of wheat through the vegetation index. Wang et al [15] constructed the SPAD inversion model of wheat through the selection of the contribution rate of the vegetation index by the use of UAV. Bendig et al. [16]and Yang et al. [17] predicted the biomass of crops by UAV and ob-tained better results.

The integration of low-altitude UAV remote sensing and ground-based measure-ments for modeling crop canopy traits has been a smart application of UAV remote sens-ing in precision agriculture [18, 19]. Machine learning, which is one of the earliest disci-plines in artificial intelligence focusing on numerical computation, allows for predicting unknown data based on established models and input parameters [20, 21]. Machine learning algorithms exhibit robustness and demonstrate high predictive capability not only in structured data with strong phenotypic patterns but also in unstructured and non-linear domains [22, 23]. For instance, typical machine learning models such as Sup-port Vector Machines, Ridge Regression, Naive Bayes algorithm, and Decision Tree mod-els have shown significant advantages in agricultural remote sensing [24, 25].

Due to the powerful predictive ability of machine learning and the high throughput of UAV remote sensing in crop phenotyping, UAV remote sensing combined with ma-chine learning provides a good opportunity for research on crop canopy traits. Currently, there are few reports on the inversion of the canopy SPAD model based on sugar beets. In this study, we combined the UAV multispectral imagery with the extraction of sin-gle-band reflectance, and then constructed the vegetation index by combining with the vegetation index model, which provides a high correlation between the vegetation index and the SPAD to determine the parameters for inversion models and thus make predic-tions of the inversion model, with a view to achieving the intelligent monitoring of sugar beets.

2 Materials and methods

2.1 Experimental materials and design

The experiment was conducted in the sugar beet scale planting area of Manas Ex-perimental Station(86¡ã12’52.2”N, 44¡ã18’15.77”E) of Xinjiang Academy of Agricultural Sci-ences, Xinjiang Changji Hui Autonomous Prefecture, Xinjiang, and 300 copies of domestic and foreign staple varieties were selected as the participating materials, which were planted in the morning of April 27, 2022. The Manas area has a mid-temperate continental arid-semi-arid climate, with severe cold winters, hot summers, dryness and little rainfall, abundant sunshine, high evapotranspiration, and low precipitation. In this study, two ir-rigation water treatments were set up: normal irrigation (NI) and drought stress (DS), 600 plots were selected for each irrigation treatment, and one variety was planted in each plot in a completely randomised block design with two replications, 3 row zones, 2 m row length and 20 cm row spacing, and drought stress was the water-control management for the reproductive period of the sugar beet. The field management was in accordance with the local conventional cultivation management, and the beets could grow normally and well in the field, and the fertilisation, drip irrigation, pest control and weeding were the same as the local field management.

2.2 Drone platforms and flight settings

The UAV used in this study is the DJI Genie 4 Multispectral Edition UAV P4M, which integrates one visible sensor channel and five multispectral sensor channels with five bands of multispectral channels centred on wavelengths of 450 nm (Blue), 560 nm (Green), 650 nm (Red), 730 nm (Red_edge), 840 nm (Nir). Each shot can obtain 6 images and each image has a resolution of more than 2 million pixels. At the same time, the UAV is equipped with TimeSync time synchronisation system, which can obtain centimetre-level positioning accuracy. In addition, the integrated light intensity sensor on the top of the P4M can capture solar irradiance data for image light compensation, eliminating the in-terference of ambient light on the data to improve the accuracy and consistency of the data collected in different time periods. The data can be collected at different times of the day to improve accuracy and consistency. During the multispectral image acquisition process, a clear and windless midday weather is selected, the UAV flies autonomously according to the set route and records the images, the multispectral camera lens is vertically downward, and the flight parameters are shown in Table 1.

10.1371/journal.pone.0300056.t001 Table 1 Parameters of UAV multispectral image acquisition.

Parameter	Parameter values	
Flight altitude	12m	
Flight Speed	5.4km/h	
Course overlap ratio	75%	
Lateral overlap rate	75%	
Spectral type	Blue, Green, Red, Red_edge, Nir	

2.3 Data collection plan

The data collection consisted of SPAD of sugar beet canopy and UAV multispectral image data. The SPAD and UAV multispectral image data of sugar beet were collected on 18th June 2022, which is the rapid growth period of leaf clusters of sugar beet. And all da-ta in the collection plan included two different water treatments (normal irrigation and drought stress).

2.4 Determination of chlorophyll content

The correlation coefficient between SPAD value and chlorophyll content of sugar beet leaves was significant, which can reflect the high and low levels of chlorophyll content of the crop. The measurement period was the rapid growth period of leaf tufts during the important reproductive period of sugar beet. The relative chlorophyll content of different genotypes was measured simultaneously on the day of the UAV flights by taking five uniformly growing sugar beets from each variety and measuring them using the SPAD-502 Plus chlorophyll meter, which is manufactured by Minolta Camera Company, Japan, and which has been used by many scholars to obtain SPAD data for crops [26, 27]. Measurements were made and SPAD values were recorded at the top, middle and bottom of the canopy of selected beets in the experimental field, and the average of the chlorophyll contents of the three parts of the plant was taken as the canopy SPAD value of the plant, and then the average of the SPAD values of the five plants was calculated as the canopy SPAD value of the variety of beets.

2.5 Processing of images

In this study, images were captured by DJI multispectral version P4M UAV, and Pix4Dmapper software (https://pix4d.com/) was used to stitch the acquired raw images, and image correction was performed according to the corresponding image control points on the ground before stitching to generate Digital Orthophoto Map (DOM); then reflectance conversion was performed by whiteboard correction to convert pixel values to reflectance, and finally, reflectance images of all spectra were acquired by ARCGIS software (Version 1). DOM); then the reflectance was converted from pixel values to reflectance by white-board correction to obtain reflectance images of all spectra, and finally, the plot was ex-tracted by ARCGIS software (Version 10.3.1 Esri, USA) (http://www.esri.com/arcgis/about-arcgis) to obtain vectorial surface extraction to obtain the reflectance data of this study plot to provide the data base for the subsequent vegeta-tion index, the specific process is shown in Fig 1.

10.1371/journal.pone.0300056.g001 Fig 1 Flow chart of multispectral image processing.

2.6 Selection of vegetation index

Vegetation indices are composed by combining the changes of reflectance of different bands, which can reduce the influence of background soil and other factors on the vegeta-tion spectrum to a certain extent, and improve the accuracy of estimating chlorophyll content. In this paper, a variety of vegetation indices are used, and then the correlation between vegetation indices and SPAD values is combined to preferably select the vegeta-tion indices, and finally the preferred vegetation indices are used to model inversion and prediction of SPAD values. The formula for calculating the vegetation index is shown in Table 2.

10.1371/journal.pone.0300056.t002 Table 2 Vegetation index and its calculation formula.

Vegetation index	formula to calculate	Reference	
NDVI	NDVI = (RNir − RRed)/(RNir + RRed)	[28]	
GNDVI	GNDVI = (RNir − RGreen)/(RNir + RGreen)	[29]	
MSR	MSR = (RNir/RRed − 1)/(RNir/RRed + 1)	[30]	
SR	SR = RNir/RRed	[31]	
GCI	GCI = RNir/RGreen − 1	[32]	
NDREI	NDREI = (RRededge − RGreen)/(RRededge + RGreen)	[33]	
OSAVI	OSAVI = (RNir − RRed)/(RNir + RRed + 0.16)	[34]	

2.7 Analysis methods

In order to predict the chlorophyll content of sugar beet, this study carried out five types of algorithms, namely K-NearestNeighbor (KNN) [35], Lasso [36], Ran-dom-Forest [37], RidgeCV [38] and Support Vector Machine (SVM) [39], which are the most classical algorithms of machine learning, to study, then the model inversion is performed with the studied data, and finally, through the experimental control of the data, we try to find out the optimal regression learning algorithm that is most suitable for this study, and provide model support for the subsequent data prediction. The specific flowchart of pro-gramme execution is shown in Fig 2.

10.1371/journal.pone.0300056.g002 Fig 2 Flow chart of inverse model of multiple machine learning algorithms.

2.8 Model evaluation indexes

Pearson correlation coefficient R2, root mean square error RMSE and standard root mean square error NRMSE are used as the evaluation indexes of different models, in which the closer the R2 is to 1, the lower the RMSE value indicates that the model’s pre-dicted and measured values are in good consistency, and the lower the NRMSE value is, the higher the accuracy of its estimation model and the better the results are, and the mod-el’s precision is very high when it is less than 10%, higher when it is between 10% and When it is less than 10%, the model accuracy is high, from 10% to 20%, the accuracy is high, from 20% to 30%, the accuracy is normal, and when it is more than 30%, the accu-racy is poor, and all the above data statistics methods are done using sklearn package in Python language.

3 Results

3.1 Accuracy evaluation of UAV multispectral image data

The UAV images were subjected to reflectance extraction of different band spectra according to the plots, as shown in Fig 3, the spectral reflectance of different fertility periods were all in the band range of 450–550 nm, and the spectral reflectance curves of different regions showed an increasing trend, and the phenomenon of green wave peaks appeared around 550 nm, which was more consistent with the results of the literature. Between 630nm-670nm it is obvious that the position of a red wave valley appears once, and the law of the appearance of this red wave valley is basically the same as that of the appearance of the green wave peak. In the range of 466nm-830nm band, the reflectance of the multispectral data has a high precision, and this result is more consistent with the re-sults of the literature, and the five multispectral bands selected in this paper are in the range of this band, which can be used to estimate the chlorophyll of the canopy of sugar beet.

10.1371/journal.pone.0300056.g003 Fig 3 Spectral reflectance of five bands under water and drought treatments of Manas sugar beet UAVs.

Note: A–B, denote two replicates under normal irrigation; D–E denote two replicates under wa ter limited treatment.

3.2 Distribution of SPAD phenotypes in sugar beet canopy

Canopy SPAD values were obtained for the rapid growth period of sugar beet leaf clusters under different water treatments of normal irrigation and drought stress, respec-tively. SPAD was evaluated by four dimensions, which are mean expressed as ¦Ì, median as median, coefficient of variation as cv, and standard deviation as ¦Ò. From A and B in the Fig 4, it can be seen that the mean value of SPAD under drought stress was distributed in the range of 51.75–53.05, the median was distributed in the range of 51.80–53.13, the distribution of ¦Ò was distributed in the range of 3.64–3.78, and the coefficient of variation of cv was distributed in the range of 6.90%-7.30%. From D and E in the figure, it can be seen that the mean values of SPAD under normal irrigation were distributed in the range of 47.44–50.75, the distribution of median was in the range of 47.40–50.72, the distribution of ¦Ò was in the range of 3.51–3.61, and the coefficient of variation of cv was in the range of 6.90%-7.60%. The coefficient of variation of SPAD of sugar beet under normal irrigation showed a decreasing trend compared to the drought stress data, and also the SPAD of this population under normal irrigation was greater than that under drought stress during the rapid growth period of leaf clusters. In conclusion, the overall data dispersion and the range of variability are still large, and it also indicates that the population is rich in genetic variation.

10.1371/journal.pone.0300056.g004 Fig 4 Distribution of SPAD during the rapid growth period of Manas beet leaf clusters.

3.3 Correlation analysis between SPAD and vegetation index of sugar beet canopy

Correlation analysis of canopy SPAD values during the rapid growth period of sugar beet leafy bush with spectral parameters corresponding to the fertility period was carried out and the results are shown in Fig 5. From Fig 5, it can be seen that most of the spectral vegetation indices under normal irrigation during the rapid growth period of sugar beet leafy bush reached highly significant levels (p<0.001). The correlation coeffi-cients of NDVI and SR vegetation indices reached 0.60, and the others were above 0.50; SPAD also reached highly significant levels (p<0.001) with the corresponding vegetation indices under drought stress; the correlation coefficients of SPAD and NDVI vegetation indices reached -0.60, and the other vegetation indices reached -0.55 or above. Combining the results of correlation analyses between SPAD and various vegetation indices during the rapid growth period of leaf clusters in the important fertility period of sugar beet, the correlations of the selected vegetation indices reached a significant level, and the next step can be the inversion of model prediction for SPAD of sugar beet.

10.1371/journal.pone.0300056.g005 Fig 5 Correlation of different vegetation indices with SPAD of sugar beet during rapid growth period of leaf clusters.

(a) Normal treatment during rapid growth period of leaf clusters of Manas sugar beet. (b) Water treatment during rapid growth period of leaf clusters of Manas sugar beet.

3.4 Evaluation of the accuracy of the prediction model

Five machine learning algorithms, namely KNN, Lasso, Random-Forest, RidgeCV and SVM, were used to invert the model under two water treatments for the SPAD values of the canopy during the rapid growth period of the leaf clusters of sugar beets, respec-tively, and the results are shown in Fig 6. The correlation coefficients of SPAD predic-tion using the RNN model under normal irrigation were R2 = 0.481, Rmse = 2.5, and Re = 0.6%; the correlation coefficients R2 for SPAD prediction using the Lasso model were 0.630, Rmse = 2.12 and Re = 0.80%; the correlation coefficients R2 for SPAD prediction using the Random-Frost model were 0.606, Rmse = 2.19 and Re = 0.3%; and the correlation coefficients R2 for SPAD prediction using the RidgeCV model were 0.3%. The correlation coefficients for SPAD prediction using the RidgeCV model R2 = 0.606, Rmse = 2.19 and Re = 0.3%; and the correlation coefficients for SPAD prediction using the SVM model R2 = 0.635, Rmse = 2.13 and Re = 0.8%. Under drought stress, the correlation coefficients for SPAD prediction using the RNN model R2 = 0.518, Rmse = 2.89 and Re = 0.01. The correlation coefficients for SPAD prediction using the Lasso model R2 = 0.610, Rmse = 2.7 and Re = 0.1%; and the correlation coefficients for SPAD prediction using the Random-Frost model R2 = 0.512, Rmse = 2.91, and Re = 0.4%; the correlation coefficient R2 for SPAD prediction using the Ridgecv model was 0.512, Rmse = 2.91 and Re = 0.4%; and the correlation coefficient R2 for SPAD prediction using the SVM model was 0.609, Rmse = 2.71 and Re = 0.1%.

10.1371/journal.pone.0300056.g006 Fig 6 Prediction results of five machine learning models for rapid growth period of SPAD leaf clusters in sugar beet canopy under normal irrigation and drought stress.

(a) KNN model prediction results for rapid growth period of SPAD leaf clusters in sugar beet canopy under normal irrigation and drought stress. (b) Lasso model prediction results for rapid growth period of SPAD leaf clusters in sugar beet canopy under normal irrigation and drought stress. (c) Random-Forest model predictions of rapid growth period of SPAD leaf clusters in sugar beet canopy under normal irrigation and drought stress. (d) RidgeCV model predictions of rapid growth period of SPAD leaf clusters in sugar beet canopy under normal irrigation and drought stress. (e) SVM model predictions of rapid growth period of SPAD leaf clusters in sugar beet canopy under normal irrigation and drought stress.

4 Discussion

4.1 Effects of drought and water treatments on chlorophyll

In drought environments, plants have evolved a series of mechanisms for self-protection and adaptation to and resistance to unfavourable environmental stresses, and their phenotypic traits are significantly altered to minimize the effects of the adverse environment on their growth and development. At the same time, drought stress has complex and multifaceted effects on the population structure and physiology of crops [40]. There are more studies on the effects of drought on the above-ground parts of sugar beet, and it has been shown that there is a linear positive correlation between yield and leaf ar-ea of sugar beet under drought stress [41]. The production of reactive oxygen species (ROS) in the organelles under drought is one of the main factors affecting crop growth and de-velopment, and during photosynthesis, the lack of energy dissipated by excited chloro-phyll leads to the formation of chlorophyll triplet states and the reaction with triplet oxy-gen to generate highly reactive oxygen species, thus suggesting that chlorophyll content is closely associated with both drought tolerance and growth and development of sugar beet.

In this study, the analysis of chlorophyll content of sugar beet canopy showed that the results indicated that normal irrigation conditions highly significantly reduced the chlorophyll content of sugar beet canopy leaf clusters during the rapid growth period than drought stress. In addition, chlorophyll is the most important pigment for photosynthesis, which affects the physiological and biochemical processes in crops under drought stress. Drought stress causes the reactive oxygen species produced by plants to damage cell membranes, hindering chlorophyll synthesis and accelerating degradation, thus reducing chlorophyll content. At the same time, previous researchers have shown that in the early stage of stress, SOD activity and POD activity in sugar beet roots showed an increasing trend to protect sugar beet from drought stress, but in the later stage, SOD activity and POD activity gradually decreased with the intensification of the degree of stress until the end of the stress [42]. Drought stress promotes the increase of proline and malondialde-hyde in crop roots, and the promotion is stronger with increasing drought [43]. The drought stress situation increased the antioxidant enzyme activity of the crop, exacerbated the degree of lipid peroxidation in the crop root system membrane, and accumulated os-moregulatory substances to a certain extent [44, 45]. Meanwhile, previous studies also showed that the canopy SPAD value of sugar beet under drought stress showed a de-creasing trend, and sugar beet varieties with higher SPAD values under stress had higher yields and better drought tolerance [46]. These findings are consistent with the results of this paper that the SPAD values of sugar beet canopy under drought stress showed a de-creasing trend.

4.2 Generalisation of the SPAD inversion models

The current UAV multispectral with high spectral resolution and flexible manoeu-vrability plays an important role in crop high-throughput phenotyping research. In this paper, a UAV-mounted multispectral camera was used to collect ground image data and estimate the ground SPAD content [47]. The reflectance extraction of the image data re-vealed that the spectral reflectance curves of the different fertility periods studied in this paper and can be seen in the phenomenon of green light wave peaks at a wavelength of about 550 nm, which is more consistent with the results of the literature [48, 49]. Between 630nm-670nm it is obvious that the position of a red wave valley appeared once, and the law of the appearance of this red wave valley and the law of the appearance of the green wave peak is basically the same. In the range of 466nm-830nm band, the reflectance of multispectral data has a high accuracy, and this result is more consistent with the results of Aasen et al. [48] and Zhao et al. [50]. A single vegetation index does not adequately reflect crop growth, but too many veg-etation indices as input parameters to the model [51, 52] will lead to an increase in the complexity of the model. Therefore, before the model construction, different optimal vege-tation indices were obtained through the correlation between vegetation indices and SPAD. In terms of the prediction model of SPAD, this paper investigated the SPAD prediction model by five machine learning algorithmic models under normal irrigation and water restriction treatments for the rapid growth period of leaf clusters of sugar beet, respectively. It was found that the prediction models for different water treatments at different fertility periods were different, but the model with higher correlation between predicted and true values under different water treatments was the SVM model, which embodied a strong advantage among all models in terms of goodness-of-fit and accuracy.

4.3 Conclusions

In this study, a method utilizing unmanned aerial vehicle (UAV) remote sensing im-agery is developed for estimating the SPAD (Soil Plant Analysis Development) of sugar beet canopies. The approach integrates field-measured data and aerial UAV remote sens-ing data, incorporating the selection of vegetation indices and the assessment of the corre-lation between SPAD and vegetation indices. Five machine learning algorithms, namely KNN (K-Nearest Neighbors), Lasso, Random Forest, Ridgecv, and SVM (Support Vector Machine), are employed for model inversion. Under normal irrigation conditions, the cor-relation coefficients (R2) between predicted and test values are 0.635, RMSE (Root Mean Square Error) is 2.13, and RE (Relative Error) is 0.80%. Under drought stress, the corre-sponding values are R2 = 0.609, RMSE = 2.71, and RE = 0.10%. The results of this study demonstrate that constructing prediction models using the SVM algorithm under different water treatments can effectively invert the chlorophyll content of sugar beet canopies with varying growth conditions.

Supporting information

S1 Data (XLSX)

10.1371/journal.pone.0300056.r001
Decision Letter 0
Ali Habib Academic Editor
© 2024 Habib Ali
2024
Habib Ali
https://creativecommons.org/licenses/by/4.0/ This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
Submission Version0
3 Jan 2024

PONE-D-23-33769Remote sensing estimation of sugar beet SPAD based on unmanned aerial vehicle multispectral imageryPLOS ONE

Dear Dr. Li,

Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE’s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.

Please submit your revised manuscript by Feb 17 2024 11:59PM. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at plosone@plos.org. When you're ready to submit your revision, log on to https://www.editorialmanager.com/pone/ and select the 'Submissions Needing Revision' folder to locate your manuscript file.

Please include the following items when submitting your revised manuscript:A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.

A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.

An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.

If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.

If applicable, we recommend that you deposit your laboratory protocols in protocols.io to enhance the reproducibility of your results. Protocols.io assigns your protocol its own identifier (DOI) so that it can be cited independently in the future. For instructions see: https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols. Additionally, PLOS ONE offers an option for publishing peer-reviewed Lab Protocol articles, which describe protocols hosted on protocols.io. Read more information on sharing protocols at https://plos.org/protocols?utm_medium=editorial-email&utm_source=authorletters&utm_campaign=protocols.

We look forward to receiving your revised manuscript.

Kind regards,

Habib Ali, PhD

Academic Editor

PLOS ONE

Journal requirements:

When submitting your revision, we need you to address these additional requirements.

1. Please ensure that your manuscript meets PLOS ONE's style requirements, including those for file naming. The PLOS ONE style templates can be found at

https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf and

https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf

2. Please note that PLOS ONE has specific guidelines on code sharing for submissions in which author-generated code underpins the findings in the manuscript. In these cases, all author-generated code must be made available without restrictions upon publication of the work. Please review our guidelines at https://journals.plos.org/plosone/s/materials-and-software-sharing#loc-sharing-code and ensure that your code is shared in a way that follows best practice and facilitates reproducibility and reuse.

3. We note that the grant information you provided in the ‘Funding Information’ and ‘Financial Disclosure’ sections do not match.

When you resubmit, please ensure that you provide the correct grant numbers for the awards you received for your study in the ‘Funding Information’ section.

4. Thank you for stating the following financial disclosure:

“This research was funded by Key Research and development task special project of Xin-jiang(2022B02002); National Sugar Industry Technology System Project (CARS-170108); Henan Provincial Science and Technology Tackling Project(232102111132).”

Please state what role the funders took in the study.  If the funders had no role, please state: "The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript."

If this statement is not correct you must amend it as needed.

Please include this amended Role of Funder statement in your cover letter; we will change the online submission form on your behalf.

5. We note that your Data Availability Statement is currently as follows: [All relevant data are within the manuscript and its Supporting Information files.]

Please confirm at this time whether or not your submission contains all raw data required to replicate the results of your study. Authors must share the “minimal data set” for their submission. PLOS defines the minimal data set to consist of the data required to replicate all study findings reported in the article, as well as related metadata and methods (https://journals.plos.org/plosone/s/data-availability#loc-minimal-data-set-definition).

For example, authors should submit the following data:

- The values behind the means, standard deviations and other measures reported;

- The values used to build graphs;

- The points extracted from images for analysis.

Authors do not need to submit their entire data set if only a portion of the data was used in the reported study.

If your submission does not contain these data, please either upload them as Supporting Information files or deposit them to a stable, public repository and provide us with the relevant URLs, DOIs, or accession numbers. For a list of recommended repositories, please see https://journals.plos.org/plosone/s/recommended-repositories.

If there are ethical or legal restrictions on sharing a de-identified data set, please explain them in detail (e.g., data contain potentially sensitive information, data are owned by a third-party organization, etc.) and who has imposed them (e.g., an ethics committee). Please also provide contact information for a data access committee, ethics committee, or other institutional body to which data requests may be sent. If data are owned by a third party, please indicate how others may request data access.

6. PLOS requires an ORCID iD for the corresponding author in Editorial Manager on papers submitted after December 6th, 2016. Please ensure that you have an ORCID iD and that it is validated in Editorial Manager. To do this, go to ‘Update my Information’ (in the upper left-hand corner of the main menu), and click on the Fetch/Validate link next to the ORCID field. This will take you to the ORCID site and allow you to create a new iD or authenticate a pre-existing iD in Editorial Manager. Please see the following video for instructions on linking an ORCID iD to your Editorial Manager account: https://www.youtube.com/watch?v=_xcclfuvtxQ.

7. We note that Figure 1 in your submission contain copyrighted images. All PLOS content is published under the Creative Commons Attribution License (CC BY 4.0), which means that the manuscript, images, and Supporting Information files will be freely available online, and any third party is permitted to access, download, copy, distribute, and use these materials in any way, even commercially, with proper attribution. For more information, see our copyright guidelines: http://journals.plos.org/plosone/s/licenses-and-copyright.

We require you to either (1) present written permission from the copyright holder to publish these figures specifically under the CC BY 4.0 license, or (2) remove the figures from your submission:

1. You may seek permission from the original copyright holder of Figure 1 to publish the content specifically under the CC BY 4.0 license.

We recommend that you contact the original copyright holder with the Content Permission Form (http://journals.plos.org/plosone/s/file?id=7c09/content-permission-form.pdf) and the following text:

“I request permission for the open-access journal PLOS ONE to publish XXX under the Creative Commons Attribution License (CCAL) CC BY 4.0 (http://creativecommons.org/licenses/by/4.0/). Please be aware that this license allows unrestricted use and distribution, even commercially, by third parties. Please reply and provide explicit written permission to publish XXX under a CC BY license and complete the attached form.”

Please upload the completed Content Permission Form or other proof of granted permissions as an "Other" file with your submission.

In the figure caption of the copyrighted figure, please include the following text: “Reprinted from [ref] under a CC BY license, with permission from [name of publisher], original copyright [original copyright year].”

2. If you are unable to obtain permission from the original copyright holder to publish these figures under the CC BY 4.0 license or if the copyright holder’s requirements are incompatible with the CC BY 4.0 license, please either i) remove the figure or ii) supply a replacement figure that complies with the CC BY 4.0 license. Please check copyright information on all replacement figures and update the figure caption with source information. If applicable, please specify in the figure caption text when a figure is similar but not identical to the original image and is therefore for illustrative purposes only.

8. Please review your reference list to ensure that it is complete and correct. If you have cited papers that have been retracted, please include the rationale for doing so in the manuscript text, or remove these references and replace them with relevant current references. Any changes to the reference list should be mentioned in the rebuttal letter that accompanies your revised manuscript. If you need to cite a retracted article, indicate the article’s retracted status in the References list and also include a citation and full reference for the retraction notice.

Additional Editor Comments:

The use of language could be more precise and concise. Consider avoiding unnecessary words to enhance clarity. Ensure consistent use of tense throughout the paper for a smoother flow of ideas. The paper would benefit from providing more context and background information to help readers better understand the research problem. author should Work on transitions between paragraphs to enhance the overall coherence and make the paper more reader-friendly.There are typographical errors present. Consider thorough proofreading to eliminate spelling mistakes and improve the overall professionalism of the paper.These comments are intended to guide improvements in language, grammar, and overall paper structure. It is advisable to carefully review and revise the paper with these considerations in mind.

[Note: HTML markup is below. Please do not edit.]

Reviewers' comments:

Reviewer's Responses to Questions

Comments to the Author

1. Is the manuscript technically sound, and do the data support the conclusions?

The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented.

Reviewer #1: Yes

Reviewer #2: Yes

**********

2. Has the statistical analysis been performed appropriately and rigorously?

Reviewer #1: Yes

Reviewer #2: Yes

**********

3. Have the authors made all data underlying the findings in their manuscript fully available?

The PLOS Data policy requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data—e.g. participant privacy or use of data from a third party—those must be specified.

Reviewer #1: Yes

Reviewer #2: Yes

**********

4. Is the manuscript presented in an intelligible fashion and written in standard English?

PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.

Reviewer #1: Yes

Reviewer #2: Yes

**********

5. Review Comments to the Author

Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)

Reviewer #1: I appreciate the Editor to give me a chance to review an interesting and valuable paper. I found some merits in the both methodology and results. However, I have also some concerns on the manuscript. If the author(s) address to the comments, I’ll recommend this paper entitled “Remote sensing estimation of sugar beet SPAD based on un-manned aerial vehicle multispectral imagery” for publication with minor revision:

1.I noticed that manuscript is very good but authors not corrected cited the reference, please correct them and use latest reference.

2.Double check the reference and arrange according to the journal style.

3.L52: You not added any reference here. Add this “a new solution for the canopy traits of crops (Tian et al., 2020) and this study focuses with the SPAD prediction of sugar beet based on multispectral images from UAV remote sensing (Tian et al., 2019).” Add references according to the journal like [5] and [6].

Tian H, Huang N, Niu Z, Qin Y, Pei J, Wang J. Mapping winter crops in china with multi-source satellite imagery and phenology-based algorithm. Remote Sens. 2019; 11: 820. https://doi.org/10.3390/rs11070820

Tian H, Pei J, Huang J, Li X, Wang J, Zhou B, Qin Y, Wang L. Garlic and winter wheat identification based on active and passive satellite imagery and the google earth engine in northern china. Remote Sens, 2020; 12, 3539. https://doi.org/10.3390/rs12213539 “

4.L56: You not add any reference after “rapidly in both breadth and depth.” Add these as “UAV remote sensing of agriculture has been developing rapidly in both breadth and depth (Zhao et al., 2023; Cheng et al., 2023). Add references according to the journal like [7, 8].

Zhao K, Jia Z, Jia F, Shao H. Multi-scale integrated deep self-attention network for predicting remaining useful life of aero-engine. Eng Appl Artif Intell, 2023; 120, 105860. https://doi.org/10.1016/j.engappai.2023.105860

Cheng Y, Lan S, Fan X, Tjahjadi T, Jin S, Cao L. A dual-branch weakly supervised learning based network for accurate mapping of woody vegetation from remote sensing images. Int J Appl Earth Obs Geoinf, 2023; 124, 103499. https://doi.org/10.1016/j.jag.2023.103499

5.L58: You not added any reference, Please add like “they have become the favoured object in the majority of research (Zhou et al., 2021; Zhuo et al., 2022).” Add references according to the journal like [9, 10].

Zhou G, Li W, Zhou X, Tan Y, Lin G, Li X, Deng R. An innovative echo detection system with STM32 gated and PMT adjustable gain for airborne LiDAR. Int J Remote Sens, 2021; 42:24, 9187-9211. https://doi.org/10.1080/01431161.2021.1975844

Zhuo Z, Du L, Lu X, Chen J, Cao Z. Smoothed Lv Distribution Based Three-Dimensional Imaging for Spinning Space Debris. IEEE Trans Geosci Remote Sens, 2022; 60, 1-13. https://doi.org/10.1109/TGRS.2022.3174677

6.L60: You not added any reference, add like “spectral sensors, multispectral sensors, etc (Zhang et al., 2023; Zhao et al., 2023).” Add references according to the journal like [11, 12].

Zhang Y, Li S, Wang S, Wang X, Duan H. Distributed bearing-based formation maneuver control of fixed-wing UAVs by finite-time orientation estimation. Aerosp Sci Technol, 2023; 136, 108241. https://doi.org/10.1016/j.ast.2023.108241

Zhao J, Gao F, Jia W, Yuan W, Jin W. Integrated Sensing and Communications for UAV Communications with Jittering Effect. IEEE Wirel Commun Lett, 2023; 12, 758-762. https://doi.org/10.1109/LWC.2023.3243590

7.L62-63: “At present, domestic and foreign scholars use hyperspectral for the estimation of vegetation chlorophyll content”. It’s not correct. Please remove at present, domestic and foreign scholar, write just many researchers. Correct this sentence.

8.L68: You write “Bendig et al[7] predicted the biomass of crops by UAV and obtained better results.” Give space between al and [7] and also give another reference as “Bendig et al. [7] and Dai et al. (2023) predicted the biomass of crops by UAV and obtained better results.” Add references according to the journal like Bendig et al. [14] and Dai et al. [15].

Dai X, Xiao Z, Jiang H, Lui JCS. UAV-Assisted Task Offloading in Vehicular Edge Computing Networks. IEEE Trans Mob Comput. 2023; 21, 3536-3550. https://doi.org/10.1109/TMC.2023.3259394

9.L71: You not add any reference here. Add reference as “remote sensing in precision agriculture (Zhou et al., 2021; Liu et al., 2022). Add references according to the journal like [17,18]

Zhou G, Deng R, Zhou X, Long S, Li W, Lin G, Li X. Gaussian Inflection Point Selection for LiDAR Hidden Echo Signal Decomposition. IEEE Geosci Remote Sens Lett. 2021; 19, 1-5. https://doi.org/10.1109/LGRS.2021.3107438

Liu H, Li J, Meng X, Zhou B, Fang G, Spencer B.F. Discrimination Between Dry and Water Ices by Full Polarimetric Radar: Implications for China’s First Martian Exploration. IEEE Trans Geosci Remote Sens, 2022; 61, 1-11. https://doi.org/10.1109/TGRS.2022.3228684

10.L73: You not add any reference. Please add reference as “unknown data based on established models and input parameters (Lin et al., 2022; She et al., 2022).” Add references according to the journal like [20, 21]

Lin Z, Wang H, Li S. Pavement anomaly detection based on transformer and self-supervised learning. Autom Constr. 2022; 143, 104544. https://doi.org/10.1016/j.autcon.2022.104544

She Q, Hu R, Xu J, Liu M, Xu K, Huang H. Learning High-DOF Reaching-and-Grasping via Dynamic Representation of Gripper-Object Interaction. ACM Trans Graph. 2022; 41(4). https://doi.org/10.1145/3528223.3530091

11.L75-76: You not added any reference, please add reference as “but also in unstructured and non-linear domains (Zhou et al., 2021; Zhang et al., 2021). Add references according to the journal like [22, 23]

Zhou G, Zhang R, Huang S. Generalized Buffering Algorithm. IEEE access, 2021; 9, 27140-27157. https://doi.org/10.1109/ACCESS.2021.3057719

Zhang J, Zhu C, Zheng L, Xu K. ROSEFusion: random optimization for online dense reconstruction under fast camera motion. ACM Trans Graph. 2021; 40, 1-17. https://doi.org/10.1145/3450626.3459676

12.L78: Reference [8-10] is not suitable, remove them and add following reference instead to these at this place.

Mao Y, Zhu Y, Tang Z, Chen Z. A Novel Airspace Planning Algorithm for Cooperative Target Localization. Electronics. 2022; 11, 2950. https://doi.org/10.3390/electronics11182950

Yin L, Wang L, Li J, Lu S, Tian J, Yin Z, Liu S, Zheng W. YOLOV4_CSPBi: Enhanced Land Target Detection Model. Land, 2023; 12, 1813. https://doi.org/10.3390/land12091813

13.L203: Please don’t use any reference in the results section. Remove all from the results.

14.L330: Add this reference here after the “estimate the ground SPAD content (Cao et al., 201)” Add references according to the journal like [31]

Cao B, Li M, Liu X, Zhao J, Cao W, Lv Z. Many-Objective Deployment Optimization for a Drone-Assisted Camera Network. IEEE Trans Netw Sci Eng, 2021; 8, 2756-2764. https://doi.org/10.1109/TNSE.2021.3057915

15.L333: “which is more consistent with the results of the literature [26]” You add only 1 reference. Add 1 more as I suggested and given following “Wang et al., 2022”.

Wang H, Zhang X, Jiang S. A Laboratory and Field Universal Estimation Method for Tire–Pavement Interaction Noise (TPIN) Based on 3D Image Technology. Sustainability, 2022; 14, 12066. https://doi.org/10.3390/su141912066

16.L338: Add following reference as well with the “result is more consistent with the results of literature [26]” Also remove the word literature. Just write the “results of the Aasen et al. [26] and Zhao et al. [7]”.

Zhao F, Wu H, Zhu S, Zeng H, Zhao Z, Yang X, Zhang S. Material stock analysis of urban road from nighttime light data based on a bottom-up approach. Environ Res, 2023; 228, 115902. https://doi.org/10.1016/j.envres.2023.115902

17.L340-341: “model will lead to an increase in the complexity of the model.” Add following reference here as “model will lead to an increase in the complexity of the model (Zheng et al., 2023; Yin et al., 2023). Add references according to the journal like [20, 21].

Zheng H, Fan X, Bo W, Yang X, Tjahjadi T, Jin S. A Multiscale Point-Supervised Network for Counting Maize Tassels in the Wild. Plant Phenomics. 2023; 5, 100. https://doi.org/10.34133/plantphenomics.0100

Yin L, Wang L, Li T, Lu S, Tian J, Yin Z., et al. U-Net-LSTM: Time Series-Enhanced Lake Boundary Prediction Model. Land, 2023; 12, 1859. https://doi.org/10.3390/land12101859

18.Don’t repeat results in discussion section.

19.In conclusion you just make repetition of similar information as given in the start of conclusion. Make it clear.

20.Need to focus on the findings according to result. What are recommendations?

21.Double check that all references are cited within the text

Overall paper is very good. I recommend the minor revision.

Reviewer #2: Dear Editor,

Gao et al. attempted to describe remote sensing estimation of sugar beet SPAD based on unmanned aerial vehicle multispectral imagery; it is a nice piece of work, I would like it to be published, however there are some points, cited below, which need author’s attention.

1.In lines 37-39 taxonomical details for the studied plant species are erroneous. Sugar beet (scientific name: Beta vulgaris) belongs to Amaranthaceae family and genus Beta and not as it is cited [genus Sugar Beet, family Quinoa]. The manuscript do not cite the scientific name of the studied plant species.

2.In lines 92-94 it is cited that [300 copies of domestic and foreign staple varieties were selected as the participating materials…]. There is no available information a) for their genetic and/or physiological background b) for their resistance to stress factor (drought). Further explanations are needed due to the fact that outcome UAV spectral data are not linked with known informative basis of the crop.

In Result section lines: 226-229 “In conclusion, the overall data dispersion and the range of variability are still large, and it also indicates that the population is rich in genetic variation. Genetic variation should be standardized, defined and stated prior to the experiment; authors received SPAD response variation in stressed and non-stressed conditions which cannot provide reverse statements for optimized materials experimentation.

3.Drone platforms and flight setting are well described; however no geographical spatial / positioning information was provided for the scanned area.

4.Authors provide extensive discussion on causes of chlorophyll decline due to drought (section 4.1-Discussion); however, this information is not taken into account on experimental planning and outcome results. Core aim of the manuscript is to introduce UAV remote sensing crop phenotyping in machine learning (as it is indicated in lines 79-87) but there is no categorization and or validation of drought-chrolophyll decline causes prior data being introduced to algorithmic – machine learning analysis phase.

5.Some inconsistency typing problems found citation’s section format (capital letters text etc).

In conclusion, according to my opinion the manuscript has some interest viewpoints in terms of UAV spectral scans on sugar beet plantations introducing outcome data for machine learning processes; if some clarifications /changes take place I would be glad to see it published as one more step in machine learning and UAV spectral analysis of crops.

**********

6. PLOS authors have the option to publish the peer review history of their article (what does this mean?). If published, this will include your full peer review and any attached files.

If you choose “no”, your identity will remain anonymous but your review may still be made public.

Do you want your identity to be public for this peer review? For information about this choice, including consent withdrawal, please see our Privacy Policy.

Reviewer #1: Yes: Muhammad Saqlain Zaheer

Reviewer #2: No

**********

[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]

While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, https://pacev2.apexcovantage.com/. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at figures@plos.org. Please note that Supporting Information files do not need this step.

10.1371/journal.pone.0300056.r002
Author response to Decision Letter 0
Submission Version1
18 Feb 2024

Response Letter of PONE-D-23-33769

Dear Editor, and the reviewers,

This is the response letter for paper PONE-D-23-33769, entitled “Remote sensing estimation of sugar beet SPAD based on unmanned aerial vehicle multispectral imagery”. We greatly thank the editors and the reviewers for their efforts and their constructive comments that help us improve this study. This letter details our revision in response to their comments.

Response to Reviewer #1

1.I noticed that manuscript is very good but authors not corrected cited the reference, please correct them and use latest reference.

2.Double check the reference and arrange according to the journal style.

3.L52: You not added any reference here. Add this “a new solution for the canopy traits of crops (Tian et al., 2020) and this study focuses with the SPAD prediction of sugar beet based on multispectral images from UAV remote sensing (Tian et al., 2019).” Add references according to the journal like [5] and [6].

Tian H, Huang N, Niu Z, Qin Y, Pei J, Wang J. Mapping winter crops in china with multi-source satellite imagery and phenology-based algorithm. Remote Sens. 2019; 11: 820. https://doi.org/10.3390/rs11070820

Tian H, Pei J, Huang J, Li X, Wang J, Zhou B, Qin Y, Wang L. Garlic and winter wheat identification based on active and passive satellite imagery and the google earth engine in northern china. Remote Sens, 2020; 12, 3539. https://doi.org/10.3390/rs12213539 “

4.L56: You not add any reference after “rapidly in both breadth and depth.” Add these as “UAV remote sensing of agriculture has been developing rapidly in both breadth and depth (Zhao et al., 2023; Cheng et al., 2023). Add references according to the journal like [7, 8].

Zhao K, Jia Z, Jia F, Shao H. Multi-scale integrated deep self-attention network for predicting remaining useful life of aero-engine. Eng Appl Artif Intell, 2023; 120, 105860. https://doi.org/10.1016/j.engappai.2023.105860

Cheng Y, Lan S, Fan X, Tjahjadi T, Jin S, Cao L. A dual-branch weakly supervised learning based network for accurate mapping of woody vegetation from remote sensing images. Int J Appl Earth Obs Geoinf, 2023; 124, 103499. https://doi.org/10.1016/j.jag.2023.103499

5.L58: You not added any reference, Please add like “they have become the favoured object in the majority of research (Zhou et al., 2021; Zhuo et al., 2022).” Add references according to the journal like [9, 10].

Zhou G, Li W, Zhou X, Tan Y, Lin G, Li X, Deng R. An innovative echo detection system with STM32 gated and PMT adjustable gain for airborne LiDAR. Int J Remote Sens, 2021; 42:24, 9187-9211. https://doi.org/10.1080/01431161.2021.1975844

Zhuo Z, Du L, Lu X, Chen J, Cao Z. Smoothed Lv Distribution Based Three-Dimensional Imaging for Spinning Space Debris. IEEE Trans Geosci Remote Sens, 2022; 60, 1-13. https://doi.org/10.1109/TGRS.2022.3174677

6.L60: You not added any reference, add like “spectral sensors, multispectral sensors, etc (Zhang et al., 2023; Zhao et al., 2023).” Add references according to the journal like [11, 12].

Zhang Y, Li S, Wang S, Wang X, Duan H. Distributed bearing-based formation maneuver control of fixed-wing UAVs by finite-time orientation estimation. Aerosp Sci Technol, 2023; 136, 108241. https://doi.org/10.1016/j.ast.2023.108241

Zhao J, Gao F, Jia W, Yuan W, Jin W. Integrated Sensing and Communications for UAV Communications with Jittering Effect. IEEE Wirel Commun Lett, 2023; 12, 758-762. https://doi.org/10.1109/LWC.2023.3243590

7.L62-63: “At present, domestic and foreign scholars use hyperspectral for the estimation of vegetation chlorophyll content”. It’s not correct. Please remove at present, domestic and foreign scholar, write just many researchers. Correct this sentence.

8.L68: You write “Bendig et al[7] predicted the biomass of crops by UAV and obtained better results.” Give space between al and [7] and also give another reference as “Bendig et al. [7] and Dai et al. (2023) predicted the biomass of crops by UAV and obtained better results.” Add references according to the journal like Bendig et al. [14] and Dai et al. [15].

Dai X, Xiao Z, Jiang H, Lui JCS. UAV-Assisted Task Offloading in Vehicular Edge Computing Networks. IEEE Trans Mob Comput. 2023; 21, 3536-3550. https://doi.org/10.1109/TMC.2023.3259394

9.L71: You not add any reference here. Add reference as “remote sensing in precision agriculture (Zhou et al., 2021; Liu et al., 2022). Add references according to the journal like [17,18]

Zhou G, Deng R, Zhou X, Long S, Li W, Lin G, Li X. Gaussian Inflection Point Selection for LiDAR Hidden Echo Signal Decomposition. IEEE Geosci Remote Sens Lett. 2021; 19, 1-5. https://doi.org/10.1109/LGRS.2021.3107438

Liu H, Li J, Meng X, Zhou B, Fang G, Spencer B.F. Discrimination Between Dry and Water Ices by Full Polarimetric Radar: Implications for China’s First Martian Exploration. IEEE Trans Geosci Remote Sens, 2022; 61, 1-11. https://doi.org/10.1109/TGRS.2022.3228684

10.L73: You not add any reference. Please add reference as “unknown data based on established models and input parameters (Lin et al., 2022; She et al., 2022).” Add references according to the journal like [20, 21]

Lin Z, Wang H, Li S. Pavement anomaly detection based on transformer and self-supervised learning. Autom Constr. 2022; 143, 104544. https://doi.org/10.1016/j.autcon.2022.104544

She Q, Hu R, Xu J, Liu M, Xu K, Huang H. Learning High-DOF Reaching-and-Grasping via Dynamic Representation of Gripper-Object Interaction. ACM Trans Graph. 2022; 41(4). https://doi.org/10.1145/3528223.3530091

11.L75-76: You not added any reference, please add reference as “but also in unstructured and non-linear domains (Zhou et al., 2021; Zhang et al., 2021). Add references according to the journal like [22, 23]

Zhou G, Zhang R, Huang S. Generalized Buffering Algorithm. IEEE access, 2021; 9, 27140-27157. https://doi.org/10.1109/ACCESS.2021.3057719

Zhang J, Zhu C, Zheng L, Xu K. ROSEFusion: random optimization for online dense reconstruction under fast camera motion. ACM Trans Graph. 2021; 40, 1-17. https://doi.org/10.1145/3450626.3459676

12.L78: Reference [8-10] is not suitable, remove them and add following reference instead to these at this place.

Mao Y, Zhu Y, Tang Z, Chen Z. A Novel Airspace Planning Algorithm for Cooperative Target Localization. Electronics. 2022; 11, 2950. https://doi.org/10.3390/electronics11182950

Yin L, Wang L, Li J, Lu S, Tian J, Yin Z, Liu S, Zheng W. YOLOV4_CSPBi: Enhanced Land Target Detection Model. Land, 2023; 12, 1813. https://doi.org/10.3390/land12091813

13.L203: Please don’t use any reference in the results section. Remove all from the results.

14.L330: Add this reference here after the “estimate the ground SPAD content (Cao et al., 201)” Add references according to the journal like [31]

Cao B, Li M, Liu X, Zhao J, Cao W, Lv Z. Many-Objective Deployment Optimization for a Drone-Assisted Camera Network. IEEE Trans Netw Sci Eng, 2021; 8, 2756-2764. https://doi.org/10.1109/TNSE.2021.3057915

15.L333: “which is more consistent with the results of the literature [26]” You add only 1 reference. Add 1 more as I suggested and given following “Wang et al., 2022”.

Wang H, Zhang X, Jiang S. A Laboratory and Field Universal Estimation Method for Tire–Pavement Interaction Noise (TPIN) Based on 3D Image Technology. Sustainability, 2022; 14, 12066. https://doi.org/10.3390/su141912066

16.L338: Add following reference as well with the “result is more consistent with the results of literature [26]” Also remove the word literature. Just write the “results of the Aasen et al. [26] and Zhao et al. [7]”.

Zhao F, Wu H, Zhu S, Zeng H, Zhao Z, Yang X, Zhang S. Material stock analysis of urban road from nighttime light data based on a bottom-up approach. Environ Res, 2023; 228, 115902. https://doi.org/10.1016/j.envres.2023.115902

17.L340-341: “model will lead to an increase in the complexity of the model.” Add following reference here as “model will lead to an increase in the complexity of the model (Zheng et al., 2023; Yin et al., 2023). Add references according to the journal like [20, 21].

Zheng H, Fan X, Bo W, Yang X, Tjahjadi T, Jin S. A Multiscale Point-Supervised Network for Counting Maize Tassels in the Wild. Plant Phenomics. 2023; 5, 100. https://doi.org/10.34133/plantphenomics.0100

Yin L, Wang L, Li T, Lu S, Tian J, Yin Z., et al. U-Net-LSTM: Time Series-Enhanced Lake Boundary Prediction Model. Land, 2023; 12, 1859. https://doi.org/10.3390/land12101859

-> Answer: Thank you very much for your remind! The reviewer gave professional references and current up-to-date references, which were revised in the article, and the references provided improved my new understanding in this research area, thank you very much for the patient review!

18.Don’t repeat results in discussion section.

-> Answer: Thank you very much for your remind! We have removed some of the results in the discussion section!

19.In conclusion you just make repetition of similar information as given in the start of conclusion. Make it clear.

-> Answer: Thank you very much for your comments! We have simplified the conclusion section to describe it more clearly, thank you very much for your professional guidance!

In this study, a method utilizing unmanned aerial vehicle (UAV) remote sensing imagery is developed for estimating the SPAD (Soil Plant Analysis Development) of sugar beet canopies. The approach integrates field-measured data and aerial UAV remote sensing data, incorporating the selection of vegetation indices and the assessment of the correlation between SPAD and vegetation indices. Five machine learning algorithms, namely KNN (K-Nearest Neighbors), Lasso, Random Forest, Ridgecv, and SVM (Support Vector Machine), are employed for model inversion. Under normal irrigation conditions, the correlation coefficients (R2) between predicted and test values are 0.635, RMSE (Root Mean Square Error) is 2.13, and RE (Relative Error) is 0.80%. Under drought stress, the corresponding values are R2=0.609, RMSE=2.71, and RE=0.10%. The results of this study demonstrate that constructing prediction models using the SVM algorithm under different water treatments can effectively invert the chlorophyll content of sugar beet canopies with varying growth conditions.

20.Need to focus on the findings according to result. What are recommendations?

-> Answer: Thank you very much for your comments! We have scrutinized the full text and revised some of the descriptions where they were unclear.

21.Double check that all references are cited within the text

-> Answer: Thank you very much for your comments! We double-checked all the references and made changes according to the format of the journal.

Reviewer #2:

1.In lines 37-39 taxonomical details for the studied plant species are erroneous. Sugar beet (scientific name: Beta vulgaris) belongs to Amaranthaceae family and genus Beta and not as it is cited [genus Sugar Beet, family Quinoa]. The manuscript do not cite the scientific name of the studied plant species.

-> Answer: Thank you very much for your comments! Thank you very much for your professional opinion, we have also learned a lot by reviewing the literature and giving references in the article.

2.In lines 92-94 it is cited that [300 copies of domestic and foreign staple varieties were selected as the participating materials…]. There is no available information a) for their genetic and/or physiological background b) for their resistance to stress factor (drought). Further explanations are needed due to the fact that outcome UAV spectral data are not linked with known informative basis of the crop.

In Result section lines: 226-229 “In conclusion, the overall data dispersion and the range of variability are still large, and it also indicates that the population is rich in genetic variation. Genetic variation should be standardized, defined and stated prior to the experiment; authors received SPAD response variation in stressed and non-stressed conditions which cannot provide reverse statements for optimized materials experimentation.

3.Drone platforms and flight setting are well described; however no geographical spatial / positioning information was provided for the scanned area.

-> Answer: Thank you very much for your comments! Regarding the 300 populations you mentioned, 300 natural populations were used in this study for the SPAD model prediction study of sugar beets, and since the genotypes of the 300 populations were different, we analyzed the variability of the populations in the data analysis of the phenotypes. Thank you very much for your professional question. The next step of our plan is to correlate the genotypes of SPAD content in sugar beets with the phenotypes obtained by drone remote sensing to find out the genes that may affect it and to provide a theoretical basis for the subsequent breeding of sugar beet.

4.Authors provide extensive discussion on causes of chlorophyll decline due to drought (section 4.1-Discussion); however, this information is not taken into account on experimental planning and outcome results. Core aim of the manuscript is to introduce UAV remote sensing crop phenotyping in machine learning (as it is indicated in lines 79-87) but there is no categorization and or validation of drought-chrolophyll decline causes prior data being introduced to algorithmic – machine learning analysis phase.

-> Answer: Thank you very much for your professional evaluation, in the article we set up different treatments of water and drought to study the SPAD of sugar beets, as there are fewer studies on UAV SPAD of sugar beets at the moment, not much can be referred to in this part, we compared the prediction accuracy of the UAV model through water and drought and evaluated it, and the actual measurements were given as well, this is in the part of the analysis of the results.

5.Some inconsistency typing problems found citation’s section format (capital letters text etc).

-> Answer: Thank you very much for your comments! We double-checked all the references and made changes according to the format of the journal.

Attachment Submitted filename: renamed_be71e.docx

10.1371/journal.pone.0300056.r003
Decision Letter 1
Ali Habib Academic Editor
© 2024 Habib Ali
2024
Habib Ali
https://creativecommons.org/licenses/by/4.0/ This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
Submission Version1
21 Feb 2024

Remote sensing estimation of sugar beet SPAD based on unmanned aerial vehicle multispectral imagery

PONE-D-23-33769R1

Dear Dr. Li,

We’re pleased to inform you that your manuscript has been judged scientifically suitable for publication and will be formally accepted for publication once it meets all outstanding technical requirements.

Within one week, you’ll receive an e-mail detailing the required amendments. When these have been addressed, you’ll receive a formal acceptance letter and your manuscript will be scheduled for publication.

An invoice for payment will follow shortly after the formal acceptance. To ensure an efficient process, please log into Editorial Manager at http://www.editorialmanager.com/pone/, click the 'Update My Information' link at the top of the page, and double check that your user information is up-to-date. If you have any billing related questions, please contact our Author Billing department directly at authorbilling@plos.org.

If your institution or institutions have a press office, please notify them about your upcoming paper to help maximize its impact. If they’ll be preparing press materials, please inform our press team as soon as possible -- no later than 48 hours after receiving the formal acceptance. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact onepress@plos.org.

Kind regards,

Habib Ali, PhD

Academic Editor

PLOS ONE

Additional Editor Comments (optional):

Reviewers' comments:

10.1371/journal.pone.0300056.r004
Acceptance letter
Ali Habib Academic Editor
© 2024 Habib Ali
2024
Habib Ali
https://creativecommons.org/licenses/by/4.0/ This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
15 May 2024

PONE-D-23-33769R1

PLOS ONE

Dear Dr. Li,

I'm pleased to inform you that your manuscript has been deemed suitable for publication in PLOS ONE. Congratulations! Your manuscript is now being handed over to our production team.

At this stage, our production department will prepare your paper for publication. This includes ensuring the following:

* All references, tables, and figures are properly cited

* All relevant supporting information is included in the manuscript submission,

* There are no issues that prevent the paper from being properly typeset

If revisions are needed, the production department will contact you directly to resolve them. If no revisions are needed, you will receive an email when the publication date has been set. At this time, we do not offer pre-publication proofs to authors during production of the accepted work. Please keep in mind that we are working through a large volume of accepted articles, so please give us a few weeks to review your paper and let you know the next and final steps.

Lastly, if your institution or institutions have a press office, please let them know about your upcoming paper now to help maximize its impact. If they'll be preparing press materials, please inform our press team within the next 48 hours. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact onepress@plos.org.

If we can help with anything else, please email us at customercare@plos.org.

Thank you for submitting your work to PLOS ONE and supporting open access.

Kind regards,

PLOS ONE Editorial Office Staff

on behalf of

Professor Habib Ali

Academic Editor

PLOS ONE
==== Refs
References

1 Kwiatkowska M , Kadluczka D , Wedzony M , Dedicova B , Grzebelus E . Refinement of a clearing protocol to study crassinucellate ovules of the sugar beet (Beta vulgaris L., Amaranthaceae). PLANT METHODS. 2019;15 . doi: 10.1186/s13007-019-0452-6 31316582
2 Tsialtas JT , Baxevanos D , Maslaris N . Chlorophyll Meter Readings, Leaf Area Index, and Their Stability as Assessments of Yield and Quality in Sugar Beet Cultivars Grown in Two Contrasting Environments. CROP SCIENCE. 2014;54 (1 ):265–273. doi: 10.2135/cropsci2013.03.0186
3 Meskini-Vishkaee F , Mohammadi MH , Neyshabouri MR , Shekari F . Evaluation of canola chlorophyll index and leaf nitrogen under wide range of soil moisture. INTERNATIONAL AGROPHYSICS. 2015;29 (1 ):83–90. doi: 10.1515/intag-2015-0014
4 Netto A , Campostrini E , de Oliveira J , Bressan-Smith R . Photosynthetic pigments, nitrogen, chlorophyll a fluorescence and SPAD-502 readings in coffee leaves. SCIENTIA HORTICULTURAE. 2005;104 (2 ):199–209. doi: 10.1016/j.scienta.2004.08.013
5 Zhang J , Fengler KA , Van Hemert JL , Gupta R , Mongar N , Sun J , et al . Identification and characterization of a novel stay-green QTL that increases yield in maize. PLANT BIOTECHNOLOGY JOURNAL. 2019;17 (12 ):2272–2285. doi: 10.1111/pbi.13139 31033139
6 Tian H , Huang N , Niu Z , Qin Y , Pei J , Wang J . Mapping Winter Crops in China with Multi-Source Satellite Imagery and Phenology-Based Algorithm. REMOTE SENSING. 2019;11 (7 ). doi: 10.3390/rs11070820
7 Tian H , Pei J , Huang J , Li X , Wang J , Zhou B , et al . Garlic and Winter Wheat Identification Based on Active and Passive Satellite Imagery and the Google Earth Engine in Northern China. REMOTE SENSING. 2020;12 (21 ). doi: 10.3390/rs12213539
8 Zhao K , Jia Z , Jia F , Shao H . Multi-scale integrated deep self-attention network for predicting remaining useful life of aero-engine. ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE. 2023;120 . doi: 10.1016/j.engappai.2023.105860
9 Cheng Y , Lan S , Fan X , Tjahjadi T , Jin S , Cao L . A dual-branch weakly supervised learning based network for accurate mapping of woody vegetation from remote sensing images. INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION. 2023;124 . doi: 10.1016/j.jag.2023.103499
10 Zhou G , Li W , Zhou X , Tan Y , Lin G , Li X , et al . An innovative echo detection system with STM32 gated and PMT adjustable gain for airborne LiDAR. INTERNATIONAL JOURNAL OF REMOTE SENSING. 2021;42 (24 ):9179–9203. doi: 10.1080/01431161.2021.1975844
11 Zhuo Z , Du L , Lu X , Chen J , Cao Z . Smoothed Lv Distribution Based Three-Dimensional Imaging for Spinning Space Debris. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING. 2022;60 . doi: 10.1109/TGRS.2022.3174677
12 Zhang Y , Li S , Wang S , Wang X , Duan H . Distributed bearing-based formation maneuver control of fixed-wing UAVs by finite-time orientation estimation. AEROSPACE SCIENCE AND TECHNOLOGY. 2023;136 . doi: 10.1016/j.ast.2023.108241
13 Zhao J , Gao F , Jia W , Yuan W , Jin W . Integrated Sensing and Communications for UAV Communications With Jittering Effect. IEEE WIRELESS COMMUNICATIONS LETTERS. 2023;12 (4 ):758–762. doi: 10.1109/LWC.2023.3243590
14 Hunt ER Jr , Doraiswamy PC , McMurtrey JE , Daughtry CST , Perry EM , Akhmedov B . A visible band index for remote sensing leaf chlorophyll content at the canopy scale. INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION. 2013;21 :103–112. doi: 10.1016/j.jag.2012.07.020
15 Wang W , Cheng Y , Ren Y , Zhang Z , Geng H . Prediction of Chlorophyll Content in Multi-Temporal Winter Wheat Based on Multispectral and Machine Learning. FRONTIERS IN PLANT SCIENCE. 2022;13 . doi: 10.3389/fpls.2022.896408 35712585
16 Bendig J , Yu K , Aasen H , Bolten A , Bennertz S , Broscheit J , et al . Combining UAV-based plant height from crop surface models, visible, and near infrared vegetation indices for biomass monitoring in barley. International Journal of Applied Earth Observation & Geoinformation. 2015;39 :79–87. doi: 10.1016/j.jag.2015.02.012
17 Yang C , Liu B , Li H , Li B , Xie K , Xie S . Learning Based Channel Allocation and Task Offloading in Temporary UAV-Assisted Vehicular Edge Computing Networks. IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY. 2022;71 (9 ):9884–9895. doi: 10.1109/TVT.2022.3177664
18 Zhou G , Deng R , Zhou X , Long S , Li W , Lin G , et al . Gaussian Inflection Point Selection for LiDAR Hidden Echo Signal Decomposition. IEEE GEOSCIENCE AND REMOTE SENSING LETTERS. 2022;19 . doi: 10.1109/LGRS.2021.3107438
19 Liu H , Li J , Meng X , Zhou B , Fang G , Spencer BFF . Discrimination Between Dry and Water Ices by Full Polarimetric Radar: Implications for China’s First Martian Exploration. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING. 2023;61 . doi: 10.1109/TGRS.2022.3228684
20 Lin Z , Wang H , Li S . Pavement anomaly detection based on transformer and self-supervised learning. AUTOMATION IN CONSTRUCTION. 2022;143 . doi: 10.1016/j.autcon.2022.104544
21 She Q , Hu R , Xu J , Liu M , Xu K , Huang H . Learning High-DOF Reaching-and-Grasping via Dynamic Representation of Gripper-Object Interaction. ACM TRANSACTIONS ON GRAPHICS. 2022;41 (4 ). doi: 10.1145/3528223.3530091
22 Zhou G , Zhang R , Huang S . Generalized Buffering Algorithm. IEEE ACCESS. 2021;9 :27140–27157. doi: 10.1109/ACCESS.2021.3057719
23 Zhang J , Zhu C , Zheng L , Xu K . ROSEFusion: Random Optimization for Online Dense Reconstruction under Fast Camera Motion. ACM TRANSACTIONS ON GRAPHICS. 2021;40 (4 ). doi: 10.1145/3476576.3476604
24 Mao Y , Zhu Y , Tang Z , Chen Z . A Novel Airspace Planning Algorithm for Cooperative Target Localization. ELECTRONICS. 2022;11 (18 ). doi: 10.3390/electronics11182950
25 Yin L , Wang L , Li J , Lu S , Tian J , Yin Z , et al . YOLOV4 CSPBi: Enhanced Land Target Detection Model. LAND. 2023;12 (9 ). doi: 10.3390/land12091813
26 He J , Liang X , Qi B , Jing W , Zhang Z , Shi S . Diagnosis of Nitrogen Nutrition in Sugar Beet Based on the Characteristics of Scanned Leaf Images. INTERNATIONAL JOURNAL OF PLANT PRODUCTION. 2020;14 (4 ):663–677. doi: 10.1007/s42106-020-00109-1
27 Wu Z , Wang X , Song B , Zhao X , Du J , Huang W . Responses of Photosynthetic Performance of Sugar Beet Varieties to Foliar Boron Spraying. SUGAR TECH. 2021;23 (6 ):1332–1339. doi: 10.1007/s12355-021-01008-z
28 Chen J , Jnsson P , Tamura M , Gu Z , Matsushita B , Eklundh L . A simple method for reconstructing a high-quality NDVI time-series data set based on the Savitzky-Golay filter. REMOTE SENSING OF ENVIRONMENT. 2004;91 (3-4 ):332–344. doi: 10.1016/j.rse.2004.03.014
29 Gitelson A, Merzlyak M. Remote sensing of chlorophyll concentration in higher plant leaves. In: Choudhury B, Tanaka S, Kondo A, Menenti M, Becker F, editors. SYNERGISTIC USE OF MULTISENSOR DATA FOR LAND PROCESSES. vol. 22 of ADVANCES IN SPACE RESEARCH. Comm Space Res; Int Astronaut Federat; NOAA, Natl Environm Satellite, Data & Informat Serv; Int Union Geodesy & Geophys; Int Assoc Hydrol Sci; European Space Agcy; Sci Comm Ocean Res; World Climate Res Programme; UN Off Outer Space Affairs. THE BOULEVARD LANGFORD LANE KIDLINGTON, OXFORD OX5 1GB, ENGLAND: PERGAMON PRESS LTD; 1998. p. 689–692.
30 Chen JM . Evaluation of Vegetation Indices and a Modified Simple Ratio for Boreal Applications. Canadian Journal of Remote Sensing. 1996;22 (3 ):229–242. doi: 10.1080/07038992.1996.10855178
31 LIU H , HUETE A . A FEEDBACK BASED MODIFICATION OF THE NDVI TO MINIMIZE CANOPY BACKGROUND AND ATMOSPHERIC NOISE. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING. 1995;33 (2 ):457–465. doi: 10.1109/36.377946
32 Huete A , Didan K , Miura T , Rodriguez E , Gao X , Ferreira L . Overview of the radiometric and biophysical performance of the MODIS vegetation indices. REMOTE SENSING OF ENVIRONMENT. 2002;83 (1-2 ):195–213. doi: 10.1016/S0034-4257(02)00096-2
33 Jiang Z , Huete AR , Didan K , Miura T . Development of a two-band enhanced vegetation index without a blue band. REMOTE SENSING OF ENVIRONMENT. 2008;112 (10 ):3833–3845. doi: 10.1016/j.rse.2008.06.006
34 Rondeaux G , Steven M , Baret F . Optimization of soil-adjusted vegetation indices. REMOTE SENSING OF ENVIRONMENT. 1996;55 (2 ):95–107. doi: 10.1016/0034-4257(95)00186-7
35 COVER T , HART P . NEAREST NEIGHBOR PATTERN CLASSIFICATION. IEEE TRANSACTIONS ON INFORMATION THEORY. 1967;13 (1 ):21+. doi: 10.1109/TIT.1967.1053964
36 GEVA S , SITTE J . ADAPTIVE NEAREST NEIGHBOR PATTERN-CLASSIFICATION. IEEE TRANSACTIONS ON NEURAL NETWORKS. 1991;2 (2 ):318–322. doi: 10.1109/72.80344 18276387
37 MURPHY O . NEAREST NEIGHBOR PATTERN-CLASSIFICATION PERCEPTRONS. PROCEEDINGS OF THE IEEE. 1990;78 (10 ):1595–1598. doi: 10.1109/5.58344
38 KOUTROUMBAS K, KALOUPTSIDIS N. NEAREST NEIGHBOR PATTERN CLASSIFICATION NEURAL NETWORKS. In: 1994 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOL 1-7. IEEE, NEURAL NETWORKS COUNCIL; IEEE, ORLANDO SECT. 345 E 47TH ST, NEW YORK, NY 10017: I E E E; 1994. p. 2911–2915.
39 COVER T . CITATION CLASSIC—NEAREST NEIGHBOR PATTERN-CLASSIFICATION. CURRENT CONTENTS/ENGINEERING TECHNOLOGY & APPLIED SCIENCES. 1982;(13 ):20.
40 Zargar A , Sadiq R , Naser B , Khan FI . A review of drought indices. ENVIRONMENTAL REVIEWS. 2011;19 :333–349. doi: 10.1139/a11-013
41 Tsialtas JT , Maslaris N . Sugar beet response to N fertilization as assessed by late season chlorophyll and leaf area index measurements in a semi-arid environment. INTERNATIONAL JOURNAL OF PLANT PRODUCTION. 2008;2 (1 ):57–69.
42 Yolcu S , Alavilli H , Ganesh P , Panigrahy M , Song K . Salt and Drought Stress Responses in Cultivated Beets (Beta vulgaris L.) and Wild Beet (Beta maritima L.). PLANTS-BASEL. 2021;10 (9 ). doi: 10.3390/plants10091843 34579375
43 Wisniewska A , Andryka-Dudek P , Czerwinski M , Choluj D . Fodder beet is a reservoir of drought tolerance alleles for sugar beet breeding. PLANT PHYSIOLOGY AND BIOCHEMISTRY. 2019;145 :120–131. doi: 10.1016/j.plaphy.2019.10.031 31677543
44 Li W , Lin M , Li J , Liu D , Tan W , Yin X , et al . Genome-wide association study of drought tolerance traits in sugar beet germplasms at the seedling stage. FRONTIERS IN GENETICS. 2023;14 . doi: 10.3389/fgene.2023.1198600 37547461
45 Alavilli H , Yolcu S , Skorupa M , Aciksoz SB , Asif M . Salt and drought stress-mitigating approaches in sugar beet (Beta vulgaris L.) to improve its performance and yield. PLANTA. 2023;258 (2 ). doi: 10.1007/s00425-023-04189-x 37358618
46 Wisniewska A , Andryka-Dudek P , Czerwinski M , Choluj D . Fodder beet is a reservoir of drought tolerance alleles for sugar beet breeding. PLANT PHYSIOLOGY AND BIOCHEMISTRY. 2019;145 :120–131. doi: 10.1016/j.plaphy.2019.10.031 31677543
47 Cao B , Li M , Liu X , Zhao J , Cao W , Lv Z . Many-Objective Deployment Optimization for a Drone-Assisted Camera Network. IEEE TRANSACTIONS ON NETWORK SCIENCE AND ENGINEERING. 2021;8 (4 ):2756–2764. doi: 10.1109/TNSE.2021.3057915
48 Aasen H , Burkart A , Bolten A , Bareth G . Generating 3D hyperspectral information with lightweight UAV snapshot cameras for vegetation monitoring: From camera calibration to quality assurance. ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING. 2015;108 :245–259. doi: 10.1016/j.isprsjprs.2015.08.002
49 Wang H , Zhang X , Jiang S . A Laboratory and Field Universal Estimation Method for Tire-Pavement Interaction Noise (TPIN) Based on 3D Image Technology. SUSTAINABILITY. 2022;14 (19 ). doi: 10.3390/su141912066
50 Zhao F , Wu H , Zhu S , Zeng H , Zhao Z , Yang X , et al . Material stock analysis of urban road from nighttime light data based on a bottom-up approach. ENVIRONMENTAL RESEARCH. 2023;228 . doi: 10.1016/j.envres.2023.115902 37059324
51 Zheng H , Fan X , Bo W , Yang X , Tjahjadi T , Jin S . A Multiscale Point-Supervised Network for Counting Maize Tassels in the Wild. PLANT PHENOMICS. 2023;5 . doi: 10.34133/plantphenomics.0100
52 Yin L , Wang L , Li T , Lu S , Tian J , Yin Z , et al . U-Net-LSTM: Time Series-Enhanced Lake Boundary Prediction Model. LAND. 2023;12 (10 ). doi: 10.3390/land12101859
