
==== Front
Sensors (Basel)
Sensors (Basel)
sensors
Sensors (Basel, Switzerland)
1424-8220
MDPI

10.3390/s24113346
sensors-24-03346
Article
Light and Displacement Compensation-Based iPPG for Heart-Rate Measurement in Complex Detection Conditions
https://orcid.org/0009-0002-5903-6967
Bi Shubo Conceptualization Methodology Validation Formal analysis Writing – review & editing Project administration Funding acquisition 12*
https://orcid.org/0000-0002-7400-8158
Wang Haipeng Conceptualization Software Investigation Writing – original draft Visualization Funding acquisition 1
Zhang Shuaishuai Validation Data curation Writing – review & editing 2
Baumgartner Christian Academic Editor
1 School of Intelligent Manufacturing, Jiangsu College of Engineering and Technology, Nantong 226006, China; wanghai463100@126.com
2 Department of Precision Mechanical Engineering, Shanghai University, Shanghai 200444, China; zshuai@shu.edu.cn
* Correspondence: 13764107770@163.com; Tel.: +86-1376-410-7770
23 5 2024
6 2024
24 11 334615 4 2024
08 5 2024
22 5 2024
© 2024 by the authors.
2024
https://creativecommons.org/licenses/by/4.0/ Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).
A light and displacement-compensation-based iPPG algorithm is proposed in this paper for heart-rate measurement in complex detection conditions. Two compensation sub-algorithms, including light compensation and displacement compensation, are designed and integrated into the iPPG algorithm for more accurate heart-rate measurement. In the light-compensation sub-algorithm, the measurement deviation caused by the ambient light change is compensated by the mean filter-based light adjustment strategy. In the displacement-compensation sub-algorithm, the measurement deviation caused by the subject motion is compensated by the optical flow-based displacement calculation strategy. A series of heart-rate measurement experiments are conducted to verify the effectiveness of the proposed method. Compared with conventional iPPG, the average measurement accuracy increases by 3.8% under different detection distances and 5.0% under different light intensities.

heart-rate measurement
iPPG
light compensation
displacement compensation
Basic Science Research Programs of the Higher Education Institutions of Jiangsu Province22KJD460002 23KJD410001 Basic Science Research Project of NantongJC12022030 Natural Science Research Foundation of JCETGYKY/2023/1 This research was funded by the Basic Science Research Programs of the Higher Education Institutions of Jiangsu Province, Grant No. 22KJD460002, Grant No. 23KJD410001; Basic Science Research Project of Nantong, Grant No. JC12022030; and the Natural Science Research Foundation of JCET, Grant No. GYKY/2023/1.
==== Body
pmc1. Introduction

Heart rate represents the number of heartbeats per minute (beat per minute, bpm), which is an effective indicator of human health [1]. There exists a high requirement for heart-rate measurement in multiple tasks such as household healthcare [2,3], medical treatment [4], and search and rescue [5]. Conventionally, the heart-rate measurement requires the subject to be equipped with contact measuring equipment. However, the subject cannot carry contact measurement devices in certain special environmental and task conditions. In such cases, the heart rate should be measured in a non-contact [6] way.

A series of sensors, including microwave radars, pressure sensors, and near-infrared cameras, can be used for non-contact heart-rate measurement. A wave of a fixed frequency shining on the object will produce a reflected wave of the same frequency. When the wave shines on the human heart (fixed-frequency vibration), a fixed-frequency mutation will be produced on the reflected wave according to the Doppler effect. In paper [7], a low power microwave radar is used to irradiate the human body, and the heart rate is measured by measuring the frequency mutation of the reflected wave. In paper [8], the pressure sensor is pasted onto the human body. The pressure sensor data will produce periodic fluctuations in the human heartbeat. The human heart rate can be calculated by analysis of the data fluctuations. The blood vessel pressure of human skin will change periodically when the human is in the heartbeat process. The temperature will also change with the same period. Paper [9,10] use a near-infrared camera to irradiate the human body and measure the human heart rate by measuring the temperature change period in a specific area. However, such sensors are not universal enough, which affects their popularization to some extent. By contrast, RGB video analysis-based heart-rate measurement has been widely used in recent years. Research [11] shows that RGB video analysis-based heart-rate measurement has the same accuracy as professional measurement equipment (such as radar).

iPPG (imaging Photoplethysmography) is the current mainstream RGB video analysis-based non-contact heart-rate measurement method [12,13,14]. In the method, exposed human skin images are captured and analyzed for pulse signal measurement. The pulse rate is equivalent to the heart rate. However, there still exist large differences in the signal-to-noise ratio (SNR) [15] by different detection and calculation strategies. The main reason for this is that different parts of the human body have different reflexes to ambient light, and the same area of the human body has different reflect abilities from different light spectrums [16,17,18]. In current studies, human facial [19,20] images are usually used for heart-rate measurement. In paper [21], specific spectral components are added to ambient light to improve the SNR. Another image registration algorithm is proposed in [22] to increase the SNR.

In paper [23], independent component analysis (ICA) was directly used to analyze the ambient reflected light of the R, G, and B channels, respectively. The method is simple but not robust enough to the subject motion, and the relationship between signals of different channels is unclear. Another principal component analysis (PCA) was proposed [24] to extract signals from the three channels. Compared with ICA, PCA can effectively reduce calculation time. In paper [25], the facial region was first divided into four sub-regions, and then the underlying signal set was obtained by the blind source separation of signals from different human skin regions. The heart-rate signal was recovered by spectral clustering of the underlying signal set. Based on this idea, a multi-objective optimization strategy was proposed [26] for signal selection in the blind source separation process. More accurate measurement results can be obtained based on this strategy.

The above research can achieve high measurement accuracy under ideal conditions. However, the accuracy will be significantly reduced when the ambient light changes or the subject moves. Paper [27] establishes two orthogonal chrominance signals based on the skin reflection model and uses the difference between the chrominance signals to cancel the specular reflection component to obtain a more accurate heart rate. Subsequently, the team proposed the CHROME (Chrominance-Based) [28] method and the color space normalization [29] method in turn to solve the interference caused by motion artifacts. In paper [30], joint blind source separation and ensemble empirical mode decomposition were used to reduce the interference caused by illumination. In paper [31], the image jitter is corrected based on a multi-task convolutional neural network, and the heart-rate signal is denoised by empirical mode decomposition and permutation entropy. Paper [32] proposes a gray level compensation algorithm to compensate for the change of gray level caused by the ambient light.

Based on the above methods, accurate heart-rate measurement can be achieved under small ambient light or displacement changes. However, when there is a relatively large change in the ambient light or the subject’s motion, the accuracy of the iPPG-based algorithm will be greatly disturbed. Based on this problem, a light and displacement-compensation-based iPPG algorithm is proposed in this paper. The method takes ordinary RGB video data as input to achieve the accurate measurement of human heart rate. Two sub-algorithms are designed and integrated into the conventional iPPG algorithm: the light-compensation sub-algorithm and the displacement-compensation sub-algorithm. The proposed method can better adapt to complex detection conditions. Firstly, the measurement deviation caused by the ambient light change is compensated by a light compensator. Secondly, the measurement deviation caused by the subject motion is compensated by a displacement compensator. The optical flow method [33,34] is used for the displacement calculation. A series of experiments in different detection conditions are conducted to verify the effectiveness of the proposed method. The experimental results show that the heart-rate measurement method proposed in this paper can effectively improve the accuracy of heart-rate measurement.

The rest of this paper is organized as follows: Section 2 details the basic procedure of the proposed method. The four phases of the proposed method are detailed in the later four sections (Section 3, Section 4, Section 5, and Section 6), respectively. Experiments are conducted in Section 7. Section 8 concludes the paper.

2. Overview of the Heart-Rate Measurement

Shown in Figure 1 is the heart-rate measurement flow chart. The method takes RGB video as input. The RGB video frame rate should be no less than 30 fps (frames per second), and the duration time should be no less than 20 s.

The whole process consists of four stages. Firstly, a series of spatial processing, including Gaussian smoothing, skin-color detection, and color decomposition, are conducted. Secondly, a light-compensation algorithm is proposed to compensate for the skin-reflect light changes caused by the ambient light change. The skin-reflect lights of the R, G, and B channels are compensated, respectively. Thirdly, a displacement-compensation algorithm is designed to compensate for the light intensity changes caused by the subject’s motion. The Lucas–Kanade(LK) optical flow algorithm is used for the subject displacement calculation. Finally, a band-pass filter is embedded in the CHROME algorithm for heart-rate measurement.

3. Spatial Processing

3.1. Gaussian Smoothing

In spatial processing, the Gaussian smoothing is first applied to all the frames to reduce image noise. The Gaussian function is defined as:(1) G(x,y)=12πσ2e−x2+y22σ2,

where σ is the standard deviation, which is set to 1 in this paper. The intensity value of each pixel is updated to the average intensity value of itself and the nearby elements multiplied by a certain weight, w. (2) I′(x,y)=∑i=04∑j=04wij×I(x+i−2,y+j−2)25,

where (x,y) is the initial intensity value of pixel (x,y) and I′(x,y) is the updated intensity value of I(x,y). (3) w=0.0030.0130.0220.0130.0030.0130.0590.0970.0590.0130.0220.0970.1590.0970.0220.0130.0590.0970.0590.0130.0030.0130.0220.0130.003

3.2. Skin-Color Detection Color Decomposition

H component of the HSV (Hue, Saturation, Value) color space and Cb and Cr components of the YCbCr space are selected for skin-color detection. The following constraints are designed:(4) 1≤H≤2377≤Cb≤127133≤Cr≤173

Shown in Figure 2 is the skin detection result. It can be seen that the human facial region is successfully distinguished from the other areas. Finally, all the pixels in all the frames are decomposed into the red, green, and blue components, respectively. (5) I(x,y)∈{R(i,j),G(i,j),B(i,j)},

where R(x,y), G(x,y), and B(x,y) are the red, green, and blue component of pixel (x,y), respectively.

4. Light Compensation

4.1. Light-Compensation Algorithm

A light compensator (see Algorithm 1) is proposed to compensate for the pixel intensity change caused by the ambient light change. Shown in the above algorithm is the process of the light-compensation algorithm. In the algorithm, the pixel intensities of the R, G, and B channels are compensated independently. The light-compensation algorithm assumes that the mean intensity value of any pixel with a fixed size is constant. Firstly, a mean filter with a window size of 2a×2b is applied to all the frames:(6) gn(i,j)=∑p=−aa∑q=−bbIt′(i+p,j+q)2a×2b,t∈[1,N],

where gn(i,j) is the mean pixel intensity of the area with the size of 2a×2b, which is constant to C (the constant). The center coordinates of the area is (i,j); n is the order of frames. (7) gn(i,j)∈{Rn(i,j),Gn(i,j),Bn(i,j)}

Algorithm 1: Light-compensation sub-algorithm	
Input: R = {R1, …, RN}, G = {G1, …, GN}, B = {B1, …, BN};	
/ / N represents the number of frames	
Output: R*={R1*,…,RN*},G*={G1*,…,GN*},B*={B1*,…,BN*};	
	

The intensities of each pixel in each frame are then added with the difference between gn(i,j) and g1(i,j). (8) In*(i,j)=In′(i,j)+gn(i,j)−g1(i,j),

where In*(i,j) is the compensated light intensities of pixel (i,j).

4.2. Results of Light Compensation

Shown in Figure 3 is the light-compensation result. The upper shows the snapshots of the RGB video (20 s), and the lower shows the filtered curves. The red curve and green curve represent the pixel intensities with and without light compensation, respectively. The shaded area between the two curves represents the compensation values. It can be seen from the figure that the filtered curve has a large deviation relative to the initial state without light compensation. In the compensated curve, the deviation is eliminated.

5. Displacement Compensation

The LK algorithm is first used to evaluate the specific pixel’s displacement between any adjacent frames, and then the displacement is compensated for each pixel on each frame. In the LK algorithm, three typical assumptions are first introduced:

Constant Brightness: Pixels of the target image in the scene appear to be unchanged as they move from frame to frame.

Temporal Persistence (Small Movement): The motion of the objects on the image varies slowly over time.

Spatial Consistency: Adjacent points on the same surface in the scene have similar motion and are projected relatively close to the image plane.

Suppose I(x,y,t) is the pixel value of the pixel point (x,y) at time t. After time dt, the subject’s specific point at pixel coordinate (x,y) moves to (x+dx,y+dy). According to the first assumption, there is:(9) I(x,y,t)=I(x+dx,y+dy,t+dt).

According to the second assumption, the motion of the subjects on the image is small. Hence, the function I(x+dx,y+dy,t+dt) can be expanded at (x,y,t) using Taylor’s formula. (10) I(x+dx,y+dy,t+dt)=I(x,y,t)+∂I∂x+∂I∂y+∂I∂t+ϵ,

where ϵ represents the higher-order remainder of Taylor’s formula, which can be ignored. Therefore, there is:(11) ∂I∂x+∂I∂y+∂I∂t=0.

Which is equivalent to:(12) ∂I∂x∂x∂t+∂I∂y∂y∂t+∂I∂t=0,

where (∂x∂t,∂y∂t)=(u,v) is the optical flow of the pixel to be resolved. The velocity components along the x and y directions are denoted as u and v, respectively. The above formula can be written as:(13) IxIyuv=−It.

This formula shows that the temporal pixel value differential at the same coordinate position is the production of the spatial pixel value differential and the velocity relative to the observer at that position. However, as the solution of the above binary linear equation is not unique, other constraints are required.

According to the third assumption, it can be assumed that within a window of size m×m, the optical flow of the image is a constant value. Hence, the following equation can be obtained:(14) Ix1Iy1Ix2Iy2⋮⋮IxmIym=−It1It2⋮Itm⇔AV→=−b.

The final result can be calculated by:(15) uv=∑i=1nIxi2∑i=1nIxiIyi∑i=1nIxiIyi∑i=1nIyi2−1−∑i=1nIxiIti−∑i=1nIyiIti.

Displacement measurement experiments are conducted to verify the effectiveness of the algorithm. The results are shown in Figure 4. Select three random points on the human body in the video and track the movement. The trajectory curves are shown as the color lines. It can be seen that the optical flow method-based displacement measurement algorithm can accurately track the coordinates of specific pixels when the subject moves, then the light intensity change of a specific point on the video can be obtained.

6. Heart-Rate Measurement

6.1. Design of the Filter

The human heart rate ranges approximately from 1.0 Hz to 1.667 Hz. In this paper, a Butterworth band-pass filter is used to filter out the high-frequency and low-frequency noises. The magnitude of the frequency response (first order) is given by (16) H(jω)=jωτ11+jωτ11jωτ2

(17) W1,W2=1τ1,1τ2,

where the passband is [W1,W2]. The filter performance is influenced by two aspects: the order of the filter and the range of the filter passband.

Shown in Figure 5 is the frequency response of the band-pass filter. The red zone represents the range of the human heart rate. The order is 256 on the left curve, and the passband ranges from 0.8 to 1.9 on the right curve. It can be seen that the stopband falls faster with the increase of the filter order, and the filter pass width is widened as the passband widens. Based on the above analysis, a 256th-order band-pass filter with a passband from 0.8 Hz to 1.9 Hz is utilized to let through the maximum frequency of human heart rate without attenuation.

6.2. Color Decomposition

This paper uses the CHROME algorithm to measure the robustness. First, decompose the light as follows:(18) Ck=ICk(ρCdc+ρCk+Sk),

where Ck is the C channel intensity of a particular pixel in graph k. C∈{R,G,B}. ICk represents the intensity of Ck in the camera’s exposure stage. ρCdc represents the fixed coefficient of reflection of light from the skin surface, which is fixed but different in different channels: ρRdc>ρGdc>ρBdc. ρCk represents the component of dynamic disturbance caused by the pulse. Sk represents the specular reflection component due to motion, which is the same in different channels.

The CHROME algorithm combines the signals of the R, G, and B channels in different proportions to eliminate the static component and the additional specular reflection component and outputs the pulsating diffuse reflection component. The combination mode is as follows:(19) Xs=3R(n)−2G(n)Ys=1.5R(n)+G(n)−1.5B(n),

where R(n), G(n), and B(n) are the normalized signals of the R, G, and B channel. Xs and Ys are filtered by the band-pass filter, respectively, after the filters Xf and Yf are obtained. Finally, the heart-rate signal is formed by the following formula:(20) S=Xf−αYf.

The filtering results are shown in Figure 6. The three figures on the left are the partial filtering results of the R, G, and B channels, respectively. The figure on the upper right shows the result of Xf and Yf, and the figure on the lower right shows the value of S. As can be seen from the figure, the filtered data of the R, G, and B channels fluctuate greatly, which makes it difficult to filter effective heartbeat signals from them. The fluctuation of S obtained by Xf and Yf is relatively uniform. Follow-up heart-rate data extraction can be performed.

6.3. Heart-Rate Measurement

(21) cycle=∑i=1ncyclein

The time interval between any two adjacent peaks in the pixel value curve is regarded as a heartbeat cycle, and the average of all heartbeat cycles is considered as the heart rate of the human. As shown in Equation (21), cyclei is the ith heartbeat cycle, and cycle is the average heart rate of the human.

Shown in Figure 7 is the pixel value of a specific point on the RGB video. The horizontal coordinate represents the time, and the vertical coordinate represents the pixel value after standardization. The data have been filtered and standardized. The processed data values are between −0.5 and 0.5. It can be seen from the figure that the curve has obvious periodic characteristics. The height of each wave crest and trough are not the same; the main reason for this is that there is a certain difference in the heartbeat amplitude of each human. The time between the two peaks (or troughs) in the curve is the heartbeat cycle of the human hour. To ensure measurement accuracy, a 20-s video is collected to calculate the average heartbeat cycle. It can be seen that a total of 18 complete heartbeat cycles exist in the curve. The mean cycle time is 18.82 s. Hence, the heart rate is 60/(18.82/18) = 57.4 bpm.

7. Experiment

The experimental scene is shown in Figure 8. A built-in camera of a laptop computer is used for the subject’s facial videos collection. The subject sits in front of the laptop with their face facing the camera of the laptop to facilitate image acquisition. The size of the frame is 1920 × 1080 pixels, and the frame rate is 30 fps. Video capture duration is no less than 20 s. The subjects are asked to remain as still as possible during the data collection. A total of five subjects participated in the data collection. Meanwhile, a medical heart-rate measurement device is used as the control group. The measurement device is fixed on the human’s arm at the same horizontal height as the human’s heart. The data and images of the control group are collected at the same time. Each subject captured five videos in each set of experimental conditions (specific light and detection distance). The real-time heart rate of the subjects during the collection of each video is recorded at the same time.

Shown in Figure 9 are the heart-rate measurement results under various human–camera distances. The light intensity is approximately 300 lux in this group. It can be seen that the subjects’ heartbeat fluctuates at different distance conditions, but the overall change is small. The heart rate calculated by the proposed method is less than the actual heart rate. The main reason for this is that part of the human heartbeat is light and filtered by filters. There exists a large deviation in heart-rate measurement by all the methods. The average measurement accuracy is 7.4% by the traditional iPPG-based algorithm, and the average measurement accuracy increases to 3.6% with the proposed method. The results show that the proposed method can increase the heart-rate measurement accuracy at any human–camera distances.

Figure 10 show the variances under various human–camera distances. The greater the variance, the greater the fluctuation and the worse the stability of the measurement results. It can be seen from the results that the measurement results using the conventional IPPG-based algorithm have a large fluctuation, which is much higher than that of the proposed method. The data fluctuation is suppressed to a large extent using the proposed method. At the same time, it can be seen that the human–camera distance has little influence on the measurement accuracy under the two methods. This means that the method proposed can achieve high-precision heart-rate measurements at a distance of less than 3 m. Generally, the average measurement accuracy is improved by 3.8% at different distances by the proposed compensation algorithm.

Shown in Figure 11 are the heart-rate measurement results under different light intensities. The human–camera distance in this group is 1.0 m. It can be seen from the figure that the subjects’ heart rates fluctuate to some extent under different lighting conditions, but the overall change was small. At the same time, with the increase in light intensity the difference between the measured results and the real heart rate gradually decreased. The main reason for this is that there exists more noise under low light conditions, and some image noise cannot be effectively filtered out, which results in a high heart-rate measurement. The environmental noise is effectively filtered with the increase of light intensities. On the contrary, the weaker heartbeat of the human part was filtered out by the filter, and the measured value was slightly lower than the true value. On the whole, the average measurement accuracy is 7.8% without compensation, and the average measurement accuracy increases to 2.8% by the proposed method.

Figure 12 shows the variances under different light intensities. It can also be seen that large variances exist in heart-rate measurement by the iPPG-based algorithm. The variance is greatly suppressed by the proposed method. In the case of low light intensity, the algorithm based on iPPG is more sensitive to light, and the variance is larger under low-light conditions, indicating that the measurement results fluctuate greatly under low-light conditions. However, the proposed method can guarantee a low variance under any illumination conditions, indicating a good consistency of measurement results.

8. Discussion and Conclusions

Aimed at the problem of the low robustness of current heart-rate measurement methods in complex detection conditions, a light and displacement-compensation-based iPPG algorithm is proposed in this paper for heart-rate measurement. The method consists of four main procedures: spatial processing, light compensation, displacement compensation, and measurement. Only an RGB video with a human face is required in this method.

The input video is first processed by a Gaussian fuzzy filter, and then the video is decomposed frame by frame. The light-compensation module is used to compensate for the influence caused by ambient light on the measurement results. Displacement compensation is used to compensate for the influence caused by the subject’s movement in a small range. To measure the displacement of the humans, a displacement measurement method based on the optical flow method is introduced in this study. The measurement deviation caused by the ambient light change and subject motion is compensated by the two compensation sub-algorithms. In the final measurement stage, the CHROME algorithm is first used to decompose and reassemble the image, then the band-pass filter is used to filter the input data frame by frame and pixel by pixel, and the clutter outside the human heart-rate range is filtered out. Finally, the heart rate is calculated.

A series of experiments in different detection conditions (various light intensities and various human–camera distances) are conducted to verify the effectiveness of the proposed method. Compared with traditional methods, the proposed method can achieve higher measurement accuracy and lower measurement variance. Specifically, the following conclusions are drawn:

(1) The average measurement accuracy is improved by 3.8% by the proposed compensation algorithm under different distance conditions.

(2) The average measurement accuracy is improved by 5.0% by the proposed compensation algorithm under different light intensities.

(3) To achieve a higher accuracy of heart-rate measurement, the detection distance should not exceed 2 m and the lighting intensity should not be less than 200 lux.

The proposed method can be used for heart-rate measurement under small movements of the human body. However, when the motion range of the human body is large, the processing capacity of the optical flow method makes it unable to accurately measure the heart rate. In future work, the key points of the face should be identified under large-scale human movement, and then the heart-rate measurement could also be realized under large-scale human movement.

Author Contributions

Conceptualization, S.B. and H.W.; methodology, S.B.; software, H.W.; validation, S.B. and S.Z.; formal analysis, S.B.; investigation, H.W.; data curation, H.W. and S.Z.; writing—original draft preparation, H.W.; writing—review and editing, S.B. and S.Z.; visualization, H.W.; project administration, S.B.; funding acquisition, S.B. and H.W. All authors have read and agreed to the published version of the manuscript.

Informed Consent Statement

Informed consent was obtained from all subjects involved in the study.

Data Availability Statement

Raw data underlying the results presented in this paper are available from the authors upon reasonable request.

Conflicts of Interest

The authors declare no conflicts of interest.

Abbreviations

The following abbreviations are used in this manuscript: bpm	beat per minute	
iPPG	imaging Photoplethysmography	
SNR	signal-to-noise ratio	
ICA	independent component analysis	
PCA	principal component analysis	
CHROME	Chrominance-Based	
fps	frames per second	
LK	Lucas–Kanade	

Figure 1 Heart-rate measurement flow chart.

Figure 2 Result of skin-color detection.

Figure 3 Results of light compensation.

Figure 4 Displacements of specific pixels in the video.

Figure 5 The frequency response of the band-pass filter.

Figure 6 Color decomposition of one specific pixel.

Figure 7 Pixel value of one specific pixel.

Figure 8 The experimental scene.

Figure 9 Heart-rate measurement results under various human–camera distances.

Figure 10 Variances under various human–camera distances.

Figure 11 Heart-rate measurement results under different light intensities.

Figure 12 Variances under different light intensities.

Disclaimer/Publisher’s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.
==== Refs
References

1. Bansal P. Malik M. Kundu R. Smart heart rate monitoring system Proceedings of the 2018 IEEMA Engineer Infinite Conference (eTechNxT) New Delhi, India 13–14 March 2018 1 4 10.1109/ETECHNXT.2018.8385347
2. Luo J. Yan Z. Guo S. Chen W. Recent Advances in Atherosclerotic Disease Screening Using Pervasive Healthcare IEEE Rev. Biomed. Eng. 2021 15 293 308 10.1109/RBME.2021.3081180 34003754
3. Lakshmi Devi R. Kalaivani V. Velammal B.L. Adaptive neuro-fuzzy inference healthcare system for cardiac arrhythmia detection using heart rate variability features Advances in Automation, Signal Processing, Instrumentation, and Control Springer Singapore 2021 2167 2174 Available online: https://link.springer.com/chapter/10.1007%2F978-981-15-8221-9_201 (accessed on 21 May 2024)
4. Georgiou K. Larentzakis A.V. Khamis N.N. Alsuhaibani G.I. Alaska Y.A. Giallafos E.J. Can wearable devices accurately measure heart rate variability? A systematic review Folia Medica 2018 60 7 20 10.2478/folmed-2018-0012 29668452
5. Lambert K. Merci B. Gryspeert C. Jekovec N. Search & rescue operations during interior firefighting: A study into crawling speeds Fire Saf. J. 2021 121 103269 10.1016/j.firesaf.2020.103269
6. Khong W.L. Mariappan M. Chong C.S. Contact and non-contact heart beat rate measurement techniques: Challenges and issues Pertanika J. Sci. Technol. 2021 29 1707 1732 10.47836/pjst.29.3.03
7. Li C. Peng Z. Huang T.Y. Fan T. Wang F.K. Horng T.S. Munoz-Ferreras J.M. Gomez-Garcia R. Ran L. Lin J. A review on recent progress of portable short-range noncontact microwave radar systems IEEE Trans. Microw. Theory Tech. 2017 65 1692 1706 10.1109/TMTT.2017.2650911
8. Chen S. Wu N. Ma L. Lin S. Yuan F. Xu Z. Li W. Wang B. Zhou J. Noncontact heartbeat and respiration monitoring based on a hollow microstructured self-powered pressure sensor ACS Appl. Mater. Interfaces 2018 10 3660 3667 10.1021/acsami.7b17723 29302965
9. Guo K. Zhai T. Pashollari E. Varlamos C.J. Ahmed A. Islam M.N. Contactless vital sign monitoring system for heart and respiratory rate measurements with motion compensation using a near-infrared time-of-flight camera Appl. Sci. 2021 11 10913 10.3390/app112210913
10. Kurihara K. Sugimura D. Hamamoto T. Non-contact heart rate estimation via adaptive rgb/nir signal fusion IEEE Trans. Image Process. 2021 30 6528 6543 10.1109/TIP.2021.3094739 34260354
11. Ren L. Kong L. Foroughian F. Wang H. Theilmann P. Fathy A.E. Comparison study of noncontact vital signs detection using a Doppler stepped-frequency continuous-wave radar and camera-based imaging photoplethysmography IEEE Trans. Microw. Theory Tech. 2017 65 3519 3529 10.1109/TMTT.2017.2658567
12. Hassan H. Zulkifli M.S.A. Suhaime M.A.M. Kaidi H.M. Bakar R.A. A real-time non-contact heart rate measurement based on imaging photoplethysmography (ippg)-power spectral density (psd) Proceedings of the 2021 IEEE Symposium on Industrial Electronics & Applications (ISIEA), IEEE Langkawi Island, Malaysia 10–11 July 2021 1 6 10.1109/ISIEA51897.2021.9509987
13. Zhang C. Tian J. Li D. Hou X. Wang L. Comparative study on the effect of color spaces and color formats on heart rate measurement using the imaging photoplethysmography (IPPG) method Technol. Health Care 2022 30 391 402 10.3233/THC-THC228036 35124614
14. Wieler M.E. Murphy T.G. Blecherman M. Mehta H. Bender G.J. Infant heart-rate measurement and oxygen desaturation detection with a digital video camera using imaging photoplethysmography J. Perinatol. 2021 41 1725 1731 10.1038/s41372-021-00967-1 33649437
15. Zaunseder S. Vehkaoja A. Fleischhauer V. Signal-to-noise ratio is more important than sampling rate in beat-to-beat interval estimation from optical sensors Biomed. Signal Process. Control. 2022 74 103538 10.1016/j.bspc.2022.103538
16. Matsumura K. Toda S. Kato Y. RGB and near-infrared light reflectance/transmittance photoplethysmography for measuring heart rate during motion IEEE Access 2020 8 80233 80242 10.1109/ACCESS.2020.2990438
17. Lin Y.C. Lin Y.H. A study of color illumination effect on the SNR of rPPG signals Proceedings of the 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), IEEE Jeju, Republic of Korea 11–15 July 2017 4301 4304 10.1109/EMBC.2017.8037807
18. Kim G. Park K. Hwang K.J. Jin S. Highly sunlight reflective and infrared semi-transparent nanomesh textiles ACS Nano 2021 15 15962 15971 10.1021/acsnano.1c04104 34661392
19. Scherpf M. Ernst H. Misera L. Malberg H. Schmidt M. Skin Segmentation for Imaging Photoplethysmography Using a Specialized Deep Learning Approach Proceedings of the 2021 Computing in Cardiology (CinC) Brno, Czech Republic 13–15 September 2021 Volume 48 1 4 10.23919/CinC53138.2021.9662682
20. Woyczyk A. Fleischhauer V. Zaunseder S. Skin segmentation using active contours and gaussian mixture models for heart rate detection in videos Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops Seattle, WA, USA 14–19 June 2020 312 313 10.1109/CVPRW50498.2020.00164
21. Kamshilin A.A. Zaytsev V.V. Mamontov O.V. Novel contactless approach for assessment of venous occlusion plethysmography by video recordings at the green illumination Sci. Rep. 2017 7 1 9 10.1038/s41598-017-00552-7 28127051
22. Iakovlev D. Hu S. Dwyer V. Frame registration for motion compensation in imaging photoplethysmography Sensors 2018 18 4340 10.3390/s18124340 30544812
23. Hashemi-Nasab F.S. Parastar H. Vis-NIR hyperspectral imaging coupled with independent component analysis for saffron authentication Food Chem. 2022 393 133450 10.1016/j.foodchem.2022.133450 35751218
24. Inagawa A. Kimura M. Uehara N. Total protein assay by PCA-based RGB-spectrum conversion methods with smartphone-acquired digital images Anal. Sci. 2022 38 869 880 10.1007/s44211-022-00107-5 35325437
25. Qi H. Guo Z. Chen X. Video-based human heart rate measurement using joint blind source separation Biomed. Signal Process. Control 2017 31 309 320 10.1016/j.bspc.2016.08.020
26. Macwan R. Benezeth Y. Mansouri A. Remote photoplethysmography with constrained ICA using periodicity and chrominance constraints Biomed. Eng. Online 2018 17 1 22 10.1186/s12938-018-0450-3 29310661
27. Pai A. Veeraraghavan A. Sabharwal A. HRVCam: Robust camera-based measurement of heart rate variability J. Biomed. Opt. 2021 26 022707 10.1117/1.JBO.26.2.022707 33569935
28. De Haan G. Van Leest A. Improved motion robustness of remote-PPG by using the blood volume pulse signature Physiol. Meas. 2014 35 1913 10.1088/0967-3334/35/9/1913 25159049
29. Huang R.Y. Dung L.R. A motion-robust contactless photoplethysmography using chrominance and adaptive filtering Proceedings of the IEEE Biomedical Circuits and Systems Conference (BioCAS) Atlanta, GA, USA 22–24 October 2015 1 4 10.1109/BioCAS.2015.7348451
30. Cheng J. Chen X. Xu L. Wang Z.J. Illumination variation-resistant video-based heart rate measurement using joint blind source separation and ensemble empirical mode decomposition IEEE J. Biomed. Health Inform. 2016 21 1422 1433 10.1109/JBHI.2016.2615472 27723609
31. Yue H. Li X. Cai K. Chen H. Liang S. Wang T. Huang W. Non-contact heart rate detection by combining empirical mode decomposition and permutation entropy under non-cooperative face shake Neurocomputing 2020 392 142 152 10.1016/j.neucom.2018.09.100
32. Li S. Wang H. Wang S. Zhang S. Life detection and non-contact respiratory rate measurement in cluttered environments Multimed. Tools Appl. 2020 79 32065 32077 10.1007/s11042-020-09510-4
33. Xu H. Zhang J. Cai J. Rezatofighi H. Tao D. Gmflow: Learning optical flow via global matching Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition New Orleans, LA, USA 18–24 June 2022 8121 8130
34. Zhai M. Xiang X. Lv N. Kong X. Optical flow and scene flow estimation: A survey Pattern Recognit. 2021 114 107861 10.1016/j.patcog.2021.107861
