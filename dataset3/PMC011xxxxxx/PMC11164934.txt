
==== Front
Sci Rep
Sci Rep
Scientific Reports
2045-2322
Nature Publishing Group UK London

38858487
64018
10.1038/s41598-024-64018-3
Article
Sampling unknown large networks restricted by low sampling rates
Jiao Bo jiaoboleetc@outlook.com

https://ror.org/00mcjh785 grid.12955.3a 0000 0001 2264 7233 School of Information Science and Technology, Xiamen University Tan Kah Kee College, Zhangzhou, 363123 Fujian China
10 6 2024
10 6 2024
2024
14 1334025 2 2024
4 6 2024
© The Author(s) 2024
https://creativecommons.org/licenses/by/4.0/ Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.
Graph sampling plays an important role in data mining for large networks. Specifically, larger networks often correspond to lower sampling rates. Under the situation, traditional traversal-based samplings for large networks usually have an excessive preference for densely-connected network core nodes. Aim at this issue, this paper proposes a sampling method for unknown networks at low sampling rates, called SLSR, which first adopts a random node sampling to evaluate a degree threshold, utilized to distinguish the core from periphery, and the average degree in unknown networks, and then runs a double-layer sampling strategy on the core and periphery. SLSR is simple that results in a high time efficiency, but experiments verify that the proposed method can accurately preserve many critical structures of unknown large scale-free networks with low sampling rates and low variances.

Keywords

Graph sampling
Unknown network
Low sampling rate
Scale-free network
Subject terms

Complex networks
Information theory and computation
issue-copyright-statement© Springer Nature Limited 2024
==== Body
pmcIntroduction

Graph sampling extracts nodes or edges to create subgraphs representing an original network, which is often used as pre-processing before data mining to reduce the scale of datasets1–5 or as post-processing after optimization to represent the original network more accurately6–9. The former usually adopts traversal-based samplings5 that simulate walkers travelling on unknown networks based on the neighbor information of the nodes they are accessing. The traversal-based samplings5 are time efficient, which enables complex mining algorithms, such as graph convolutional networks1, subgraph pattern mining2,3 and network embedding4, to be applied to networks with more than one million nodes. The latter adopts samplings that construct optimization models6–9 to minimize the difference between known original networks and sampled subgraphs. Approximation algorithms used for solving the optimization models are powerful in representing objective structures of the original networks but are time-consuming6–9. This paper focuses on the traversal-based samplings in pre-processing systems that travel on unknown original networks, and intents to represent more important structures of the networks with high time efficiency.

Metropolis–hastings random walk (MHRW)10 and simple random walk (SRW)10,11 are two classical traversal-based samplings. Based on Markov chain random models, MHRW is unbiased, which samples each node with uniform stationary distribution, whereas, SRW is biased, that is, the probability of a node being sampled is proportional to its degree10,11. This paper focuses on ubiquitous scale-free networks exhibiting core-periphery structures, which consist of a dense core and a sparse periphery12–15. The core determines many important structures of the networks, such as low-diameter; however, it is almost ignored by unbiased samplings since the number of nodes in the core is extremely small. On the contrary, biased samplings preserve more structures determined by the core nodes that have high-degrees. However, the above-mentioned node sampling probability of SRW corresponds to the convergence state of Markov chain11.

Sampling rate is defined as the ratio of the number of nodes (or edges) between sampled and original networks5. Low sampling rates are needed to improve time efficiency on large networks, but also make it difficult to achieve the convergence of Markov chain. In the core-periphery structures of scale-free networks, each core node is well-connected by periphery nodes but the latter are not well-connected to each other12–15, that is, the walkers of biased samplings are more likely to be attracted to the core under constraints of low sampling rates, resulting in loss of structures related to the periphery that occupies the vast majority of nodes in the networks. Thus, this paper proposes a sampling for unknown networks at low sampling rates, called SLSR, objective to achieve a balanced sampling on the core-periphery structures.

The organization of this paper is as follows: Section "Problem formulation and design principles" investigates the problem formulation and design principles of SLSR. Section "Random node sampling for evaluating parameters" provides a random node sampling to evaluate the average degree (AD) and degree threshold (DT) of original unknown large networks. Section "Unknown network sampling SLSR" designs the traversal-based sampling SLSR. Specifically, SLSR starts by the AD and DT evaluation, then limits the sampling process to the periphery using the DT, and designs a bisection method constrained by the AD to preserve the core structure. Section "Evaluation" evaluates SLSR with related methods and verifies that SLSR can capture many critical structures except for degree, including shortest path length, clustering, graph spectrum, centrality and communities.

The contributions of this paper are as follows:Analysis of the advantages of the random node sampling in capturing the DT and its high time efficiency, as well as the shortcomings of the sampling in subgraph representation, such as, the loss of critical high-degree core nodes and periphery topological structure.

Designing a simple traversal-based sampling that only relies on node set and the adjacent node information of sampled nodes, without involving complex topological characteristics, but can preserve critical properties at low sampling rates. Simplicity corresponds to a high time efficiency that is important for pre-processing systems.

Analysis of entropy and variance of sampled subgraphs at low sampling rates. Assuming Ω is a sample space with n samples, then the probability of extracting a sample from Ω uniformly at random is 1/n, and the entropy of the probability distribution is H=logn=-∑1nlog1n. That is, with increasing n, the uncertainty measured by the entropy grows16. The traversal-based samplings randomly choose next node w from the adjacent nodes of a current node v, that is, the adjacent node set of the node v constructs a sample space for randomly choosing w. We prove that SLSR sharply reduces the scale of the sample space at most cases by a simple and deterministic bisection method (i.e., reduces the entropy), and experimentally verify that the reduced entropy can ensure the low variances of many critical statistics of the sampled SLSR subgraphs.

We experimentally obtain that, the smaller and denser the cores in original networks, the stronger the preference of the traditional traversal-based samplings for high-degree core nodes at low sampling rates, which is difficult to be mathematically proven by the Markov chain theory10, because the low sampling rates prevent the Markov chain random process from reaching convergence state.

Time efficiency and community visualization are analyzed in depth.

The codes of SLSR are provided at https://github.com/jiaoboleetc/SLSR.

Related work

Graph sampling on unknown networks

Node/edge-based samplings choose a set of nodes (or edges) at random and extract the subgraphs induced by the chosen nodes (or edges), including uniform samplings, such as random node (RN) and random edge (RE), and non-uniform samplings, such as random degree node (RDN) and random PageRank node (PRN)5,17. Specifically, nodes can be sampled proportional to the degree centrality by RDN5, and proportional to the PageRank weight by PRN5. Recently, Wang et al.18 investigated the relations between edges and their edge neighbors caused by the reconcile of scale-free and self-similarity, and proposed a series of sampling algorithms based on the relations, which can keep important statistical characteristics of original networks.

Traversal-based samplings start with one or more seeds and crawl on unknown original networks based on the neighbor information of the nodes they are accessing. Forest fire (FF), which is a variant of breadth first (BF) and snow ball (SB), performs superior in time efficiency since each node in the unknown networks is traversed no more than once19. FF starts by a random seed, then burns a fraction of its neighbors that have not been traversed, where the fraction is randomly drawn from a geometric distribution, and the process is recursively repeated for each burnt neighbor until the desired sample size is obtained5. SRW11 starts by a random seed, and moves from a node to one of its neighbors chosen uniformly at random, until the expected fraction of nodes is collected. In addition, more random walk samplings, namely, non-backtracking random walk (NBRW), circulated neighbor random walk (CNRW), and common neighbor awareness random walk (CNARW)20, have been proposed to reduce the asymptotic variance of sampled subgraphs and overcome the slow convergence of SRW, as simple random walker tends to be stuck in local loops20. The principles and pseudo codes of the three improved random walk samplings can be obtained in the recent review articles10,20. Rank degree (RD) is a multi-seed sampling21, which adopts a predetermined number of random starting seeds to avoid the sampling trapped locally, then iteratively explores top-k highest-degree neighbors of each seed and adds them to the seed set. Moreover, some samplings were designed to capture specific network structures, such as, community structure expansion (CSE)22. Recently, the node/edge-based and traversal-based samplings have become important tools for efficient network intervention and AD evaluation on large unknown networks23.

Stream-based samplings generate subgraphs from activity networks that can be treated as a stream of edges24,25. In the networks, besides the unknown topology, the node set and the neighbor information of any node are unobtainable.

Graph sampling on known networks

If all network information of a dataset is known, complex structures hidden in the dataset can be discovered in advance. Hong et al.6 first extracted precise structures, such as k-core, closeness, betweenness, and eigenvector centrality, from known original networks, and then reduced the scale of the networks under the guidance of the structures. Martin et al.8 created an optimization model for large-scale network reduction towards scale-free structure. Jiao et al.9 adopted a strategy of removing edges from known original networks one by one. However, a lower sampling rate means more edges need to be removed. Sampling on known networks helps preserve more precise structures, but usually comes at the cost of time6–9.

Problem formulation and design principles

Problem formulation

This paper focuses on simple, undirected, and scale-free original networks, in which self-loops, multi-edges, and direction of edges are ignored. We assume that the topological information of the original networks, such as, community, clique, and global statistical characteristics, is unknown. But we assume that the node set and the neighbors of sampled nodes can be accessed5,17–23. We intend to quickly obtain subgraphs representing the unknown large original networks. The notions used by our SLSR sampling are listed in Table 1.Table 1 Notions and descriptions.

Notions	Descriptions	
Gorg=Vorg,Eorg	An unknown original network Gorg where Vorg and Eorg respectively denote the node set and edge set. Please note that Gorg is a simple and undirected graph	
d¯org	The average degree of Gorg that can be evaluated by a random node sampling23	
d⃛org	A degree threshold of Gorg that can be evaluated by a random node sampling	
Norgv	The set of neighbor nodes of a sampled node v in Gorg, which can be obtained by the traversal-based samplings	
·	The cardinality of a set	
dorgv	The degree of a sampled node v in Gorg, where dorgv=Norgv	
S1-S2	A set consisting of elements that belong to S1 but not to S2, where S1 and S2 denote two sets	
RRN	A sampling rate of the random node sampling for evaluating AD and DT	
RSLSR	A sampling rate of the SLSR sampling	
Gsub=Vsub,Esub	A sampled subgraph of Gorg where Vsub⊆Vorg and Esub⊆Eorg	

Design principles

The classical Barabasi–Albert (BA) scale-free evolving network model26 confirms that the degree distribution of the network almost remains the same as the scale changes. Please note that the distribution only represents low-degrees of nodes in periphery, ignoring high-degrees of nodes in core, because the number of core nodes is extremely smaller than that of periphery nodes12–15. Based on the preferential attachment (PA) rule adopted by the BA model26, which attaches each newly-added node preferentially to high-degree nodes, the degrees of core nodes quickly grow with increasing network scale, that is, the larger an original network, the greater the difference in degree between the core and periphery nodes, which causes the biased samplings on large networks to be overly attracted to the core at low sampling rates. The degree distribution is an important metric and the existing biased samplings are good at capturing the metric under specific conditions17–22. Thus, the first principle P1 is to create a core-periphery framework in which the existing biased samplings continue to be used but are only limited to the periphery sampling, that is, the core, which hinders the capture of the degree distribution, is stripped off and processed separately.

During changes in a scale-free network, such as scale-reduction, the core has a low variability15. In addition, based on the fractal characteristic26, the communities of the network also represent core-periphery structures9,27. Specifically, the community cores are mainly located in the core of the network, that is, the network core represents the structure of community centers. Thus, the second principle P2 is to maximize the preservation of the connections in the network core.

Owing to sparse connections between periphery nodes, faster information exchange between these nodes depends on core nodes12–15. Specifically, based on the PA rule26, the higher the degree of a core node, the greater its probability of being connected by other newly-added periphery nodes, that is, the core node has stronger ability to shorten the path length between periphery nodes. Thus, the third principle P3 is to preserve a proportion of core neighbors with top highest degrees for each sampled periphery node, where the proportion can be determined by the AD of original networks that can be evaluated by a random node sampling23. Please note that the second and third principles are helpful in preserving the path length distribution.

The periphery is the main contributor of the clustering coefficient distribution since it occupies the vast majority of nodes in the network12–15. Based on the PA rule26, the neighbors of a periphery node tend to be located in the core, that is, the connections between high-degree core nodes has a significant impact on the distribution. Thus, the above-mentioned three principles marked as P1, P2, and P3 are helpful in preserving the distribution.

Random node sampling for evaluating parameters

Random node evaluation

Core-periphery detection27 refers to a partition of a network into two groups of nodes called core and periphery, which is a useful tool to realize P1. An important procedure of the detection is to provide rank orders of nodes for the partition. Many measures based on clique, community, centrality, and probability12–15,27, have been adopted for the rank. These complex measures can help improve detection accuracy, but are difficult to be quickly evaluated on unknown networks. Thus, we use a simple measure, namely degree, to rank the nodes, and adopt a random node sampling to evaluate the AD and DT of the unknown networks that are critical for P1 and P3. Specifically, nodes with degrees larger than DT are classified to the core, while other nodes are divided to the periphery. To clearly distinguish the core nodes and periphery nodes, the DT is determined by maximizing the number of edges connecting the two types of nodes.

In the above sampling, line 4 evaluates the AD of the unknown original network Gorg, and lines 5–12 evaluate the DT of Gorg. Our random node sampling is different from the RN sampling5 introduced in Section "Graph sampling on unknown networks" that generates a subgraph induced by randomly chosen nodes. Our sampling collects the degrees dorgv and neighbors Norgv of the randomly chosen nodes in Gorg, and evaluates the AD and DT based on the degrees and neighbors.

Analysis of the AD evaluation

Recently, Qi et al.23 confirmed the effectiveness of the random node sampling on the evaluation of AD. We further analyze the shortcomings of the sampling in subgraph representation.

All degrees existing in the com-Youtube network28 are ranked by decreasing order in Table 2, which shows that the top highest-degrees are related to only one or several nodes. Please note that the phenomenon in Table 2 is common in scale-free networks. With uniform distribution, the probability of a k-degree node being sampled is equal to Pk that is defined as the ratio of the number of k-degree nodes to the total number of nodes in the original network. Thus, the top highest-degree nodes in scale-free networks are easily lost by unbiased samplings at low sampling rates, such as the random node sampling, which induces that the AD of the subgraph induced by the nodes randomly chosen by the RN sampling5 is extremely small, as shown in Fig. 1.Table 2 Degree rank and the number of nodes with a certain degree in a scale-free network. (com-Youtube with 1,134,879 nodes28, described in Section "Original networks and sampled node number", was chosen for the analysis.)

Rank i	The ith highest-degree k	The number of nodes with degree k	Rank i	The ith highest-degree k	The number of nodes with degree k	
1	28,754	1	800	180	17	
2	14,641	1	900	80	121	
3	11,281	1	978	2	182,237	
500	490	2	979	1	602,530	

Figure 1 Random node sampling on a simple core-periphery graph, in which Norgv is defined in the original network, not in the RN subgraph, and can be obtained by the traversal-based samplings. The random node sampling is suitable for the evaluation of the AD of the original network23, but cannot directly output a sampled subgraph capturing the degree property.

The AD of the original network Gorg is equal to ∑kPk, where k is the degree defined in Gorg. The random node sampling is prone to losing top highest-degrees d. However, owing to the extremely small Pd, the loss of these degrees has almost no impact on the AD evaluation.

Analysis of the DT evaluation

Let us return to the random node sampling algorithm described in Section "Random node evaluation". Assuming that d⃛org in line 8 is not more than the actual DT value, then the Vk nodes in line 8 and the nodes u with dorgu=d⃛org in removed_edge_set (in line 9) are classified into the periphery, that is,1 added_edge_set>removed_edge_set,

because added_edge_set (in line 9) contains the edges that connect the peripheral Vk nodes to core nodes in the original network Gorg, and removed_edge_set consists of the edges connecting two periphery nodes. Please note that there are dense connections between core and periphery nodes but sparse connections between periphery nodes12–15,27. Although the node set V in line 3 (chosen by the random node sampling) losses top highest degree nodes in the core, most of nodes in V can directly reach the core through only one jump in the scale-free original network Gorg, because the PA rule26 causes the core to be densely connected by the periphery12–15,27, which ensures that the top highest degree nodes in Gorg are not lost in the neighbor sets Norgv for most of nodes v that falls in the node set V (the result will be further verified in Section "Analysis of diverse core-periphery structures"). Thus, all the connections between the peripheral Vk nodes and the core nodes in Gorg are preserved in the edge set added_edge_set=v,uv∈Vk∧u∈Norgv∧dorgu>d⃛org in line 9.

The nodes in the original network Gorg are independently chosen with uniform distribution; thus, the random node sampling not only loses top highest degree nodes in the core but also ignores the complex topological correlation between sampled periphery nodes. However, the determination of the DT value depends on the connections between core and periphery nodes, while it is weakly correlated with the connections between periphery nodes. The uniform distribution enables the random node sampling to choose the periphery nodes without preference, which is critical for the accurate DT evaluation of our random node sampling.

Analysis of the variance and runtime

We choose five real-world large scale-free networks28, described in Section "Original networks and sampled node number", for the variance and runtime analysis, as listed in Table 3.Table 3 Mean and standard errors of the evaluated AD, evaluated DT and runtime (seconds) from 100 independent realizations for each sampling rate RRN.

Random node sampling (designed in Section "Random node evaluation") on original real-world networks28	Sampling rate RRN	
15%	20%	25%	30%	35%	100%	
ego-Twitter	
 Evaluated AD d¯org	33.01 ± 0.521	32.93 ± 0.450	33.01 ± 0.413	33.02 ± 0.363	32.96 ± 0.349	33.01 ± 0	
 Evaluated DT d⃛org	68.18 ± 4.085	68.34 ± 3.687	68.48 ± 3.666	70.00 ± 3.552	70.65 ± 3.561	76.00 ± 0	
 Runtime (Seconds)	0.309 ± 0.086	0.465 ± 0.103	0.587 ± 0.143	0.744 ± 0.222	0.797 ± 0.243	–	
loc-Gowalla							
 Evaluated AD d¯org	9.676 ± 0.292	9.687 ± 0.212	9.662 ± 0.206	9.654 ± 0.184	9.661 ± 0.174	9.662 ± 0	
 Evaluated DT d⃛org	27.35 ± 2.921	27.71 ± 2.768	28.48 ± 2.664	29.28 ± 2.574	29.47 ± 1.951	32.00 ± 0	
 Runtime (Seconds)	0.581 ± 0.066	0.797 ± 0.102	1.065 ± 0.106	1.218 ± 0.080	1.408 ± 0.085	–	
com-DBLP	
 Evaluated AD d¯org	6.629 ± 0.046	6.621 ± 0.032	6.619 ± 0.029	6.623 ± 0.028	6.618 ± 0.021	6.621 ± 0	
 Evaluated DT d⃛org	10.05 ± 0.297	10.02 ± 0.200	10.02 ± 0.245	10.01 ± 0.173	10.01 ± 0.100	10.00 ± 0	
 Runtime (Seconds)	0.636 ± 0.238	0.912 ± 0.281	0.982 ± 0.335	1.249 ± 0.491	1.350 ± 0.444	–	
web-Stanford	
 Evaluated AD d¯org	14.18 ± 0.695	14.09 ± 0.526	14.10 ± 0.572	14.08 ± 0.439	14.14 ± 0.423	14.14 ± 0	
 Evaluated DT d⃛org	37.69 ± 0.597	37.68 ± 0.601	37.72 ± 0.514	37.68 ± 0.468	37.74 ± 0.440	38.00 ± 0	
 Runtime (Seconds)	0.701 ± 0.253	0.939 ± 0.327	1.196 ± 0.410	1.429 ± 0.470	1.759 ± 0.589	–	
com-Youtube	
 Evaluated AD d¯org	5.277 ± 0.113	5.251 ± 0.086	5.259 ± 0.083	5.271 ± 0.070	5.274 ± 0.067	5.265 ± 0	
 Evaluated DT d⃛org	34.49 ± 2.783	35.44 ± 2.388	35.67 ± 2.165	35.81 ± 2.218	36.09 ± 2.020	39.00 ± 0	
 Runtime (Seconds)	2.401 ± 0.714	3.273 ± 0.924	4.360 ± 0.965	5.094 ± 0.922	6.560 ± 1.038	–	
The real AD and DT were obtained by RRN=100%. The running environment is illustrated in Section "Time efficiency of the traversal-based samplings".

Based on Table 3, a low sampling rate RRN is capable of evaluating the AD and DT values. However, with increasing RRN, the standard errors of the evaluated values show a decreasing trend. Owing to the very high time efficiency of the random node sampling, which is induced by that the sampling ignores the complex topological correlation among the randomly chosen nodes, we choose RRN=35% to pursue a low variance. Note that the random node sampling cannot directly output a subgraph capturing the degree properties or other important properties, as shown in Fig. 1; however, our purpose is to obtain a subgraph representing the original network.

Analysis of diverse core-periphery structures

Based on the DT value d⃛org, the original network Gorg=Vorg,Eorg can be partitioned into core nodes with dorgv>d⃛org, periphery nodes with dorgv≤d⃛org, core edges that connect two core nodes, periphery edges that connect two periphery nodes, and vertical edges that connect a periphery node to a core node. As shown in Table 4, the five real-world scale-free networks consist of a dense core and a sparse periphery. In addition, a few core nodes are densely connected by the periphery, and more than 55% of periphery nodes can directly reach the core through only one jump. Moreover, for the com-Youtube, web-Stanford and loc-Gowalla networks in Table 4, we find that their core node percentages are much smaller and their core edge densities (defined as the ratio of the number of core edges to the number of core nodes) are much denser than those of other networks. Restricted by low sampling rates, the smaller and denser the core, the stronger its attraction to traditional traversal-based samplings. Because the Markov chain theory cannot achieve convergence at low sampling rates20, this paper will further confirm the impact of the core structure of the original networks on the sampling results through experimental comparisons in Section "Evaluation".Table 4 Percentage distributions of nodes and edges in the core-periphery structures partitioned by d⃛org.

Original networks28	d⃛org	Node percentage distribution	Edge percentage distribution	Rper (%)	
Core (%)	Periphery (%)	Core (%)	Vertical edges (%)	Periphery (%)	
ego-Twitter	76	9.88	90.12	25.37	46.79	27.83	97.83	
70.65	11.22	88.78	28.47	46.55	24.98	98.21	
loc-Gowalla	32	5.31	94.69	26.09	38.56	35.35	56.44	
29.47	6.05	93.95	28.50	38.48	33.01	58.12	
com-DBLP	10	14.91	85.09	31.13	41.65	27.21	79.14	
10.01	14.91	85.09	31.13	41.65	27.21	79.14	
web-Stanford	38	4.48	95.52	14.64	58.23	27.13	77.87	
37.74	5.05	94.95	16.16	58.19	25.61	78.04	
com-Youtube	39	1.60	98.40	16.44	50.92	32.64	55.93	
36.09	1.75	98.25	17.58	50.87	31.55	56.75	
Two DT values were chosen for each original network: bold represents the accurate value with RRN=100%, and non-bold represents the mean of the evaluated values with RRN=35%, as shown in Table 3. Rper is defined as the ratio of the number of periphery nodes that can directly reach core through only one jump to the total number of periphery nodes.

Unknown network sampling SLSR

Traversal-based sampling algorithm at low sampling rates

Traversing on an original network establishes topological connections between sampled nodes, but may be overly attracted to the high-degree core nodes at low sampling rates. Thus, this section designs a new traversal-based sampling SLSR, which only adopts the information of the node set and the neighbors of sampled nodes, that is, any complex topological information of the unknown original network, such as, community, clique, and real statistical characteristics, cannot be used in design process of SLSR. To improve time efficiency, a low sampling rate RSLSR is needed, but the sampled subgraph should capture more properties of the original network.

Our SLSR creates a core-periphery framework for existing traversal-based samplings that run on unknown networks, such as FF19, SRW11, NBRW20, CNRW20, CNARW20, and RD21. First, choose one sampling from the existing methods and use Ts to represent it, then SLSR restricts Ts to only traverse on the periphery using the evaluated d⃛org. Specifically, the set of neighbors of a node v that is accessing by Ts is changed as2 Norgperv=uu∈Norgv∧dorgu≤d⃛org

and other principles and steps of Ts remain unchanged. Please note that, the other neighbor set3 Norgcorv=uu∈Norgv∧dorgu>d⃛org

that is obtained simultaneously with Eq. (2) should be saved for the core sampling. The process of Ts running on the periphery of Gorg with a sampling rate RSLSR is represented as follows:4 Gsubper=Vsubper,Esubper,Norgcorvv∈Vsubper←PeripherySamplingTs,Gorg,d⃛org,RSLSR

where Gsubper denotes the sampled subgraph of the periphery, and Vsubper and Esubper denote its node set and edge set. According to P3, predefine a parameter x% to preserve top-Norgcorv×x% highest degree core neighbors for each v∈Vsubper, and let Vxv denote the node set composed of the preserved core neighbors where Vxv⊆Norgcorv.5 Vsubcor=⋃v∈VsubperVxv,

6 Esubver=v,uv∈Vsubper∧u∈Vxv.

We define Vsubcor in Eq. (5) as the set of sampled core nodes. According to P2, all the connections between the Vsubcor nodes in Gorg should be preserved, which can be implemented by the access of the neighbors of each Vsubcor node in Gorg. Please note that the Vsubcor nodes and the connections between them construct the sampled core. To ensure the connectivity of the sampled subgraph, the vertical edge set Esubver defined in Eq. (6) also should be preserved.

Next, analyze how to determine the parameter x%. With the growth of x%, the number of the vertical edges (namely, Esubver) increases, while the sampled periphery Gsubper remains unchanged and the sampled core induced by the node set Vsubcor has a low variability15. Thus, the AD of the subgraph, composed of the vertical edges, the sampled periphery, and the sampled core, increases monotonically as x% grows, that is, a bisection method can be used to determine x% under the guidance of the evaluated d¯org that is our target AD of the sampled subgraph.

In the proposed bisection method, the number of iterations of the While loop is not more than log2100. In addition, Norgcorv≤d⃛org for each v∈Vsubper in line 7, and Vsubcor≪Vsubper in line 10, since the scale of the core is much smaller than that of the periphery, as shown in Table 4. Thus, the time complexity of the bisection method is OVsubper. Once the parameter x% is determined, the sampled subgraph of Gorg can be obtained using lines 6 to 10 in the bisection method. The Main function of SLSR is described as follows:

The sampling framework created by SLSR is simple. Simpler methods typically have higher time efficiency. However, the framework can significantly improve the accuracy of multi-structure preservation for Ts at low sampling rates that are needed for a high time efficiency.

We arbitrarily choose Ts as the FF sampling19, since the sampling traverses each node no more than once which leads to its high time efficiency. Users can use Ts to represent other existing traversal-based samplings. Once Ts is chosen, the periphery sampling can be determined.

Analysis of the variance of sampled SLSR subgraphs

Low sampling rates may lead to high variances in the sampling results of large sample spaces. However, our SLSR sampling can control the variances based on the following three points:The bisection method is deterministic, that is, there is no randomness in the method.

The random node sampling has a very high time efficiency, as shown in Table 3, thus setting its sampling rate RRN=35% can not only reduce the variance, but also has a weak impact on the time efficiency of our traversal-based SLSR sampling.

The smaller the scale of a sample space, the lower the uncertainty of randomly extracting a sample from the space, which can be ensured by the theory of information entropy16. In the periphery sampling Ts of SLSR, described in Section "Traversal-based sampling algorithm at low sampling rates", the set of neighbors of a node v that is accessing by Ts has been compressed from Norgv to Norgperv={u|u∈Norgv∧dorgu≤d⃛org}. In a scale-free network, the scale of the neighbor set of a core node is extremely larger than that of a periphery node, as shown in Table 2, and the number of the vertical edges connecting a periphery node to a core node is much larger than the number of edges connecting a periphery node to another periphery node, as listed in Table 4. Thus, Norgperv<Norgv≪Norgu when v is a periphery node and u is a core node. Please note that Norgperv is related to the sample space of w when Ts traverses from v to w∈Norgperv. Compared to the traditional traversal-based samplings that excessively prefer high-degree core nodes at low sampling rates, the sample space of w in our SLSR sampling has been sharply compressed at most cases.

The above three points are critical for controlling the uncertainty of SLSR with RSLSR≤10%, and the experimental results in Section "Evaluation" can further verify the low variance.

Evaluation

Metrics

This paper proposes a traversal-based sampling SLSR that only uses the information of node set and the neighbors of sampled nodes, without involving complex topological characteristics, but can solve the issue of excessive preference for high-degree core nodes at low sampling rates. Thus, some metrics that can measure the excessive preference are included in this section.

AD is defined as ∑kPk=2E/V in a simple and undirected graph G=V,E with node set V and edge set E, where Pk denotes the fraction of nodes with degree k in G29–31. The statistic reflects whether a sampling favors core nodes with high-degrees.

Complementary cumulative distribution defined as Fk versus k where Fk=∑d>kPd exhibits better degree power-law characteristic29.

Average clustering coefficient (ACC) defined as C¯=∑CkPk represents how close a node’s neighbors are to forming a clique32–35, where Ck=2Tk/kk-1 and Tk denotes the average of the number of links between two neighbors of k-degree nodes. A related distribution characteristic is clustering coefficient distribution32 defined as Ck versus k.

Average path length (APL) is defined as L¯=∑l·μl that represents the reachability of nodes within each other, where μl denotes the fraction of node pairs with shortest path length l between the two nodes. A related distribution characteristic is shortest path length distribution that is defined as μl versus l32–34.

Ratio of weighted spectral distribution to node number (RWSD) represents the connection relationship between low-degree nodes36 most of which are in the periphery. The weighted spectral distribution is defined as ∑1-λi4 where λi denotes the ith eigenvalue in the normalized Laplacian spectrum of G36–38. Please note that the statistic can be quickly calculated by a 4-cycle enumeration algorithm without the need for the calculation of the eigenvalues39.

Ratio of maximum degree to node number (RMD) represents the influence of the node with maximum degree, which is suitable for the comparison of graphs with different scales40.

Closeness centrality (CC) of a node is defined as n-1/L where n is the total number of nodes and L denotes the sum of the length of the shortest path from the node to other nodes, which reflects how efficiently the node exchanges information with others41.

Betweenness centrality (BC) of a node represents the fraction of the shortest paths that pass through the node for any pair of nodes, which describes potential power of the node in controlling the information flow in a network42,43.

Community represents local densely-connected structures that are visually salient44,45. Thus, a visual evaluation was adopted. Specifically, the communities were detected by a Louvain method45 and visually displayed by a force-directed method46. The correspondence between the communities of an original network and its sampled subgraphs was established by their shared nodes.

Original networks and sampled node number

The above multiple metrics and five widely-used large original networks chosen from Stanford Large Network Dataset Collection28 were adopted for the evaluation. Please note that the original networks listed in Table 5 were simplified as undirected graphs, namely the self-loops, multi-edges, direction of edges, and a few isolated nodes with degree zero in the five chosen networks have been removed. In addition, the important statistics of the original networks have been listed in Tables 6, 7, 8, 9 and 10 for the convenience of comparison.Table 5 Descriptions of the five widely-used large original networks28, and the mean and standard errors of the sampled node number of the SLSR subgraphs from 100 independent realizations for each sampling rate RSLSR.

Original networks	Original node number	Original edge number	Descriptions	RSLSR(%)	Sampled node number	
ego-Twitter	81,305	1,342,220	This dataset consists of 'circles' (or 'lists') from Twitter	5	5,733 ± 172	
loc-Gowalla	196,588	949,712	This dataset consists of a location-based social network where users share their locations	5	11,256 ± 159	
com-DBLP	317,076	1,049,760	This dataset consists of a co-authorship network from DBLP that is a computer science bibliography	10	49,402 ± 155	
web-Stanford	281,902	1,992,634	This dataset consists of a web network from Stanford University (stanford.edu)	10	30,385 ± 294	
com-Youtube	1,134,879	2,987,595	This dataset consists of a social network from Youtube that is a video-sharing web site	5	58,998 ± 232	

Table 6 The statistics of the original ego-Twitter network, and the mean and standard errors of the statistics of the sampled subgraphs. APL and BC(vorgmax) are related to 10 independent realizations, while other statistics are related to 100 independent realizations.

Statistics	AD	ACC	APL	RWSD	RMD	CC vorgmax	BC vorgmax	
Original network	33.01	0.565	3.889	0.008	0.042	0.402	0.059	
Mean and standard errors of the sampled subgraphs	
 SLSR	33.06 ± 0.410	0.445 ± 0.014	3.326 ± 0.096	0.011 ± 0.0008	0.137 ± 0.035	0.442 ± 0.017	0.056 ± 0.012	
 FF	46.26 ± 6.895	0.512 ± 0.018	3.058 ± 0.149	0.007 ± 0.0016	0.189 ± 0.087	0.461 ± 0.023	0.043 ± 0.021	
 RD	13.73 ± 0.383	0.312 ± 0.007	4.063 ± 0.023	0.022 ± 0.0009	0.088 ± 0.007	0.387 ± 0.003	0.101 ± 0.006	
 SRW	35.26 ± 2.070	0.543 ± 0.006	3.438 ± 0.041	0.013 ± 0.0009	0.111 ± 0.011	0.440 ± 0.007	0.060 ± 0.007	
 NBRW	34.856 ± 1.918	0.544 ± 0.006	3.428 ± 0.078	0.013 ± 0.0008	0.110 ± 0.011	0.440 ± 0.007	0.059 ± 0.007	
 CNRW	49.026 ± 0.749	0.546 ± 0.003	3.447 ± 0.022	0.007 ± 0.0002	0.081 ± 0.003	0.443 ± 0.003	0.055 ± 0.003	
 CNARW	37.65 ± 1.651	0.467 ± 0.005	3.306 ± 0.032	0.012 ± 0.0008	0.126 ± 0.008	0.451 ± 0.006	0.060 ± 0.008	
The sampling rate RSLSR of our SLSR sampling, and the sampled node number of the other chosen samplings FF, RD, SRW, NBRW, CNRW, and CNARW have been illustrated in Section "Original networks and sampled node number".

Table 7 The statistics of the original loc-Gowalla network, and the mean and standard errors of the statistics of the sampled subgraphs. APL and BC(vorgmax) are related to 10 independent realizations, while other statistics are related to 100 independent realizations.

Statistics	AD	ACC	APL	RWSD	RMD	CC vorgmax	BC vorgmax	
Original network	9.66	0.236	4.627	0.057	0.075	0.389	0.324	
Mean and standard errors of the sampled subgraphs	
 SLSR	9.700 ± 0.194	0.236 ± 0.007	4.644 ± 0.242	0.071 ± 0.011	0.096 ± 0.031	0.376 ± 0.024	0.312 ± 0.091	
 FF	24.12 ± 4.044	0.280 ± 0.008	3.483 ± 0.232	0.021 ± 0.009	0.205 ± 0.051	0.490 ± 0.041	0.253 ± 0.027	
 RD	11.48 ± 0.105	0.219 ± 0.003	3.505 ± 0.016	0.051 ± 0.002	0.288 ± 0.002	0.497 ± 0.002	0.375 ± 0.003	
 SRW	21.23 ± 0.421	0.309 ± 0.004	3.708 ± 0.036	0.035 ± 0.002	0.205 ± 0.005	0.473 ± 0.005	0.289 ± 0.013	
 NBRW	20.42 ± 0.484	0.315 ± 0.004	3.717 ± 0.031	0.040 ± 0.001	0.201 ± 0.006	0.468 ± 0.005	0.290 ± 0.011	
 CNRW	21.11 ± 0.126	0.292 ± 0.002	3.781 ± 0.016	0.028 ± 0.001	0.164 ± 0.002	0.465 ± 0.002	0.306 ± 0.002	
 CNARW	21.16 ± 0.458	0.253 ± 0.004	3.661 ± 0.053	0.037 ± 0.002	0.209 ± 0.005	0.474 ± 0.006	0.288 ± 0.008	
The sampling rate RSLSR of our SLSR sampling, and the sampled node number of the other chosen samplings FF, RD, SRW, NBRW, CNRW, and CNARW have been illustrated in Section "Original networks and sampled node number".

Table 8 The statistics of the original com-DBLP network, and the mean and standard errors of the statistics of the sampled subgraphs. APL and BC(vorgmax) are related to 5 independent realizations, while other statistics are related to 100 independent realizations.

Statistics	AD	ACC	APL	RWSD	RMD	CC vorgmax	BC vorgmax	
Original network	6.621	0.632	6.792	0.070	0.001	0.218	0.007	
Mean and standard errors of the sampled subgraphs	
 SLSR	6.231 ± 0.052	0.557 ± 0.002	6.852 ± 0.013	0.098 ± 0.001	0.002 ± 0.0001	0.207 ± 0.001	0.003 ± 0.0003	
 FF	9.887 ± 0.134	0.564 ± 0.005	5.576 ± 0.047	0.048 ± 0.001	0.005 ± 0.0004	0.240 ± 0.002	0.002 ± 0.0007	
 RD	8.013 ± 0.023	0.313 ± 0.002	5.688 ± 0.009	0.050 ± 0.001	0.005 ± 0.0001	0.237 ± 0.0003	0.002 ± 0.0001	
 SRW	8.975 ± 0.068	0.592 ± 0.003	6.075 ± 0.017	0.061 ± 0.001	0.005 ± 0.0002	0.239 ± 0.001	0.012 ± 0.0012	
 NBRW	8.769 ± 0.076	0.616 ± 0.002	6.156 ± 0.021	0.065 ± 0.001	0.005 ± 0.0002	0.236 ± 0.001	0.012 ± 0.0009	
 CNRW	9.001 ± 0.067	0.591 ± 0.003	6.055 ± 0.032	0.060 ± 0.001	0.005 ± 0.0002	0.239 ± 0.001	0.012 ± 0.0009	
 CNARW	7.928 ± 0.055	0.467 ± 0.002	5.936 ± 0.006	0.062 ± 0.001	0.004 ± 0.0002	0.241 ± 0.001	0.009 ± 0.001	
The sampling rate RSLSR of our SLSR sampling, and the sampled node number of the other chosen samplings FF, RD, SRW, NBRW, CNRW, and CNARW have been illustrated in Section "Original networks and sampled node number".

Table 9 The statistics of the original web-Stanford network, and the mean and standard errors of the statistics of the sampled subgraphs. APL and BC(vorgmax) are related to 10 independent realizations, while other statistics are related to 100 independent realizations.

Statistics	AD	ACC	APL	RWSD	RMD	CC vorgmax	BC vorgmax	
Original network	14.14	0.597	6.815	0.049	0.133	0.279	0.632	
Mean and standard errors of the sampled subgraphs	
 SLSR	14.22 ± 0.404	0.568 ± 0.011	5.246 ± 0.127	0.038 ± 0.002	0.173 ± 0.005	0.355 ± 0.010	0.684 ± 0.022	
 FF	26.80 ± 2.069	0.566 ± 0.025	4.025 ± 0.268	0.024 ± 0.003	0.297 ± 0.058	0.465 ± 0.034	0.663 ± 0.060	
 RD	5.629 ± 0.312	0.321 ± 0.020	4.987 ± 0.116	0.058 ± 0.002	0.169 ± 0.013	0.368 ± 0.013	0.704 ± 0.024	
 SRW	27.18 ± 4.710	0.678 ± 0.048	4.209 ± 0.269	0.016 ± 0.002	0.368 ± 0.076	0.430 ± 0.062	0.677 ± 0.051	
 NBRW	26.72 ± 3.887	0.675 ± 0.055	4.621 ± 0.598	0.017 ± 0.003	0.355 ± 0.058	0.421 ± 0.051	0.680 ± 0.065	
 CNRW	27.12 ± 4.589	0.689 ± 0.037	4.226 ± 0.294	0.015 ± 0.002	0.359 ± 0.076	0.432 ± 0.058	0.656 ± 0.092	
 CNARW	22.71 ± 1.767	0.553 ± 0.035	4.420 ± 0.170	0.021 ± 0.002	0.328 ± 0.043	0.407 ± 0.032	0.584 ± 0.084	
The sampling rate RSLSR of our SLSR sampling, and the sampled node number of the other chosen samplings FF, RD, SRW, NBRW, CNRW, and CNARW have been illustrated in Section "Original networks and sampled node number".

Table 10 The statistics of the original com-Youtube network, and the mean and standard errors of the statistics of the sampled subgraphs. APL and BC(vorgmax) are related to 5 independent realizations, while other statistics are related to 100 independent realizations.

Statistics	AD	ACC	APL	RWSD	RMD	CC vorgmax	BC vorgmax	
Original network	5.265	0.081	5.279	0.081	0.025	0.338	-	
Mean and standard errors of the sampled subgraphs	
 SLSR	5.201 ± 0.174	0.092 ± 0.002	5.808 ± 0.099	0.136 ± 0.004	0.055 ± 0.002	0.257 ± 0.003	-	
 FF	21.90 ± 0.532	0.128 ± 0.005	3.971 ± 0.052	0.027 ± 0.003	0.118 ± 0.003	0.331 ± 0.003	-	
 RD	9.857 ± 0.750	0.099 ± 0.005	4.223 ± 0.008	0.067 ± 0.005	0.117 ± 0.005	0.321 ± 0.002	-	
 SRW	19.25 ± 2.378	0.145 ± 0.015	4.041 ± 0.014	0.037 ± 0.007	0.127 ± 0.009	0.432 ± 0.019	-	
 NBRW	19.29 ± 0.987	0.143 ± 0.003	4.133 ± 0.009	0.047 ± 0.004	0.122 ± 0.002	0.424 ± 0.012	-	
 CNRW	19.97 ± 0.138	0.141 ± 0.002	4.020 ± 0.012	0.036 ± 0.001	0.125 ± 0.002	0.435 ± 0.002	-	
 CNARW	19.11 ± 2.296	0.112 ± 0.010	4.215 ± 0.482	0.040 ± 0.007	0.121 ± 0.015	0.428 ± 0.018	-	
The sampling rate RSLSR of our SLSR sampling, and the sampled node number of the other chosen samplings FF, RD, SRW, NBRW, CNRW, and CNARW have been illustrated in Section "Original networks and sampled node number".

According to Section "Traversal-based sampling algorithm at low sampling rates", our SLSR sampling sequentially executes the AD and DT evaluation, the periphery sampling with a low sampling rate RSLSR, and the bisection method for preserving core and vertical edges. Since the original network Gorg=Vorg,Eorg is unknown, SLSR cannot know in advance the actual number of periphery nodes in Gorg. Owing to that the number of core nodes is extremely smaller than that of periphery nodes, Vorg×RSLSR is approximately equal to the expected number of periphery nodes to be sampled. Thus, RSLSR is not a strict sampling rate that is defined as the ratio of the number of nodes in a sampled subgraph to Vorg. In order to compare more fairly with the traditional traversal-based samplings on unknown networks, we first obtain the sampled SLSR subgraphs, and calculate the mean and standard errors of the sampled node number of the subgraphs from 100 independent realizations for each original network and given sampling rate RSLSR in Table 5. Then, each traditional traversal-based sampling outputs 100 subgraphs whose node number is equal to the mean of the sampled node number for each original network.

Comparisons

SLSR is compared with the related traversal-based samplings, namely FF19, SRW11, NBRW20, CNRW20, CNARW20, and RD21, on the five large original networks in Table 5, because the chosen samplings do not adopt complex topological characteristics, such as, community, clique, and real global statistical characteristics, of the original networks.

Variance comparison with statistics

At a low sampling rate, low variance is important for the reliability of sampling results. Thus, we first compare the standard errors of the statistics AD, ACC, AC, RWSD, RMD, and CC(vorgmax) of the sampled subgraphs from 100 independent realizations, where vorgmax is the maximum degree node in an original network and is easily preserved in the sampled subgraphs by the chosen sampling methods. Please note that, owing to the high time complexity, we compare the standard errors of the statistics APL and BC(vorgmax) from 5 or 10 independent realizations.

BCvorgmax of the original com-Youtube network with 1,134,879 nodes and 2,987,595 edges was not provided in Table 10 due to extremely high computation and memory requirements. Please note that the RWSD of the network can be quickly obtained within 2 h39, whereas the APL and the path length distribution of the network have to be computed by a parallel algorithm. On a computer with Intel Core i7-8700 CPU 3.20 GHz Memory 16 G, the parallel algorithm with 5 threads used for calculating the APL and the path length distribution runs about 12 days.

Because Ts in SLSR was chosen as the FF sampling for the experiments. Thus, we first compare the variance between SLSR and FF. Based on Tables 6, 7, 8, 9 and 10, we can observe that the standard errors of the statistics of SLSR are generally smaller than those of FF, except for a few cases where the mean is very small. Please note that the low variance of SLSR has been analyzed in Section "Analysis of the variance of sampled SLSR subgraphs". NBRW, CNRW and CNARW are improved random walk samplings objective to reduce the asymptotic variance10,20. Although the three samplings provided rigorous mathematical proofs based on Markov chain, their theoretical basis is that the Markov chain must converge, which is difficult to be guaranteed at low sampling rates. Thus, based on the analysis in Section "Analysis of the variance of sampled SLSR subgraphs" and Tables 6, 7, 8, 9 and 10, the standard errors of the statistics of SLSR can be effectively controlled in most cases. RD consists of two steps: the first step is to extract a predetermined number of starting seeds using the random node sampling, and the second step adopts a deterministic algorithm without randomness21. Thus, RD can also effectively control the standard errors in most cases.

Mean is another important indicator of the statistics. Thus, Section "Mean comparison with statistics" will use the mean to analyze the excessive preference for high-degree core nodes at low sampling rates.

Mean comparison with statistics

This section first analyzes the importance of the statistics AD, ACC, APL, RWSD, and RMD in measuring the excessive preference for high-degree core nodes, and then experimentally studies the influence of the core-periphery structures on the excessive preference.

Scale-free networks consist of a dense core and a sparse periphery, and the core is densely connected by the periphery. Thus, high-degree core nodes tend to be densely connected to each other. If more high-degree core nodes are sampled, the subgraph induced by the sampled nodes can preserve more edges, that is, AD becomes larger as the preference is stronger.

Given a periphery node v, owing to the dense core, the local clustering coefficient of v tend to be larger as the proportion of high-degree core nodes in Norgv increases. Thus, ACC generally becomes larger as the preference is stronger.

Owing to the sparse periphery, nodes in the periphery have to shorten the path length between each other through the core, that is, APL becomes smaller as the preference is stronger.

According to the study of Jiao et al.36, RWSD indicates the feature of connections between low-degree nodes on large networks, and the statistic decreases as the connections become sparser. The excessive preference for core nodes can make the connections between low-degree periphery nodes much sparser, which lead to smaller RWSD.

In addition, the excessive preference for core nodes generally induces larger RMD because the maximum degree node must be located in the core.

According to the mean values of the above-mentioned statistics and the core-periphery structures of the original networks shown in Table 4, we study the influence of the core structures on the excessive preference for the core nodes, which is an important contribution of this paper, because it is helpful in improving the traditional traversal-based samplings at low sampling rates.

Table 4 shows that the com-Youtube network has the smallest core node percentage and largest core edge density, while the mean values of the statistics in Table 10 confirm that the traditional traversal-based samplings have the strongest excessive preference for the core. Conversely, Table 4 shows that the com-DBLP network owns the largest core node percentage and smallest core edge density, while the mean values of the statistics in Table 8 verify that the traditional traversal-based samplings can avoid the excessive preference for the core. According to Tables 6, 7, 8, 9 and 10, our SLSR sampling performs outstandingly in Tables 7, 9 and 10. The results have been analyzed in Section "Analysis of diverse core-periphery structures", that is, the cores of the com-Youtube, web-Stanford and loc-Gowalla networks in Table 4 are much smaller and denser than those of other chosen networks.

Moreover, we compare two centralities (i.e., CC and BC) of some important nodes between the original networks and their sampled subgraphs. The nodes were chosen as the maximum degree nodes vorgmax in the original networks, and they can be preserved to the sampled subgraphs by the biased samplings being compared. The chosen Ts in SLSR is competent for capturing peripheral degree distribution without the interference of the core, all the edges that connect vorgmax to nodes in Vsubper are preserved due to P3, where Gsubper=Vsubper,Esubper is the output of Ts, and the structure of the core is preserved to the maximum extent possible due to P2. All the clues strongly influence the centralities of the top highest degree core nodes in the SLSR sampled subgraphs, and Tables 6, 7, 8, 9 and 10 verify that the clues are helpful in capturing CCvorgmax and BCvorgmax.

Distribution comparison

This section chooses degree complementary cumulative distribution29, clustering coefficient distribution32, and path length distribution32,34, which are commonly-used measures, for further comparison. Because it is difficult to display the distributions of 100 realizations simultaneous, we choose only one realization with AD closest to the mean for the comparison. In addition, we choose top five sampling methods with minimum AD standard errors for each original network, since high variance corresponds to high uncertainty.

The distribution of nodes with lower degrees is more important for the first two measures. For example, in Fig. 4a and b, degrees not exceeding 10 correspond to 85.09% of the total number of nodes in the com-DBLP network. The path length distribution of a graph was calculated on the maximum connected component of the graph.

Based on the comparisons of Figs. 2, 3, 4, 5 and 6, SLSR can preserve the three distributions.Figure 2 Comparison of distribution characteristics between original ego-Twitter network and its subgraphs sampled by SLSR and related methods with relatively low variances. The sampled node number of the subgraphs has been illustrated in Section "Original networks and sampled node number".

Figure 3 Comparison of distribution characteristics between original loc-Gowalla network and its subgraphs sampled by SLSR and related methods with relatively low variances. The sampled node number of the subgraphs has been illustrated in Section "Original networks and sampled node number".

Figure 4 Comparison of distribution characteristics between original com-DBLP network and its subgraphs sampled by SLSR and related methods with relatively low variances. The sampled node number of the subgraphs has been illustrated in Section "Original networks and sampled node number".

Figure 5 Comparison of distribution characteristics between original web-Stanford network and its subgraphs sampled by SLSR and related methods with relatively low variances. The sampled node number of the subgraphs has been illustrated in Section "Original networks and sampled node number".

Figure 6 Comparison of distribution characteristics between original com-Youtube network and its subgraphs sampled by SLSR and related methods with relatively low variances. The sampled node number of the subgraphs has been illustrated in Section "Original networks and sampled node number".

Community visualization

Force-directed layout46 is a powerful visualization tool for communities, but has two shortcomings when applied to large networks. One is that communities overlap severely with each other, the other is that the layout speed is extremely slow. To make up for the shortcomings, we first use a Louvain method45 to detect the communities of an original network and its sampled subgraphs, and then extract top-k largest communities and visualize them. As shown in Fig. 7, the boundaries of distinct communities in the original web-Stanford network are clearer than those in the original loc-Gowalla network. Thus, we chose the former for the visualization comparison.Figure 7 Visualization of top largest communities in the (a,b) original web-Stanford network and the (c) original loc-Gowalla network. Specifically, the top 4 largest communities in (a) are named as C1, C2, C3 and C4, respectively.

The difficulty of the visualization under low sampling rates lies in the uncertainty of sampling results induced by high variances. To solve this issue, we only visualize the subgraphs obtained by RD, SLSR, and CNARW, which exhibit the lowest AD standard errors in Table 9. In addition, we choose two realizations for each sampling method, one with AD closest to the mean and the other with AD farthest from the mean, as shown in Fig. 8.Figure 8 AD histograms of 100 realizations for each method (i.e., SLSR, CNARW and RD) on the original web-Stanford network, and the chosen realizations for the visualization. The sampled node number of the three methods has been illustrated in Section "Original networks and sampled node number".

Let Ci=Vci,Eci denote a community in Fig. 7a, and S=Vs,Es denote a community in Figs. 9, 10 and 11. If rS=Vs∩Vci/Vs≥19%, we believe that S in the sampled subgraphs originates from Ci in the original network, because Fig. 7a and b show that C1 and C2 gather with other communities where the boundaries between them are vague, and the Louvain method45 used for community detection is a random algorithm and may divide the vague boundaries into different communities. In addition, Fig. 7a and b show that C3 and C4 are remote communities far from the gathering center that includes C1 and C2.Figure 9 Visualization of communities in the subgraphs GSLSRc with AD 14.23 and GSLSRf with AD 13.11 that were sampled by SLSR from the original web-Stanford network and were illustrated in Fig. 8. (a) Top 6 largest communities in GSLSRc, in which 79% of blue nodes fall in C1, 63% of cyan nodes fall in C2, 51% of magenta nodes fall in C3, and 44% of magenta nodes fall in C4. (b) Top 6 largest communities in GSLSRf, in which 39% of blue nodes fall in C1, 67% of cyan nodes fall in C2, 43% of magenta nodes fall in C3, and 53% of magenta nodes fall in C4.

Figure 10 Visualization of communities in the subgraphs GRDc with AD 5.632 and GRDf with AD 6.639 that were sampled by RD from the original web-Stanford network and were illustrated in Fig. 8. (a) Top 6 largest communities in GRDc, in which 19% of blue nodes fall in C1, 78% of cyan nodes fall in C2, 64% of magenta nodes fall in C3, and 35% of magenta nodes fall in C4. (b) Top 6 largest communities in GRDf, in which 21% of blue nodes fall in C1, 79% of cyan nodes fall in C2, 56% of magenta nodes fall in C3, and 43% of magenta nodes fall in C4.

Figure 11 Visualization of communities in the subgraphs GCNARWc with AD 22.71 and GCNARWf with AD 17.88 that were sampled by CNARW from the original web-Stanford network and were illustrated in Fig. 8. (a) Top 6 largest communities in GCNARWc, in which 53% of blue nodes fall in C1, 95% of cyan nodes fall in C2. (b) Top 6 largest communities in GCNARWf, in which 46% of blue nodes fall in C1, 76% of cyan nodes fall in C2, 56% of magenta nodes fall in C3, and 82% of green nodes fall in C4.

Both SLSR and RD adopt the random node sampling that randomly chooses nodes with uniform distribution, which can effectively avoid getting stuck locally at low sampling rates, as shown in Figs. 9 and 10. Different from RD, SLSR separates the random node sampling from the subgraph representation, that is, the random node sampling is only used for the evaluation of AD and DT, and does not participate in the obtainment of subgraphs. Specifically, SLSR uses the periphery sampling to construct the complex topological connections between periphery nodes, and adopts the bisection method to preserve important high-degree core nodes. Thus, SLSR not only inherits the advantage of the random node sampling in avoiding getting stuck locally, but also compensates for the shortcomings of the random node sampling analyzed in Sections "Analysis of the AD evaluation" and "Analysis of the DT evaluation", that is, the random node sampling not only loses top highest degree nodes in the core but also ignores the complex topological correlation between sampled periphery nodes.

The initial seed in Fig. 11a falls in the gathering center including C1 and C2, while the huge magenta and green communities in Fig. 11b are caused by the initial seed falling into C3 or C4 in Fig. 7a. Although the random walk-based samplings10,11,20, such as, SRW, NBRW, CNARW, and CNRW, focus on the theoretical proof of asymptotic variance, mathematical theory is usually based on simplified assumptions of the real world, and Figs. 8a, 11 and Table 10 experimentally show that the low sampling rates do not meet the simplified assumptions of the Markov chain theory.

Time efficiency of the traversal-based samplings

The seven sampling methods, namely, SLSR, FF, SRW, NBRW, CNRW, CNARW and RD, run on another computer with Intel Core i7-8550U CPU 1.80 GHz Memory 20 G. The time comparisons of the sampling methods are listed in Table 11, which shows that SLSR maintains high time efficiency of unknown graph samplings. The running time of SLSR depends on the bisection method and the periphery sampling designed in Section "Unknown network sampling SLSR". Specifically, the periphery sampling corresponds to the chosen Ts sampling, and the time complexity of the bisection method is restricted by Vsubper×log2100 where Vsubper denotes the number of sampled periphery nodes that has been sharply decreased in contrast to the number of nodes in the original network Gorg=Vorg,Eorg owing to the low sampling rate RSLSR≤10%. Please note that the Ts sampling can be replaced by other sampling methods with high time efficiency in Table 11.Table 11 The mean and standard errors of running time (Seconds) of SLSR and related methods from 100 independent realizations that sample the original networks in Table 5.

Original networks	ego-Twitter	loc-Gowalla	com-DBLP	web-Stanford	com-Youtube	
Original node number	81,305	196,588	317,076	281,902	1,134,879	
Sampled node number	5,733	11,256	49,402	30,385	58,998	
Sampling methods	Runtime (s)	
 SLSR	7.079 ± 0.649	16.06 ± 1.061	325.5 ± 41.65	77.11 ± 8.605	190.5 ± 9.888	
 FF	8.126 ± 0.583	23.58 ± 2.268	241.6 ± 23.26	114.6 ± 9.659	309.5 ± 29.03	
 RD	2.776 ± 0.313	6.325 ± 0.505	9.322 ± 0.768	24.13 ± 3.515	33.69 ± 3.233	
 SRW	8.100 ± 0.689	7.660 ± 0.699	9.810 ± 1.390	25.25 ± 6.881	39.39 ± 4.507	
 NBRW	9.590 ± 1.484	8.580 ± 1.628	8.880 ± 1.776	22.15 ± 5.585	39.90 ± 5.217	
 CNRW	11.64 ± 1.715	10.43 ± 0.997	13.09 ± 0.943	17.74 ± 2.769	41.46 ± 3.245	
 CNARW	58.45 ± 3.245	56.30 ± 5.062	58.33 ± 3.411	353.3 ± 45.13	329.6 ± 32.75	
The sampled node number has been illustrated in Section "Original networks and sampled node number".

SLSR chose FF as Ts in the experiments. Based on Table 11, SLSR can enhance the time efficiency of FF at most cases except for the case running on the com-DBLP network. According to the variance analysis in Section "Analysis of the variance of sampled SLSR subgraphs", Norgperv is the sample space of w when Ts traverses from v to w∈Norgperv, and Norgperv<Norgv≪Norgu where v is a periphery node and u is a core node. The compressed sample space not only reduces the uncertainty, but also enhances the time efficiency; for example, extracting one node from 10 nodes is definitely faster than extracting from 1000 nodes. However, as shown in Table 4, the degree threshold d⃛org=10 of the original com-DBLP network is much smaller than those of other original networks. Note that dorgv≤d⃛org for each node v in the periphery, where dorgv=Norgv is the degree of node v in the original network Gorg=Vorg,Eorg; thus, the sample space of w when Ts traverses from v to w is already very small in the original com-DBLP network. In addition, Table 4 shows that the com-DBLP network owns the largest core node percentage and smallest core edge density in contrast to those of other networks, which is helpful in avoiding the excessive preference for the core, as shown in Table 8. Thus, the runtime of the periphery sampling of SLSR (excluding the bisection method) is close to the runtime of FF, when running on the original com-DBLP network.

Conclusions

Low sampling rates redefine the concept of “large networks” from thousands of nodes to millions of nodes or more nodes, which are indispensable for large network analysis. In addition, the concept of “unknown” prevents the sampling methods from using complex topological information, such as, community, clique, and real statistical characteristics of the original networks, which provides a guarantee for high time efficiency on large networks.

The contributions of this paper focus on the “low sampling rates” and “unknown”, as well as the uncertainty and variance problem at the low sampling rates. Specifically,We analyze the advantages and shortcomings of the random node sampling, separate the random node sampling from the subgraph representation, and design a simple and deterministic bisection method after the random node evaluation and periphery sampling. The designed method not only inherits the advantage of the random node sampling in avoiding getting stuck locally, but also preserves the periphery topological structure, critical high-degree core nodes, and edges induced by the core nodes.

We theoretically analyze the impact of the sample space of w (when Ts traverses from v to w) on entropy (uncertainty) and time efficiency, and experimentally verify the low variance and high time efficiency of our traversal-based SLSR sampling.

We investigate a blind spot in Markov chain theory, namely, the low sampling rates, and find that, the smaller and denser the cores in original networks, the stronger the preference of the traditional traversal-based samplings for high-degree core nodes. The new finding is helpful in addressing the issues caused by the low sampling rates.

We adopt a local visualization method to experimentally verify the characteristics of low variance and community capture of SLSR at a low sampling rate.

SLSR does not adopt complex topology information, such as, community, clique, and real global statistical characteristics of original networks, but can avoid the excessive preference for the core, and realize a balance sampling between core and periphery.

Acknowledgements

This work was supported by the Natural Science Foundation of Fujian Province of China (No. 2022J01047).

Author contributions

B.J.: conceptualization; investigation; methodology; software; data curation; formal analysis; visualization; validation; writing.

Data availability

Data available on request from the author bo jiao (jiaoboleetc@outlook.com).

Competing interests

The author declares no competing interests.

Publisher's note

Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
==== Refs
References

1. Zeng, H., Zhou, H., Srivastava, A., Kannan, R. & Prasanna, V. Graphsaint: Graph sampling based inductive learning method. In Eighth International Conference on Learning Representations, Virtual Conference, Formerly Addis Ababa ETHIOPIA, April 26–30 (2020).
2. Zheng T Wang L Large graph sampling algorithm for frequent subgraph mining IEEE Access 2021 9 88970 88980 10.1109/ACCESS.2021.3089699
3. Jiang, P., Wei, Y., Su, J., Wang, R. & Wu, B. SampleMine: A framework for applying random sampling to subgraph pattern mining through loop perforation. In International Conference on Parallel Architectures and Compilation Techniques, Chicago, USA (2022).
4. Zhu M Chen W Hu Y Hou Y Liu L Zhang K DRGraph: An efficient graph layout algorithm for large-scale graphs by dimensionality reduction IEEE Trans. Visual Comput. Graph. 2021 27 2 1666 1676 10.1109/TVCG.2020.3030447
5. Leskovec, J. & Faloutsos, C. Sampling from large graphs. In Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining 631–636 (2006).
6. Hong, S. & Lu, S. Graph sampling methods for big complex networks integrating centrality, k-core, and spectral sparsification. In The 35th ACM/SIGAPP Symposium on Applied Computing, New York, USA (2020).
7. Zhang Z Cui P Zhu W Deep learning on graphs: A survey IEEE Trans. Knowl. Data Eng. 2020 34 249 270 10.1109/TKDE.2020.2981333
8. Martin N Frasca P Canudas-de-Wit C Large-scale network reduction towards scale-free structure IEEE Trans. Netw. Sci. Eng. 2018 6 711 723 10.1109/TNSE.2018.2871348
9. Jiao B Lu X Xia J Gupta BB Bao L Zhou Q Hierarchical sampling for the visualization of large scale-free graphs IEEE Trans. Visual Comput. Graph. 2023 29 12 5111 5123 10.1109/TVCG.2022.3201567
10. Cui Y Li X Li J Wang H Chen X A survey of sampling method for social media embeddedness relationship ACM Comput. Surv. 2022 55 4 1 39 10.1145/3524105
11. Lu, J. & Li, D. Sampling online social networks by random walk. In Proceedings of the First ACM international workshop on hot topics on interdisciplinary social networks research (2012).
12. Zhang X Martin T Newman MEJ Identification of core-periphery structure in networks Phys. Rev. E 2015 91 032803 10.1103/PhysRevE.91.032803
13. Rombach P Porter MA Fowler JH Mucha PJ Core-periphery structure in networks (revisited) SIAM Rev. 2017 59 3 619 646 10.1137/17M1130046
14. Tudisco F Higham DJ A nonlinear spectral method for core-periphery detection in networks SIAM J. Math. Data Sci. 2019 1 2 269 292 10.1137/18M1183558
15. Csermely P London A Wu L Uzzi B Structure and dynamics of core/periphery networks J. Complex Netw. 2013 1 2 93 123 10.1093/comnet/cnt016
16. Zhou J Li J IE-AK: A novel adaptive sampling strategy based on information entropy for Kriging in metamodel-based reliability analysis Reliab. Eng. Syst. Saf. 2023 229 108824 10.1016/j.ress.2022.108824
17. Ben-Eliezer, O., Eden, T., Oren, J. & Fotakis, D. Sampling multiple nodes in large networks: Beyond random walks. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining 37–47 (2022).
18. Wang W Shi S Fu X The subnetwork investigation of scale-free networks based on the self-similarity Chaos Solitons Fractals 2022 161 112140 10.1016/j.chaos.2022.112140
19. Leskovec, J., Kleinberg, J. & Faloutsos, C. Graphs over time: Densification law, shrinking diameters and possible explanations. In Proceedings of the 11th ACM SIGKDD International Conference on Knowledge Discovery in Data Mining 177–187 (2005).
20. Qi, X. A review: Random walk in graph sampling. arXiv:2209.13103. 10.48550/arXiv.2209.13103 (2022).
21. Voudigari, E., Salamanos, N., Papageorgiou, T. & Yannakoudakis, E. J. Rank degree: An efficient algorithm for graph sampling. In Proceedings of the IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 120–129 (2016).
22. Maiya, A. S. & Berger-Wolf, T. Y. Sampling community structure. In Proceedings of the 19th International Conference on World Wide Web 701–710 (2010).
23. Qi M Tan S Chen P Duan X Lu X Efficient network intervention with sampling information Chaos Solitons Fractals 2023 166 112952 10.1016/j.chaos.2022.112952
24. Ahmed NK Neville J Kompella R Network sampling: From static to streaming graphs ACM Trans. Knowl. Discov. Data 2013 8 1 56 10.1145/2601438
25. Zakrzewska, A. & Bader, D. A. Streaming graph sampling with size restrictions. In Proceedings of the IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 282–290 (2017).
26. Barabasi AL Albert R Emergence of scaling in random networks Science 1999 286 5439 509 512 10.1126/science.286.5439.509 10521342
27. Kojaku S Masuda N Core-periphery structure requires something else in the network New J. Phys. 2018 20 4 043012 10.1088/1367-2630/aab547
28. Stanford Large Network Dataset Collection. http://snap.stanford.edu/data/. accessed 2024.
29. Zhou S Mondragón RJ Accurately modeling the Internet topology Phys. Rev. E 2004 70 6 066108 10.1103/PhysRevE.70.066108
30. Luboeinski J Claro L Pomi A Mizraji E Stabilization through self-coupling in networks of small-world and scale-free topology Sci. Rep. 2023 13 1 1089 10.1038/s41598-023-27809-8 36658183
31. Vendeville A Zhou S Guedj B Discord in the voter model for complex networks Phys. Rev. E 2024 109 2 024312 10.1103/PhysRevE.109.024312 38491570
32. Haddadi H Rio M Lannaccone G Moore A Mortier R Network topologies: Inference, modeling, and generation IEEE Commun. Surv. Tutor. 2008 10 48 69 10.1109/COMST.2008.4564479
33. Sterbenz JPG Çetinkaya EK Hameed MA Jabbar A Qian S Rohrer JP Evaluation of network resilience, survivability, and disruption tolerance: Analysis, topology generation, simulation, and experimentation Telecommun. Syst. 2013 52 2 705 736
34. Xu W Zhang Z Optimal scale-free small-world graphs with minimum scaling of cover time ACM Trans. Knowl. Discov. Data 2023 17 7 1 19 10.1145/3583691
35. Yousuf MI Kim S Guided sampling for large graphs Data Min. Knowl. Discov. 2020 34 4 905 948 10.1007/s10618-020-00683-y
36. Jiao B Nie Y Shi J Huang C Zhou Y Du J Guo R Tao Y Scaling of weighted spectral distribution in deterministic scale-free networks Phys. A Stat. Mech. Appl. 2016 451 632 645 10.1016/j.physa.2016.01.096
37. Fay D Haddadi H Thomason A Moore AW Mortier R Jamakovic A Uhlig S Rio M Weighted spectral distribution for internet topology analysis: Theory and applications IEEE/ACM Trans. Netw. 2009 18 1 164 176 10.1109/TNET.2009.2022369
38. Jiao B Shi J Zhang W Xing L Graph sampling for internet topologies using normalized Laplacian spectral features Inf. Sci. 2019 481 574 603 10.1016/j.ins.2018.12.073
39. Jiao B Nie Y Shi J Lu G Zhou Y Du J Accurately and quickly calculating the weighted spectral distribution Telecommun. Syst. 2016 62 231 243 10.1007/s11235-015-0077-7
40. Jiao B Zhou Y Du J Huang C Lu Z Liu Y Study on the stability of the topology interactive growth mechanism using graph spectra IET Commun. 2014 8 16 2845 2857 10.1049/iet-com.2014.0183
41. Wei B Deng Y A cluster-growing dimension of complex networks: From the view of node closeness centrality Phys. A Stat. Mech. Appl. 2019 522 80 87 10.1016/j.physa.2019.01.125
42. Fan, C., Zeng, L., Ding, Y., Chen, M., Sun, Y. & Liu, Z. Learning to identify high betweenness centrality nodes from scratch: A novel graph neural network approach. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management 559–568 (2019).
43. Thai, P., Thai, M. T., Vu, T. & Dinh, T. Saphyra: A learning theory approach to ranking nodes in large networks. In 2022 IEEE 38th International Conference on Data Engineering 54–67 (2022).
44. Zhao W Luo J Fan T Ren Y Xia Y Analyzing and visualizing scientific research collaboration network with core node evaluation and community detection based on network embedding Pattern Recognit. Lett. 2021 144 54 60 10.1016/j.patrec.2021.01.007
45. De Meo, P., Ferrara, E., Fiumara, G. & Provetti, A. Generalized Louvain method for community detection in large networks. In 2011–11th International Conference on Intelligent Systems Design and Applications 88–93 (2011).
46. Zellmann, S. & Weier, M. & Wald, I. Accelerating force-directed graph drawing with RT cores. In 2020 IEEE Visualization Conference 96–100 (2020).
