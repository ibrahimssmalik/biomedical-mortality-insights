
==== Front
Psychometrika
Psychometrika
Psychometrika
0033-3123
1860-0980
Springer US New York

38379021
9953
10.1007/s11336-024-09953-w
Theory & Methods
Using External Information for More Precise Inferences in General Regression Models
http://orcid.org/0000-0002-5785-3894
Jann Martin martin.jann@uni-hamburg.de

1
http://orcid.org/0000-0003-1855-643X
Spiess Martin 2
1 https://ror.org/00g30e956 grid.9026.d 0000 0001 2287 2617 Department of Psychology, University of Hamburg, Von-Melle-Park 5, 20146  Hamburg, Germany
2 https://ror.org/00g30e956 grid.9026.d 0000 0001 2287 2617 University of Hamburg, Von-Melle-Park 5, 20146  Hamburg, Germany
20 2 2024
20 2 2024
2024
89 2 439460
21 12 2022
© The Author(s) 2024
https://creativecommons.org/licenses/by/4.0/ Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.
Empirical research usually takes place in a space of available external information, like results from single studies, meta-analyses, official statistics or subjective (expert) knowledge. The available information ranges from simple means and proportions to known relations between a multitude of variables or estimated distributions. In psychological research, external information derived from the named sources may be used to build a theory and derive hypotheses. In addition, techniques do exist that use external information in the estimation process, for example prior distributions in Bayesian statistics. In this paper, we discuss the benefits of adopting generalized method of moments with external moments, as another example for such a technique. Analytical formulas for estimators and their variances in the multiple linear regression case are derived. An R function that implements these formulas is provided in the supplementary material for general applied use. The effects of various practically relevant moments are analyzed and tested in a simulation study. A new approach to robustify the estimators against misspecification of the external moments based on the concept of imprecise probabilities is introduced. Finally, the resulting externally informed model is applied to a dataset to investigate the predictability of the premorbid intelligence quotient based on lexical tasks, leading to a reduction of variances and thus to narrower confidence intervals.

Supplementary Information

The online version contains supplementary material available at 10.1007/s11336-024-09953-w.

Keywords

external information
generalized method of moments
imprecise probabilities
Universität Hamburg (1037)Open Access funding enabled and organized by Projekt DEAL.

issue-copyright-statement© The Psychometric Society 2024
==== Body
pmcIntroduction

When planning new empirical studies, researchers are confronted with a variety of information from previous studies, including statistical quantities such as means, variances or confidence intervals. However, this external information is mostly used qualitatively, i.e., to develop new theories, and rarely in a quantitative way, i.e., to estimate parameters. One advantage of using external information to estimate a parameter is that some parameter values can be excluded or considered less likely than without the external information, potentially leading to more efficient estimators. The usage of informed prior distributions, where the external information can be used to specify (certain aspects of) the prior distribution, is well known in Bayesian statistics (Bernardo & Smith, 1994). The underlying goal for its use must be clear. On the one hand, external information can facilitate the fitting or tuning of a model. On the other hand, it can make estimators more robust or efficient. This paper aims to achieve the latter of the two goals. Bayesian statistics refers to this as statistical elicitation (Kadane & Wolfson, 1998). The objective is to translate expert knowledge into a prior distribution. Therefore, many psychological biases, such as judgment by representativeness, availability, anchoring, adaptation, or hindsight bias and the intentional misleading by experts, must be considered. It should be noted that the aim is not to achieve objectivity but to ensure a proper statistical representation of subjective knowledge (Garthwaite et al., 2005; Lele & Das, 2000). However, we believe that in applied psychological research, the researcher is usually the one who selects the external information, but is susceptible to the same psychological biases, e.g., in deciding which studies to include. Moreover, the difficulties in eliciting a (multivariate) prior distribution are well documented (Garthwaite et al., 2005, pp. 686–688). The method proposed in this paper allows a simplification of the elicitation compared to Bayesian statistics, since only moments need to be elicited. The elicitation of moments has been well studied for correlations, means, medians, or variances (Garthwaite et al., 2005). In Bayesian elicitation, there are several possible prior distributions for these externally given moments, e.g., with the same expected value or the same correlation, leading to different posterior distributions and thus potentially different results. This problem of prior sensitivity was addressed by Berger (1990) and led to work on robust Bayesian analysis (for an overview, see Insua & Ruggeri, 2000). However, it is somewhat arbitrary to choose the class of distributions for which one wants to make the analysis robust (Garthwaite et al., 2005, p. 695). In our framework, no restriction to a particular class of distributions is required, since it relies solely on moment information and a central limit theorem.

Another important point is that external information may not in general be precise and correct. As nearly all of the external quantities are estimates themselves, they are at least prone to sampling variation. If the external information is not correct (e.g., due to poor sampling or measurement protocols), its use can lead to biased conclusions that may even be worse than without external information. To address this problem, we suggest using an interval for the external information instead of point values, enabling researchers to incorporate any uncertainty about the external moments into the analysis. Inserting external intervals into estimators results in the imprecise probabilistic concept of feasible probability (F-probability) discussed in Sect. 4 (Augustin et al., 2014; Weichselberger, 2001). This approach provides an alternative way to enhance the robustness of elicitation compared to the classical Bayesian paradigm: Using intervals can reflect uncertainty about moments, and the resulting inference is still coherent if the interval contains the true value. However, researchers must be cautious of and avoid overconfidence bias when eliciting intervals; that is, the tendency to select intervals that are too narrow to represent current uncertainty (Winman et al., 2004). A test of the latter assumption is available, more specifically a test of the compatibility of the external interval and the data, which could serve as a pretest before applying the methods proposed here (Jann, 2023).

The insertion of intervals into estimators resembles creating fuzzy numbers (Kwakernaak, 1978; Zadeh, 1965), for which generalizations of traditional statistical methods already exist. This is particularly true for the special case of triangular numbers (Buckley, 2004). The possibility distributions induced by triangular numbers constitute special cases of imprecise probabilities and are constructed based on only one distribution (Augustin et al., 2014, pp. 84–87). This is the key difference between triangular numbers and F-probabilities, since the latter are constructed from a set of possible probability distributions, which can enhance the robustness of the outcomes compared to constructions based on only one distribution. Another difference lies in the fact that triangular numbers are constructed by varying the confidence probability of a confidence interval based on the estimator, while the external interval we use in this paper is fixed. Moreover, there is no probabilistic statement about the values within that interval.

In the present study, we analyze the frequentist properties of estimators if external information is used, that can be expressed as moment conditions and thus does not use complete distributions as prior information. To our knowledge, there is no general framework for robustly incorporating such quantitative external information into frequentist analysis. Since this would offer the advantage of improving upon classical inference procedures widely used in psychology, our goal is to present such a framework. The use of these external moment conditions in addition to the moment conditions used to estimate the model parameters leads to an overidentified system of moment conditions. The main idea to find well performing estimators for such “externally” overidentified systems is the framework of the Generalized Method of Moments (GMM) (Hansen, 1982). This idea has already been used in the econometric literature, for example, by Imbens and Lancaster (1994) who combine micro- and macro-economic data and by Hellerstein and Imbens (1999) by constructing weights for regression models based on auxiliary data. A different yet related way to incorporate external moment-information is the empirical likelihood approach (Owen, 1988). This technique is quite frequently used in the literature, for example, in finite population estimation (Zhong & Rao, 2000) and for externally informed generalized linear models (Chaudhuri et al., 2008). Both approaches have in common that the use of external information may increase the efficiency of an estimator and/or reduce its bias.

Actually, in Sect. 3, we show that there will always be a variance reduction, if the external moment conditions and the ones for the model are correlated and if the covariance matrix of all moment conditions is positive definite. As the GMM allows the estimation of a large class of models, and many statistical measures like proportions, means, variances and covariances are statistical moments, the range of possible applications is large but far from being implemented in psychological research. For a multiple linear model, we derive the estimators analytically in Sect. 3. The use of imprecise probabilities will increase the overall variation of the estimator, and moreover, the effect of the variance reduction will decrease. As we will demonstrate, however, variance reduction will still be possible while increasing the robustness of the estimation. The proposed method and techniques allow more precise and robust inferences, which is particularly relevant in small samples. To illustrate the small sample performance of the externally informed models in multiple linear models, a simulation study is presented in Sect. 5. An application to a real data set analyzing the relation of premorbid (general) intelligence and performance in lexical tasks (Pluck & Ruales-Chieruzzi, 2021) is presented in Sect. 6.

Externally Informed Models

In a first step, we assume that precise external information is available, an assumption that will be relaxed in Sect. 4. Throughout, we assume that all variables will be considered as random variables if not given otherwise. For notational clarity, we will always write single-valued random variables in italic small letters. Vectors as well as vector-valued functions will be written in small bold letters and matrices in bold capital letters.

Although the basic concepts are presented in the following section, for the class of general regression models, we will consider the family of linear models for their illustration in a concrete class of models due to their frequent use. Note that, for example, ANOVA models are special cases of this model, however, with fixed factors instead of random covariates. Nevertheless, the results derived in this paper carry over to these models.

Let z=(z1,⋯,zp)T be a real-valued random vector and zi, i=1,⋯,n, be i.i.d. random vectors distributed like z, representing the data. Suppose we want to fit a regression model to this data set with fixed parameter θ∈Rp, where the adopted model reflects the interesting aspects of the true data-generating process and θ0 is the true parameter value. In linear regression models, the parameter of scientific interest is usually the parameter of the mean structure denoted as β=(β1,⋯,βp)T with true value β0. The notation β will only be used for linear regression models, while we will use θ to denote the regression coefficients in general regression models. The random vector z is given by z=(xT,y)T with random explanatory variables x=(x1,⋯,xp)T and dependent variable y. Accordingly, the unit specific i.i.d. random vectors z are written as zi=(xiT,yi)T for i=1,⋯,n. Hence, the random (n×p)-design matrix is X=(x1,⋯,xn)T, and we write y=(y1,⋯,yn)T.

The multiple linear model can now be written as y=Xβ0+ϵ with random error terms ϵ=(ϵ1,⋯,ϵn)T. As an illustration, suppose we want to investigate the effect of the explanatory variables fluid intelligence and depression on the dependent variable mathematics skills. We could design a study, in which fluid intelligence and math skills are measured via Cattell’s fluid intelligence test, in short CFT 20-R, (x2) and the number sequence test ZF-R (y), respectively (Weiss, 2006). Depression could be measured as a binary variable indicating if a person has a depression-related diagnosis (x3). The model could be a linear multiple regression of the ZF-R score on the depression indicator and the CFT 20-R score for fluid intelligence. To include the intercept, x1 is a degenerate variable with value 1.

In addition to the observed data and the assumptions justifying the model, we often have available external information like means, correlations or proportions, e.g., through official statistics, meta-analyses or already existing individual studies. In our applied example, there are various German norm groups for the CFT 20-R and the ZF-R, even for different ages (Weiss, 2006). Hence, we could always transform the results into scores with known expected value and variance, i.e. the CFT 20-R score can be transformed into an IQ-score based on a recent calibration sample from 2019, reported in the test manual (Weiss, 2019). Regarding the relation of fluid intelligence and math skills, a recent meta-analysis based on more than 370,000 participants in 680 studies from multiple countries suggests a correlation of r=0.41 between the two variables (Peng et al., 2019). In addition, based on a study covering 87% of the German population aged at least 15 years, Steffen et al. (2020) report a prevalence of depression, defined as a F32, F33 or F34.1 diagnosis following the ICD-10-GM manual, of 15.7% in 2017.

Let us assume that these values can be interpreted as true population values, an assumption that will be relaxed later. Note that they have the form of statistical moments. For example, the observable depression prevalence is assumed to equal the expected value of the binary depression indicator (first moment), the mean (now considered as expected value) and variance of the test scores are set equal to the first moment and the second central moment, respectively, of the random variables CFT 20-R-score and ZF-R-score. Finally, the correlation is assumed to equal the mixed moment of the standardized CFT 20-R-score and ZF-R-score. Taking q to be the number of known external moments, we state

Definition 1

Let M be a statistical model. Further let u be a (q×1)-vector of statistical moment expressions and μex the corresponding (q×1)-vector of externally determined values for the statistical moments in u. Then the model combining M and the conditions u=μex is called externally informed model.

To illustrate the definition, we will use the applied example from above in which case the model M is a multiple linear regression model. Interpreting the norms for the dependent variable ZF-R from the calibration sample as population values, external knowledge about the corresponding moments, for example the means of ZF-R, is available. Let us assume that ZF-R is transformed into the IQ-scale. Then, if u=E(y) and μex=100, we get E(y)=100×1n=E(X)β0, where 1n is a (n×1)-vector of ones. Thus, u=μex imposes conditions on β.

Estimation and Properties of Externally Informed Models

Generalized Method of Moments with External Moments

The GMM approach (Hansen, 1982) allows to estimate (general) regression models and to incorporate external moments into the estimation (Imbens & Lancaster, 1994). To estimate the parameter of a general regression model, a “model moment function” m(z,θ) must be given, which satisfies the conditions E[m(z,θ)]=0 only for the true parameter value θ0. The corresponding “sample moment function” for zi will be denoted as m(zi,θ). In case of the linear regression model from Sect. 2, the model moment function corresponding to the method of Ordinary Least Squares (OLS) is m(z,β)=x(y-xTβ) (Cameron & Trivedi, 2005, p. 172). Given the model is correctly specified, for true parameter value β0, E[m(z,β0)]=E[x(y-xTβ0)]=0 holds. Replacing these population model moment conditions by corresponding sample model moment conditions,0=1n∑i=1nm(zi,β)=1n∑i=1nxiyi-xiTβ=1nXT(y-Xβ),

and solving these estimating equations for β, leads to an estimator β^ for β0. The above conditions are identical to the estimating equations resulting from the least-squares or, if normality of the errors is assumed, the maximum likelihood method. Furthermore, the general classes of M- and Z-estimators can be written using estimating equations that have this moment form. This leads to broad applicability, since these classes, for example, include the median and quantiles (Vaart, 1998).

The possibly vector-valued “external moment function” will be denoted as h(z)=u(z)-μex, where the functional form of u(z) depends on the external information included into the model. We assume that μex=E[u(z)], so that E[h(z)]=0. If, for example, the expected value of y is known to be E(y)=100, then u(z)=y, μex=100 and h(z)=y-100. The corresponding sample moment condition is 0=1n∑i=1n(yi-100) (Imbens & Lancaster, 1994).

To simplify the presentation, we define the combined moment function vector in general regression models as g(z,θ)=[m(z,θ)T,h(z)T]T in what follows and assume that E[1n∑i=1ng(zi,θ0)]=0 holds. Note that the number of moment conditions exceeds the number of parameters to be estimated, i.e. the externally informed model is overidentified. This means that there will in general be no estimator θ^ that solves the corresponding sample moment conditions 1n∑i=1ng(zi,θ)=0. To deal with the overidentification problem, we will use the GMM approach (Hansen, 1982), that finds an estimator as “close” as possible to a solution of the sample moment conditions. This is done by maximizing a quadratic form defined by a chosen symmetric, positive definite weighting matrix W in the moment functions of the sample. The efficiency of the estimator is affected by W, and this can be chosen to maximize the asymptotic efficiency of the estimator in the class of all GMM-estimators based on the same sample moment conditions (Hansen, 1982). This optimal weighting matrix is W=Ω-1, where Ω=E[g(z,θ0)g(z,θ0)T]. However, this optimal W is unknown in practice and must be estimated by a consistent estimator W^.

Definition 2

(Newey & McFadden, 1994, p. 2116) Let g(z,θ) be a vector-valued function with values in RK, that meets the moment conditions E[g(z,θ0)]=0. Further let W^∈RK,K be a positive-semidefinite, possibly random matrix, such that (rTW^r)1/2 is a measure of distance from r to 0 for all r∈RK. Then, the GMM-estimator θ^ex is defined as the θ, which maximizes the following function:Q^n(θ)=-1n∑i=1ng(zi,θ)TW^1n∑i=1ng(zi,θ).

The GMM approach provides consistent and normally distributed estimators under mild regularity conditions (Newey & McFadden, 1994, p. 2148) for a wide range of models, like linear or nonlinear, cross-sectional or longitudinal regression models. Note that we have not assumed that W^ is invertible because we will mainly derive asymptotic expressions based on W for which the invertibility of W^ is not necessary. However, when deriving estimators, additional assumptions about invertibility must be made, which we explain in Sect. 3.2. Let G=E[∇θg(z,θ0)] be a fixed matrix and W the optimal weighting matrix, then Var(θ^ex)=1n(GTWG)-1. This variance expression is not informative with respect to a possible efficiency gain of the GMM-estimator if external information is used. Hence, the following corollary explicitly shows the effect of the external information on the variance of θ^ex.

Corollary 1

Assume θ^M is the GMM-estimator based on the model estimating equations alone (ignoring the external moments), and that m(z,θ) and θ have the same dimension. Using the prerequisite g(z,θ)=[m(z,θ)T,h(z)T]T it follows, that Ω has the block formΩ=E[m(z,θ)m(z,θ)T]E[m(z,θ)h(z)T]E[h(z)m(z,θ)T]E[h(z)h(z)T]=ΩMΩRTΩRΩh

and that1 E[∇θm(z,θ0)]T-1ΩRTΩh-1ΩRE[∇θm(z,θ0)]-1

A proof of Corollary 1 can be found in the supplementary materials online. Note that (1) shows that Var(θ^ex) is equal to the conditional variance of θ^M under the external moment conditions, since the asymptotic distribution is normal. This equality shows why there is a reduction in the variance. Let the second term on the right-hand side of (1) be denoted by D, then Var(θ^ex) can be written as Var(θ^ex)=Var(θ^M)-D. If D is nonnegative definite and not equal to 0, then including external moments leads to an expected efficiency gain in θ^ex as compared to θ^M. That D≠0 is nonnegative definite if ΩR≠0 is easily seen by noting that Ωh-1 is positive definite and therefore can be written as Ωh-1=Ωh-1/2Ωh-1/2, where Ωh-1/2 is the positive definite square root of Ωh-1. Since nD can be written as the product of {E[∇θm(z,θ0)]T}-1ΩRTΩh-1/2 with its transpose, D is nonnegative definite. In summary, ΩR≠0 is a necessary and sufficient condition for the presence of variance reduction based on Corollary 1. Finally, it should be noted that Var(θ^ex) can consistently be estimated via the plug-in approach (e.g. Newey & McFadden, 1994, pp. 2171–2173) by replacing all unknown expected values by sample means.

The Externally Informed Multiple Linear Model

In linear models, θ^ex is denoted as β^ex. For analytical simplicity, in this section, we assume the Gauss–Markov assumptions hold, specifically E(ϵi)=0,Var(ϵi)=σ2,Cov(ϵi,ϵj)=0 for all i≠j with i,j=1,⋯,n, and independence of the explanatory variables and the error terms ϵ. Furthermore, we assume the errors to be normally distributed in small samples. Analytical solutions to the estimating equations exist under these assumptions:

Theorem 1

Let H=[h(x1,y1),⋯,h(xn,yn)]T be the (n×q) random matrix containing the externally informed sample moment functions and 1n a (n×1)-vector of ones. Further let Ω^h and Ω^R be consistent estimators of the corresponding matrices in Corollary 1. Then, the (consistent) externally informed OLS estimator is:β^ex=(XTX)-1XTy-(XTX)-1Ω^RTΩ^h-1HT1n

and its variance isVar(β^ex)=Var(β^)-D=1nσ2ExxT-1-1nExxT-1ΩRTΩh-1ΩRExxT-1,

where σ2 is the variance of the error in the assumed linear model.

The proof of Theorem 1 is given in the supplementary materials online. Note that only the assumption of invertibility of Ω^h is made, which is weaker than the assumption that Ω^ is invertible. From Theorem 1, it is not immediately obvious which of several possibly available functions may lead to a variance reduction. Therefore, let us consider some external moment functions and their possible effects on the variance of β^ex. Note that inclusion of external moment functions into the estimating equations may lead to expected efficiency gains only if ΩRT=E[x(y-xTβ0)h(x,y)T]=E[xϵh(x,y)T]≠0 holds.

Let the expressions σxj and σy denote the population standard deviations of xj and y, respectively, whereas σxj,y indicates the covariance of xj and y. To denote the covariance vector (σx1,xj,⋯,σxp,xj)T of x and xj the expression σx·,xj is used, including σj2 at the j-th position. Finally, ρxj,y is the population correlation of xj and y.

First, consider some function f(x) of x, i.e. h(x)=f(x)-E[f(x)]ex, where E[f(x)]ex is the known expected value of f(x). If the assumptions underlying the linear model hold, then ΩR=E[xϵh(x)T]=0 because ϵ is independent of f(x) and E(ϵ)=0. Thus, according to the results of Sect. 3.1, there will be no variance reduction if the external moment function is a function of the explanatory variables only. In the example described in Sect. 2, there will be no efficiency gain if the 15.7%-prevalence of depression is used as external information to estimate the linear regression model.

On the other hand, if the external moment function is a function of ϵ, then generally, E[xϵh(x,y)T]≠0. In the example, assume that the correlation between fluid intelligence and math skills reported in Peng et al. (2019) is taken as external information, in which case h(x,y)=h(x2,y)=[y-E(y)][x2-E(x2)]/(σx2σy)-ρ(x2,y)ex, where ρ(x2,y)ex=0.41. Then E[xϵh(x2,y)]=[σ2/(σx2σy)]σx·,x2 will not in general be zero, and hence, there will, in general, be efficiency gains with respect to β^ex. For more examples, see Table 1 and for the derivation of the results, see the supplementary materials online. It should be noted that if the distribution of the errors is not symmetrical, then E(x)E(ϵ3) has to be added to the entries in column ΩRT of Table 1 for the cases E(y2) and σy2, see the supplementary materials online for further details.Table 1 Forms of ΩRT for various single moments.

Moments	h(x,y)	ΩRT	
E(y)	y-E(y)ex	σ2E(x)	
E(xjy)	xjy-E(xjy)ex	σ2E(xj·x)	
E(y2)	y2-E(y2)ex	2σ2E(xxT)β0	
σy2	[y-E(y)]2-(σy2)ex	2σ2[E(xxT)β0-E(y)E(x)]	
σxj,y	[y-E(y)][xj-E(xj)]-(σxj,y)ex	σ2σx·,xj	
ρxj,y	[y-E(y)][xj-E(xj)]σxjσy-(ρxj,y)ex	σ2σxjσyσx·,xj	
βxj,y	[y-E(y)][xj-E(xj)]σxj2-(βxj,y)ex	σ2σxj2σx·,xj	
The subscript ex indicates externally determined values. In the last line, βxj,y represents the expected value of the estimator of the slope from a simple linear regression model, which is identical to the true value of the slope only if xj is independent of the other explanatory variables.

Table 2 Effects of various single moments in terms of variance reduction.

Moments	D	Effect on	
E(y)	σ4nωhe1e1T	Only β1	
E(xjy)	σ4nωhejejT	Only βj	
E(y2)	4σ4nωhβ0β0T	All βj≠0	
σy2	4σ4nωh[β0-E(y)e1][β0-E(y)e1]T	All βj≠0 and β1	
σxj,y	σ4nωhe~je~jT	βj and β1	
ρxj,y	σ4nωhσy2σxj2e~je~jT	βj and β1	
βxj,y	σ4nωhσxj4e~je~jT	βj and β1	
The expression ej denotes the (p×1)-vector with 1 at the j-th position and zeros elsewhere. Further we set e~j:=-E(xj)·e1+ej. In the last line, βxj,y represents the expected value of the estimator of the slope from a simple linear regression model, which is identical to the true value of the slope only if xj is independent of the other explanatory variables.

Table 2 presents, in the second column, the absolute variance reduction for the parameters if the external information given in the first column is used to estimate the regression model. The third column in Table 2 shows which entries of the parameter β can be estimated more precisely if the external information is used. The results of Table 2 are derived in the supplementary materials online. Note that Ωh is written as ωh here, as it is single-valued. It holds that ωh=E[h(x,y)2], where h(x,y) is of the form given for various moments in Table 1. However, this expression often includes the terms E(ϵ) and E(ϵ3), which are already set to zero in ΩRT (see supplementary materials online). In order to avoid invalid estimates, E(ϵ) and E(ϵ3) should be set to zero in ωh. For example, if the correlation between fluid intelligence and math skills reported in Peng et al. (2019) would be used in the regression from math skills on fluid intelligence and depression, then the variance of the estimator weighting the variable fluid intelligence would be reduced by:σ4nωhσy2σx22=σ4nVar{[x2-E(x2)][y-E(y)]}.

This means that there will be a variance reduction in all practically relevant cases, where σ2≠0 and Var{[x2-E(x2)][y-E(y)]}<∞ hold. For a comparison of the effects of the different external moments, the corresponding relative variance reductions may be of interest. These are obtained by dividing the j-th diagonal element of the absolute reductions in Table 2 by 1nσ2E(xxT)(j,j)-1, where E(xxT)(j,j)-1 denotes the element of the inverse of E(xxT) in the j-th row and the j-th column. For the resulting expressions it is clear that n factors out, as D also includes 1n as the only factor depending on n, while the rest are fixed values. Hence, the relative efficiency gains do not vanish with increasing n, but are constant. In our example, the known correlation ρx2,y=.41 exerts an expected relative variance reduction ofσ2E(xxT)(2,2)-1Var{[x2-E(x2)][y-E(y)]},

which is independent of n and does not vanish for large σ2. Including more than one external moment is straightforward. In that case Ωh includes not only variances but also covariances of the external moments which may lead to additional variance reduction. To illustrate this effect, consider the example from Sect. 2 using the external moments ρ(x2,y)ex=0.41 and E(x2)ex=100. For the sake of simplicity and without loss of generality we assume x2 and y to be centralized. In this example, the external moments ρx2,y and E(x2) are included in the externally informed multiple linear model, leading to ΩRT=0σ2σx2σyσx·,xj according to Table 1, andΩh=Var(x2)Cov(x22,y)σx2σyCov(x22,y)σx2σyVar(x2y)σx22σy2

via definition, wherein Var(x2y) is the scalar variance of x2 times y. Using the notation of Table 2, the explicit inversion formula for (2×2)-matrices impliesD=1nExxT-1ΩRTΩh-1ΩRExxT-1=1nExxT-1σ2σx2σyσx·,xj(Ωh-1)(2,2)σx·,xjTσ2σx2σyExxT-1=σ4(Ωh)(1,1)ndet(Ωh)σx22σy2e~2e~2T=σ4nVar(x2y)-Covx22,y2σ22e~2e~2T,

where det(A) denotes the determinant of matrix A. Assuming both variances to be finite and positive and invoking the Cauchy–Schwartz inequality, the fraction Cov(x22,y)2/σ22 will not exceed Var(x2y) and hence D will be nonnegative. Further, if x22 and y have a covariance different from 0, the variance will decrease even further, compared to the reduction due to ρx2,y alone. Hence, β1 and β2 can in general be estimated even more efficiently, if E(x2) is used in addition.

Additional Remarks

Using many moments, however, increases the risk of a near-singular Ω matrix, especially if the moments are strongly mutually (linear) dependent. Calculation of the GMM-estimator with additional external moment functions often includes unknown population moments, like E(x) or σy2 (see Table 1), which may be replaced by the corresponding sample moments. However, ΩR and Ωh may in addition be functions of unknown σ2 or β0, as can be seen in Table 1. Hence, the externally informed GMM-estimator is calculated iterating over the following steps until convergence: First estimate the model using the ordinary least squares approach without external moments to get σ^2 and β^ and then estimate β^ex based on the estimates from the former step.

Statistical inference with a GMM-estimator can be based on the Wald test, which simplifies to a t-test if single regression coefficients are tested and its approximative normality can be used to construct confidence intervals (Cameron & Trivedi, 2005). However, in small samples or when dealing with complex models, it is sometimes better to use a bootstrap method (Cameron & Trivedi, 2005; Spiess et al., 2019, p. 177).

As this approach combines data from different sources, one should take into account the issues arising in meta-analyses in general. The Cochrane Handbook for Systematic Reviews of Interventions (Higgins et al., 2019) and the PRISMA statement (Page et al., 2021) should be considered to select proper sources of external information, which are as up-to-date and as close as possible to the same population, method and design of the study one wishes to use the externally informed model in. This is important because a core regularity condition of the GMM is that the expected values of the moment functions are zero, which can be violated, if the external moment and the data were taken from different populations. As a possible approach to deal with this compatibility issue, the GMM framework incorporates the Sargan–Hansen test to test if the overidentification due to the additional moment conditions causes a Q^n(θ^ex) significantly larger than 0 (Hansen, 1982; Sargan, 1958). Another option to test for incompatibility especially in linear regression models is the Durbin–Wu–Hausman test (Hausman, 1978), as it compares two estimators of the same parameter. We will take a different approach here, as we will instead relax the assumption of correct external point-values to intervals containing the true value.

Robustness due to Interval Probability

External information is only an estimate itself and thus prone to uncertainty. A classical approach to analyze and prevent the issues of misspecification and thus misleading inferences is to use robust models (Huber, 1981). Hence, it is important to use techniques to robustify the estimation of the externally informed model. In this paper, we will adopt an approach based on the theory of imprecise probabilities due to Weichselberger (2001), that is capable of dealing with probabilistic and non-probabilistic uncertainty, not depending on a fully specified stochastic model. The advantage is that instead of distributional assumptions we only need bounds for the true external values. It would be possible to model the uncertainty in the external information within a probabilistic, e.g., a Bayesian, framework. However, this framework would replace uncertainty in the external information by assuming an additional parametric model of its estimation process in form of precise prior distributions. Moreover, it is not straightforward to represent only certain distributional aspects (moments) within a Baysian approach, e.g., the external information 100=E(y)=E(x)Tβ0 presented in Sect. 2.

Externally Informed Models Based on Interval Information

Assume that Iex is an interval containing the true value of an unknown external moment. Hence every value in the interval could be the true one. To illustrate a possible way to construct an Iex, we use our earlier example. In our application example, we have a 95% confidence interval of [0.39, 0.44] for the correlation between fluid intelligence and mathematical skills (Peng et al., 2019). This is, of course, an interval that includes the true value only with a positive probability, but not with certainty. However, combining this confidence interval with the results of other studies on this or a similar correlation, and thus possibly widening the interval, the resulting interval serves as a subjective, rough approximation for Iex. We illustrate the use of this technique in Sect. 6.

In this section, we discuss another way of constructing Iex. Regarding the estimated depression prevalence of 0.157 in Steffen et al. (2020), we know that 87% of the population has been investigated. Thus, we can construct an interval by the technique proposed, e.g., in Manski (1993, 2003), Manski and Pepper (2013), Cassidy and Manski (2019). The two extreme cases that could occur are that no person of the 13% unobserved individuals has a depression and on the other extreme that all of these individuals have a depression. As 87% of 0.157 is 0.137, we get the interval [0.137, 0.267] for the prevalence. The advantage of such intervals is that they completely compensate for the missing values without any further assumptions. Having available an interval for the external information, one can adopt a technique denoted as cautious data completion proposed by Augustin et al. (2014, p. 182) to determine based on Iex the sets of possible values for the estimator itself and its variance estimator. In our setting, this amounts to evaluating the estimator for the externally informed linear model and its variance estimator from Theorem 1 traversing Iex. This leads to a set Bex of possible parameter estimates and a set Vex of possible variance estimates. These sets of estimates are compact and connected in the strict mathematical sense, since both estimators are continuous functions on the external interval.

F-Probability

Interval-based inferences can be justified by adopting the concept of F-probabilities (Augustin, 2002; Weichselberger, 2000).

Definition 3

(Augustin 2002) Let Ω be a set and A be a σ-algebra on Ω. Further, let K(Ω,A) be the set of all probability measures on (Ω,A). Then, a set-valued function F(·) on A is called F-probability with structure M, if there are functions L(·),U(·):A→[0,1] such that for every event A∈A it holds that L(A)≤U(A) and F(·) has the form F(·):A→{[a,b]|a,b∈[0,1]anda≤b}A↦F(A):=[L(A),U(A)]for every eventA∈A,

the set M:={P(·)∈K(Ω,A)|L(A)≤P(A)≤U(A),for allA∈A} is not empty,

for all events A∈A it holds that infP(·)∈MP(A)=L(A) and supP(·)∈MP(A)=U(A).

For most applications, it is sufficient to restrict to the case Ω=Rd and let A be the corresponding Borel σ-algebra. F-probabilities are best understood as a representation of a “continuous” set of probability measures. For example, consider all normal distributions with a variance of 1 and a mean between -0.5 and 0.5. If we consider all these distributions as possible true distributions for a random variable X and evaluate an event in terms of its probability, we obtain a set of possible probability values. Consider the event A={X≤0}, its possible probability ranges from 0.3085 (for mean 0.5) to 0.6915 (for mean -0.5) and thus P(A)∈F(A):=[0.3085,0.6915]. If this procedure is performed for all A∈A, the resulting F(·) is an F-probability. In general, given any nonempty set P of probability measures, one can construct the narrowest F-probability containing P by defining F(A):=[infP∈PP(A),supP∈PP(A)] for each event A∈A, cf. Remark 2.3. in Augustin (2002). If the intervals F(A) consist of one element for all A, the F-probability simply corresponds to a single probability measure. Thus, it is a natural generalization of the conventional notion of probability, using simultaneously a range of probability measures between a lower bound and an upper bound. An important property of F-probabilities for ensuring robustness is that their structure M (all the probability measures covered by F(·), in the sense of condition 2 in Definition 3) is generally larger than the set P (called pre-structure) of probability measures used to construct them, since the structure is closed under convex combinations (Augustin, 2002). For two probability measures P and Q, this follows by the basic inequality that for all 0≤ϵ≤1 and A∈A it holds thatmin(P(A),Q(A))≤ϵP(A)+(1-ϵ)Q(A)≤max(P(A),Q(A)).

For example, convex combinations of normal distributions are not themselves normally distributed and include skewed and bimodal distributions. This illustrates that robustness with respect to distributional assumptions increases compared to using normal distributions alone. Unlike other concepts that reflect uncertainty about probability measures, such as triangular numbers (fuzzy numbers), there is no preference for one distribution over another caused by weighting functions or possibility distributions. This agnosticism regarding the true distribution also covers deterministic ambiguity to some extent. For instance, in our example, a deterministic alteration of μ over time, where μ(t)∈[-0.5,0.5] for all t, like μ(t)=0.5sin(t), would still be covered by the F-probability at any time t because the F-probability covers the range of μ(t). In applied research, the exact form of deterministic variation of μ is typically unknown, but if its bounds are known to lie within an interval, the F-probability based on this interval would account for it. Of course, these advantages come at the cost of greater conservatism than using a single probability distribution.

In our framework, the assumption of knowing the true moment value can be relaxed to assuming that an interval is known containing the unknown true moment value. As the GMM-estimator is asymptotically normally distributed for the true value of the external moment, we asymptotically get a pre-structure consisting of all normal distributions for estimator β^ex with expected value inside Bex and with variance inside Vex. This pre-structure is guaranteed to contain the normal distribution based on GMM asymptotics, since the true external moment value is assumed to be in Iex. Therefore, for each event, the probability assigned to an event by this true normal distribution will lie between the lower and upper bounds assigned to that event by F(·), possibly leading to more conservative but valid statistical inference. Based on this pre-structure, we get an F-probability. Statistical inference based on F-probabilities is done by treating the probability intervals as a whole, e.g., by interval arithmetic. We demonstrate this principle by constructing an equivalent to confidence intervals in the context of F-probabilities in the next section.

Confidence Intervals for the Externally Informed Model Under F-Probabilities

The construction of confidence intervals (point-CIs) is in general not possible in the framework of F-probabilities, because instead of a single probability value lower and upper bounds are assigned to an event. One possibility, however, is to use the union of all possible point-CIs traversing Iex. The idea to calculate unions of intervals already has been investigated for Bayesian highest density intervals in an imprecise probability setting by Walter and Augustin (2009). Let θ^e,j be the j-th entry of the externally informed GMM-estimator θ^ex using external value e, we define the (1-α)·100% confidence union for θj to be⋃CI1-α:=infe∈Iex[θ^e,j-t1-α2,n-pVar^(θ^e,j)],supe∈Iex[θ^e,j+t1-α2,n-pVar^(θ^e,j)]

Because the true external moment value is in Iex, the borders of the point-CI constructed via the true moment value lie between the infimum and the supremum of the lower and upper borders, respectively, of all point-CIs on Iex. Therefore, ⋃CI1-α covers the point-CI constructed via the true moment value. The asymptotic normal distribution of β^ex at the true value of the external moment implied by the asymptotic properties of GMM-estimators described in Sect. 2 ensures that the confidence union covers the true parameter asymptotically with probability at least 1-α.

An approximation of the confidence union can be calculated using grid search traversing Iex. If the point-CIs used to construct ⋃CI1-α differ, then the resulting interval is wider than every of these point-CIs. This demonstrates that the positive effect of the variance reduction (a shorter CI) can be reversed by the length of Iex. The reason is that a broader Iex increases the set over which infimum and supremum are taken, possibly expanding ⋃CI1-α. However, we will show in a simulation study in Sect. 5 that in some cases it is possible to get a ⋃CI1-α shorter than the (1-α) confidence interval based on the OLS multiple linear regression. Hence, the variance reduction can compensate the broadening of ⋃CI1-α introduced by Iex. Finally, using ⋃CI1-α strengthens the robustness through the F-probability, on which ⋃CI1-α is based, as it also includes, e.g., bimodal and skewed distributions.

A Simulation Study

Settings

To test the externally informed GMM approach for multiple linear models in small samples, we conducted two simulation studies. The first setting illustrates possible variance reduction if correctly specified external moments are used and shows that the usage of small external moment intervals can lead to confidence unions that may even be shorter than the OLS confidence interval. In the second setting, we focus on misspecified external information and non-normal errors. In this case, it is interesting to see, if inferences are still valid and whether the effects of the variance reduction illustrated in the first setting still occur. The simulation script was written and executed in R version 4.2.1 (R Core Team, 2022), the script can be found in the supplementary materials online. The function interval_gmm() implements the calculation of intervals of estimators and of their standard deviation, as well as confidence interval unions. In both settings, we used an intercept (x1=1), a normally distributed variable x2∼N(2,4) and a binary variable distributed according to Bernoulli distribution x3∼Bernoulli(0.4) as explanatory variables. The response variable was generated according to y=x1+0.5x2+2x3+ϵ, where ϵ∼N(0,9) in the first setting. In the second setting, the errors were generated by affine transformation of a χ12-distributed random sample, so that its mean is 0 and its variance is 9. The settings were selected, so that all required moments can easily be calculated, which is done before the simulations. The ratio of explained variance to total variance was 1-9/Var(y)=1-9/10.96=0.178 a value which is similar to often reported values in psychological research. This amounts to a relatively high error variance, a factor for possibly large variance reduction for some external moments (see Sect. 3).

Different moments have different scales, so a similar interval width of Iex does not imply similar “sharpness” of the external information across scales. To create intervals for the external information, that are comparable across the different scales of the external moments, we have used external intervals where the ratio of half their width to their center is the same for all external moments in each setting. It should be noted that this technique is different from the design techniques discussed in Sect. 4.1. The reason for this difference is that the simulation study aims to compare the different moments in terms of their effectiveness and statistical validity in a context where the Iex are comparable in magnitude and contain the true value. To motivate this, one could compare the given ratio to the coefficient of variation. For the standard IQ-scale, the coefficient of variation is 15/100=0.15. For the first setting, we arbitrarily chose a ratio of 0.1 to represent somewhat more precise external information than one standard deviation in the IQ-scale around the center. For the second setting, we have chosen a ratio of 0.3 to represent a radius of two standard deviations in the IQ-scale and thus an approximate confidence interval width that takes the IQ-scale as a basis. In the first setting, we created intervals that were symmetrical around the true external value. Hence, if the true external value was e, then the interval was Iex=[0.9e,1.1e]. In the second setting, we first multiplied all true external moment values by 1.3. Since none of these true external values were equal to zero, this resulted in misspecified point values. These misspecified values were used as external point values during the simulation to test the sensitivity of the externally informed model based on point information. The constant 1.3 was again chosen arbitrarily and leads to a relative bias of 30%. Then, as in the first setting we generated a symmetric interval around the misspecified value. If e again denotes the true external value, 0.7·1.3e=0.91e was the lower limit and 1.3·1.3e=1.69e the upper limit of Iex, i.e. Iex=[0.91e,1.69e], which contains the true value e. As for sensitivity, tests with center width ratio and misspecification values similar to 0.1, 0.3 and 1.3 gave similar results.

Sample sizes n chosen are 15, 30, 50, 100. The moments used are those listed in Table 2 for both, x2 and x3. Given the results in Sect. 3, the expected relative variance reductions were calculated to check if these settings are capable of providing enough variance reduction. For every moment condition in each setting we run 500 simulations. Only single moment conditions were used.

In a first step, all explanatory variables were generated and y was calculated as described above. In the second step, β^ex and Var^(β^ex) were calculated according to the following two-step GMM algorithm: Calculate β^ and σ^2 via the classical OLS method

Determine Ω^R, ω^h and β^ex based on β^ and σ^2

Recalculate σ^2,Ω^R and ω^h based on β^ex

Update β^ex and calculate Var^(β^ex)

Then, 95% confidence intervals were calculated based on β^ex and its estimated variance, using a t-distribution with n-3 degrees of freedom. Let β^ex be one element of β^ex, then it’s 95% confidence interval isCI0.95=β^ex-tn-3,0.975Var^(β^ex),β^ex+tn-3,0.975Var^(β^ex).

To calculate ⋃CI0.95 a grid search algorithm was adopted. First we determined 101 equidistant points in the given Iex (including the bounds of the interval). The number 101 was chosen after some preliminary tests of the algorithm as a compromise between precision and computing time. Then we traversed these grid points calculating β^ex and Var^(β^ex) using the two step procedure from above at each point. Comparing the bounds of the CIs sequentially, the minimal lower and maximal upper CI bounds on the grid points were determined and served as approximation for the bounds of ⋃CI0.95.

Results

As criteria to evaluate the statistical inferences, we calculated the mean β^¯ex of the estimates β^ex and their variances Var(β^ex) over 500 simulations. The latter will be compared to the corresponding means of estimated variances, Var^(β^ex)¯. To evaluate possible variance reduction for βj, the mean ratio of variance reduction to OLS-variance, Δ^j:=[Var^(β^OLS)-Var^(β^ex)](j,j)/[Var^(β^OLS)](j,j)¯, will be considered. In addition, the actual coverage is calculated over simulations. For given α=0.05 and 500 simulations, the actual coverage should be between 0.93 and 0.97 for the point-valued moments (Spiess, 1998) and equal to or greater than 0.93 for the external moment intervals, as the confidence union is used to calculate the coverage in this case. Finally, |CI|:=CI¯0.95-CI_0.95¯ and |⋃CI|:=⋃CI¯0.95-⋃CI_0.95¯ were computed. They can be compared to the OLS-CI-length to evaluate the possible precision gains or losses.

Results for the Correctly Specified Setting

The detailed results for sample size n=15 are presented in Table 3, while the results for the other sample sizes are given in Tables 7 to 9 in the supplementary materials. Consistent with the theory in Sect. 3, the use of the moment E(x2) had no effect on the variances, neither for the correctly specified nor for the misspecified setting, and estimation results were equal to OLS estimation results. The corresponding results are presented for comparison. For all moments except E(y2) and σy2 both the coverages for the point valued moments as well as the coverages for the external intervals exceeded 0.93. The coverages for σy2 were in the valid range only for n=100, while for E(y2) they were in the valid range already for n=50. The undercoverage for sample sizes below n=100 can be explained by the skewness of the distributions of their sample moment functions in small samples caused by the quadratic terms y2, leading to higher sample size required for the asymptotic results to be applicable. Using confidence unions only reduced these required sample sizes to n=50 and n=30, respectively, showing that high skewness is also problematic for ⋃CI-based coverage in small samples.Table 3 Results of the simulations with correctly specified external moments for sample size n=15.

Moments	βj	β^¯ex	Var(β^ex)	Var^(β^ex)¯	Δ^j	Cov	CovI	|CI|	|⋃CI|	
E(x2)	β1	1.045	1.929	1.968	0	0.944	0.944	5.866	5.866	
= OLS	β2	0.499	0.205	0.211	0	0.950	0.950	1.909	1.909	
β3	1.955	3.422	2.976	0	0.940	0.940	7.292	7.292	
E(y)	β1	1.048	1.453	1.593	0.217	0.942	0.964	5.215	5.639	
E(x2y)	β2	0.560	0.174	0.177	0.169	0.950	0.956	1.740	1.832	
σx2,y	β1	0.802	1.478	1.456	0.239	0.954	0.954	5.054	5.222	
β2	0.625	0.096	0.080	0.616	0.960	0.978	1.153	1.237	
ρx2,y	β1	0.928	1.405	1.418	0.258	0.944	0.948	4.984	5.141	
β2	0.562	0.069	0.074	0.639	0.976	0.984	1.110	1.188	
βx2,y	β1	0.967	1.263	1.414	0.255	0.960	0.964	4.982	5.131	
β2	0.543	0.054	0.072	0.633	0.986	0.986	1.107	1.180	
E(x3y)	β3	2.150	2.745	2.380	0.192	0.936	0.946	6.525	6.837	
σx3,y	β1	0.959	1.552	1.704	0.141	0.964	0.966	5.433	5.561	
β3	2.202	0.783	0.949	0.689	0.976	0.976	3.952	4.273	
ρx3,y	β1	0.977	1.659	1.694	0.148	0.960	0.960	5.415	5.541	
β3	2.136	0.888	0.919	0.699	0.964	0.970	3.891	4.208	
βx3,y	β1	0.942	1.545	1.700	0.143	0.964	0.970	5.426	5.559	
β3	2.182	0.692	0.908	0.698	0.976	0.980	3.888	4.213	
E(y2)	β1	1.072	1.965	1.935	0.018	0.914	0.936	5.807	5.950	
β2	0.507	0.207	0.204	0.031	0.942	0.946	1.875	1.929	
β3	1.995	3.414	2.871	0.030	0.916	0.930	7.164	7.367	
σy2	β1	0.905	1.951	1.708	0.142	0.920	0.928	5.434	5.667	
β2	0.540	0.228	0.184	0.148	0.896	0.910	1.766	1.839	
β3	2.092	3.646	2.584	0.151	0.858	0.878	6.725	7.005	
The expressions β^¯ex, Var(β^ex), Var^(β^ex)¯, Δ^j,|CI| and |⋃CI| are defined in the beginning of Sect. 5.2. The results for the moment E(x2) are equivalent to the OLS results. Cov is the coverage for the external point value and CovI symbolizes the coverage for the confidence interval union based on the external interval. Only the affected coefficients are reported per moment. The true values are β1=1, β2=0.5 and β3=2.

For βxj,y with j=2,3, the coverage for βj was in many cases above 0.97 (up to 0.994) for all n. This was also the case, though not as pronounced, when the external information about the covariance between xj and y was used. The reason for this is that the variances were mostly overestimated in these cases, as can be seen in Tables 3 and 4 as well as in Tables 7 to 12 in the supplementary materials by the fact that Var^(β^ex)¯ was larger than Var(β^ex) for the respective βj. Although variances are overestimated, the true and estimated variances nevertheless tend to be smaller than the variance of the OLS-estimators. Thus, inferences still tend to be more precise, suggesting a possible relationship with superefficiency (Bahadur, 1964).

As shown in Sect. 3, the relative variance reduction for each estimator of βj, reported in column Δ^j of Table 3 as well as Tables 7 to 9 in the supplementary materials, did not change significantly under the various conditions over the different sample sizes realized. The smallest relative variance reduction per βj was attained by using the external information E(y2), ranging from 0.018 to 0.059, followed by σy2 with a maximal relative variance reduction of 0.180. The largest relative variance reduction was attained by using the covariance, the correlation and βxj,y regarding βj, ranging from 0.633 to 0.734 for j=2 as well as from 0.698 to 0.857 for j=3. For all other moments the values varied between 0.169 and 0.294, see Table 3 and Tables 7 to 9 in the supplementary materials.

These variance reductions translated for all moments directly into a reduction of the length of the confidence interval for the external point value. For the external interval, the length of the union of the confidence intervals is always greater than the one derived from a single external point. These differences increase with larger samples, as the variance estimator decreases with increasing sample sizes, while it can be seen from the formulas in Theorem 1 that the interval for β^ex is only affected by the difference between the estimators and the true values of ΩR and Ωh, not directly by n. Finally, with regard to |⋃CI| compared to |CI| the results imply that at the sample sizes 15 and 30, using any moment except E(y2) resulted in a shorter confidence interval union than the OLS confidence interval. For n=50, this was the case for all moments except E(y2), E(y) and σy2. Finally, for n=100, only the moments σx2,y, ρx2,y, βx2,y, σx3,y, ρx3,y and βx3,y resulted in shorter confidence unions than point-CIs. This can be explained by the constancy of Iex while n increases. There is always an interval inside ⋃CI which does not vanish for large n, while |CI| converges to 0.

Results for the Misspecified Setting

The detailed results for sample size n=50 are presented in Table 4, while the results for the other sample sizes are given in Tables 10 to 12 in the supplementary materials. The coverage rates using the point-valued moments illustrate the expected sensitivity of the models due to misspecification. Even at n=15 more than half of the coverage rates are below 0.93, although in most cases they are still above 0.9. The severeness increases with increasing n: For n=30 only five coverage rates are in the acceptable range of at least 0.93. As seen in Table 4 for n=50 the coverage is as low as 0.586 in the worst case for β3 if σx3,y is used. Finally, for n=100 all coverage rates are invalid, see Table 12 in the supplementary materials. Except for the moments E(y2) and σy2, this is corrected by the union of confidence intervals based on the external interval, since all coverage rates in these cases are above 0.93, except the one for β1 using σx2,y while n=15. Like in the correctly specified setting, there are considerably larger coverage rates for the moments βxj,y and lower coverage rates for σy2 or E(y2) even in the cases n=30 and n=15. The explanations for these over- and undercoverages are the same as for the correctly specified case in Sect. 5.2.1. However, only the use of covariance, correlation or β for xj and y for j=2,3 resulted in narrower confidence unions as compared to OLS confidence intervals, not the use of other moments. Regarding βj for j=2,3 this is the case for every n, regarding β1 this is only the case for n=15. We conclude that the use of external intervals for covariances, correlations or β not only corrects low coverage rates due to misspecified point values for external moments, but can also lead to narrower (unions of) confidence intervals.Table 4 Results of the simulations with misspecified external moments for sample size n=50.

Moments	βj	β^¯ex	Var(β^ex)	Var^(β^ex)¯	Cov	CovI	|CI|	|⋃CI|	
E(x2)	β1	1.012	0.440	0.509	0.936	0.936	2.778	2.778	
= OLS	β2	0.488	0.041	0.049	0.960	0.960	0.865	0.865	
β3	2.042	0.751	0.803	0.954	0.954	3.494	3.494	
E(y)	β1	1.636	0.412	0.376	0.782	0.992	2.397	4.032	
E(x2y)	β2	0.615	0.031	0.040	0.924	0.984	0.779	1.062	
σx2,y	β1	0.733	0.307	0.380	0.912	0.954	2.409	2.922	
β2	0.627	0.016	0.016	0.864	0.984	0.496	0.747	
ρx2,y	β1	0.756	0.243	0.380	0.952	0.968	2.401	2.914	
β2	0.617	0.019	0.016	0.880	0.996	0.494	0.744	
βx2,y	β1	0.768	0.271	0.376	0.926	0.960	2.397	2.901	
β2	0.610	0.008	0.015	0.948	0.998	0.488	0.735	
E(x3y)	β3	2.505	0.486	0.622	0.934	0.982	3.095	4.165	
σx3,y	β1	0.827	0.341	0.413	0.930	0.966	2.502	3.026	
β3	2.549	0.116	0.139	0.586	1.000	1.445	2.751	
ρx3,y	β1	0.830	0.291	0.413	0.956	0.978	2.498	3.025	
β3	2.525	0.341	0.138	0.642	0.978	1.434	2.739	
βx3,y	β1	0.822	0.346	0.412	0.922	0.966	2.499	3.030	
β3	2.537	0.092	0.135	0.618	1.000	1.428	2.740	
E(y2)	β1	1.136	0.512	0.513	0.914	0.944	2.802	3.151	
β2	0.558	0.053	0.049	0.894	0.948	0.863	1.011	
β3	2.318	0.846	0.790	0.894	0.958	3.477	4.093	
σy2	β1	0.512	0.894	0.433	0.698	0.828	2.543	3.361	
β2	0.626	0.067	0.044	0.754	0.896	0.806	1.029	
β3	2.597	1.054	0.697	0.750	0.896	3.234	4.167	
The expressions β^¯ex, Var(β^ex), Var^(β^ex)¯,|CI| and |⋃CI| are defined in the beginning of Sect. 5.2. The results for the moment E(x2) are equivalent to the OLS results. Cov is the coverage for the external point value and CovI symbolizes the coverage for the confidence interval union based on the external interval. Only the affected coefficients are reported per moment. The true values are β1=1, β2=0.5 and β3=2.

Application

To illustrate the possible benefits of using external information in a linear model, we reanalyze a dataset of Pluck and Ruales-Chieruzzi (2021), who investigated the estimation of premorbid intelligence based on lexical reading tasks in Ecuador. We will focus on their Study 2. Since the purpose of this analysis is to illustrate the proposed use of external information, we will only shortly sketch the theoretical background of the study. For a more detailed description, see Pluck and Ruales-Chieruzzi (2021). The dataset was downloaded from PsychArchives (Pluck, 2020a).

To quantify the cognitive impairment of patients, it is necessary to have an accurate baseline estimate observed in the premorbid state (Pluck & Ruales-Chieruzzi, 2021). As psychometric intelligence tests can be too long or cumbersome for elderly people with emerging cognitive impairments, it is important to have short, yet reliable tests for general intelligence. It is argued in Pluck and Ruales-Chieruzzi (2021) that vocabulary has a high positive correlation with general intelligence, hence using short lexical tests could be helpful to estimate general intelligence. Following Cattell’s classical theory, general intelligence can be divided into fluid and crystallized intelligence (Cattell, 1963). In this context, the variance reduction property of the externally informed linear model could provide an asymptotically unbiased estimate with higher precision than the estimates in Pluck and Ruales-Chieruzzi (2021), because external information about the correlation of general, fluid or crystallized intelligence and lexical tests is available. Although the different factors of intelligence are not identical, combining external information about them leads to a broader and thus more reliable external interval than using information about general intelligence alone, as the correlation between lexical tasks and fluid or crystallized intelligence may be lower or higher than for general intelligence.

In their Study 2 Pluck and Ruales-Chieruzzi (2021) used a Spanish, validated seven-subtest version of the Wechsler Adult Intelligence Scale in the 4th edition (WAIS-IV) (Meyers et al., 2013) to measure general intelligence, as well as three lexical tests, the Word Accentuation Test (WAT) in Spanish (Del Ser et al., 1997), the Stem Completion Implicit Reading Test (SCIRT) (Pluck, 2018) and the Spanish Lexical Decision Task (SpanLex) (Pluck, 2020b). The sample consists of 106 premorbid participants without neurological illness. As one participant has not completed the WAT, this person was excluded from the analysis regarding the WAT score. Simple linear regression models with the WAIS-IV as dependent and the lexical tests as independent variable, respectively, were conducted to determine the percentage of explained variance and to test the predictability of general intelligence through every single test. Therefore, the sample was randomly divided into two halves; hence, the net sample size for the linear regression models was 53 as the other half was used to test the prediction based on the regression models. We compared the widths of the 95% confidence intervals for the parameters of these regression models to the widths of the 95% confidence unions resulting from externally informed versions of the linear models. Because the OLS estimation does not account for heteroscedastic errors, which are common in practice, the standard errors are often too small (White, 1980). To correct for heteroscedasticity, we have computed robust standard errors of type HC3 using the package sandwich (Zeileis, 2004; Zeileis et al., 2020). Since the dependent variable is the WAIS-IV, an intelligence test with calibration sample, we calculated E(y)=100. In the simulation study using the external information about ρ was found to lead to high variance reduction. Hence, by reviewing the literature, we identified the upper bound for the correlation between general intelligence and lexical tasks to be .85. This value was reported as correlation between WAT and the vocabulary scale of the Wechsler Adult Intelligence scale in Burin et al. (2000). A lower bound for the correlation between general intelligence and lexical tasks was found using the meta-analysis of Peng et al. (2019) or the study of Pluck (2018). Pluck (2018) argued based on a couple of studies that the correlation of general intelligence and lexical skills is typically higher than .70. In the meta-analysis of Peng et al. (2019), the reported 95% confidence interval for the correlation of fluid intelligence and reading is [0.36, 0.39]. To compare the results, both sources were used separately, leading to the lower bounds 0.4 and 0.7, where 0.4 is very conservative as it is derived from a correlation including a different variable (fluid intelligence). Together this amounts to the intervals [0.4, 0.85] and [0.7, 0.85], which are adopted for each of the three lexical tests. The confidence unions were calculated in the same way as in the simulations using grid search, but with 10001 grip points instead of 101 and Ω^h=1n∑i=1nh(z)h(z)T. The details of the analysis can be found in the R script in the online supplements to this article. The results for the interval [0.7, 0.85] are shown in Table 5 and the results for the interval [0.4, 0.85] are in Table 13 in the supplementary materials. First, the results of Pluck and Ruales-Chieruzzi (2021) were recalculated, showing no differences from the results reported in their Study 2. In addition, the corresponding OLS confidence intervals for the parameters were calculated based on the HC3 estimator (see column five of Table 5). Then, estimator and standard error intervals, as well as the unions of confidence intervals, were calculated for the externally informed model. For both [0.4, 0.85] and [0.7, 0.85], the maxima of all standard error intervals were below the respective standard errors calculated for the OLS models of Pluck and Ruales-Chieruzzi (2021). This clearly shows the variance reduction property of the externally informed model and was most pronounced for the SpanLex. For [0.4, 0.85] all estimation intervals included the OLS estimates and all confidence unions were larger than the corresponding OLS confidence intervals, indicating that [0.4, 0.85] is very conservative. For [0.7, 0.85], the estimation interval [β^j_,β^j¯] included the OLS estimator only for the slope and intercept of the regression on SCIRT and the one based on the WAT. In this case, however, all confidence unions overlapped with the OLS-based confidence intervals. Using [0.7, 0.85], for every lexical test, the widths of the confidence unions from the externally informed model were smaller than the confidence intervals from the simple linear regression models, for both slopes and intercepts, except for the intercept of WAT. Since the prediction interval is calculated based on the distribution of parameter estimators, this would lead to shorter prediction intervals for a participant’s general intelligence based on the externally informed model. In addition, the confidence union approach is more robust than OLS confidence intervals with respect to deviations from the assumed normal distribution. Taken together, this amounts to possibly more precise yet robust parameter estimation and prediction, if the external information is correct.Table 5 Results using ρx,y∈[0.7,0.85] and E(y)=100.

j	Test	Pluck and Ruales-Chieruzzi	Externally informed estimates	
		β^j	s(β^j)	CI0.95	[β^j_,β^j¯]	[s(β^j)_,s(β^j)¯]	⋃CI0.95	
1	SpanLex	54.61	8.864	[37.06, 72.15]	[37.41, 47.15]	[2.373, 2.663]	[32.06, 51.91]	
WAT	62.81	4.701	[53.51, 72.12]	[60.02, 62.89]	[3.587, 3.612]	[52.77, 70.10]	
SCIRT	60.81	4.395	[52.11, 69.51]	[59.01, 61.28]	[3.910, 3.920]	[51.14, 69.13]	
2	SpanLex	1.821	0.332	[1.163, 2.480]	[2.068, 2.430]	[0.124, 0.132]	[1.818, 2.696]	
WAT	2.083	0.240	[1.607, 2.559]	[2.041, 2.186]	[0.190, 0.191]	[1.659, 2.568]	
SCIRT	3.292	0.358	[2.583, 4.001]	[3.213, 3.393]	[0.309, 0.310]	[2.592, 4.015]	
The third and fourth columns contain the recomputed results of Pluck and Ruales-Chieruzzi (2021) in terms of the OLS regression coefficients β^j, where β^1 is the intercept and β^2 is the slope and the robust standard errors s(β^j) of the coefficients. The (robust) 95% confidence intervals CI0.95 for the parameters were computed in addition. The estimator interval [β^j_,β^j¯], the standard error interval [s(β^j)_,s(β^j)¯] and the 95% confidence interval union ⋃CI0.95 are shown as results of the estimation of the externally informed model.

Discussion

In this paper, we show that incorporating external moments into the GMM framework by using intervals instead of point values can lead to more robust analyses, while a possible variance reduction can prevent the confidence unions from being too wide.

The results of the simulation study for point values show that the variance reduction can be considerable, over 70% using external information about covariances, correlations or βxj,y. However if the external moments deviate from the true values, the inferences will be biased, getting worse with increasing sample size. Instead, the use of external intervals often leads to correct inferences. However, the F-probability couldn’t completely correct the undercoverages caused by using the moments σy2 as well as E(y2), though it slightly improved them. The reason for these undercoverages is the skewed distribution induced by y2, indicating a limitation of the distributional robustness in the presence of large deviations from the normal distribution. As these two moments also showed low variance reduction when used, one should thoughtfully decide on basis of their relative variance reduction if one wants to use them in small samples. However, bootstrap methods, like the bias-corrected accelerated bootstrap (Efron & Tibshirani, 1993), could be used instead to try to correct the undercoverage.

For small sample sizes, the use of covariances, correlations, and βxj,y, j=2,3, leads to variance reduction despite the use of external intervals. However, this was mostly the case for certain entries βj of β in this setting, not for all elements in β. Interestingly, the use of covariances and βxj,y, j=2,3, still resulted in overcoverage caused by overestimation of the variance. This means that inferences based on these moments would be more conservative than necessary, yet they had the highest variance reduction of all the moments tested, providing an interesting link to the concept of superefficiency (Bahadur, 1964). Further research on the variance estimator is needed to potentially correct for its overestimation.

Taken together, the simulation study showed promising results regarding very small sample sizes as n=15, and however, one should still be cautious as the estimators are only proved to be consistent, not unbiased. To be sure that the inference will be valid in the sample at hand, a simulation to test the adopted scenario, i.e., model to be estimated and data set, is advised. In Sect. 6, we showed the applicability of the theoretical results to real data, where for the variable SpanLex the width of the confidence unions was significantly smaller than the width of the corresponding point-CI, if an appropriately small external interval is used. This shows the usefulness of adopting an externally informed model for applied problems.

A possible limitation of GMM is the assumption of the covariance matrix of the external moments being positive definite, which excludes distributions for which the required covariance matrix does not exist, e.g., the Cauchy distribution. Nevertheless, in many psychological applications the variables have a constrained range of values, so that at least the existence of the covariance matrix can be assumed. In general, the applicability of the method is not overtly limited by its assumptions. Another limitation is that the true value of the external moment must be within the external interval. However, this identifiability assumption, or an analogous assumption, exists in other approaches, and it is much weaker than point identifiability. Thus, a more robust use of external information is possible, up to using the full range of possible values, which would definitely lead to a valid, more robust, but also very conservative inference. The construction of the external moment interval in Sect. 6 was based on a rough, subjective approximation. The question of how to construct the external intervals requires further research. In particular, further links to existing techniques for eliciting intervals and preventing overconfidence bias would be important.

An application of the theory to generalized linear models or multi-level models is of inherent interest for psychological research, especially as Corollary 1 sets the foundation for research on more complex models. At first glance, the results appear to be in conceptional “conflict” with multi-level-models, since these often assume the random effects to be normally distributed and in this case there is no bounded interval, that includes the true parameter. However, even in these models there are fixed (hyper-)parameters one could know bounds for, and hence, it would be interesting for future research to analyze the behavior of these models in the external GMM framework. With respect to the limitation of robustness found in the simulation study, it would be interesting to investigate how robust the estimators are as a function of the length of the external interval. Finally, research on (the properties of) significance tests based on the use of an external intervals would be of great interest.

Supplementary Information

Below is the link to the electronic supplementary material.Supplementary file 1 (zip 5 KB)

Supplementary file 2 (pdf 318 KB)

Funding

Open Access funding enabled and organized by Projekt DEAL.

Declarations

Conflict of interest

The authors have no conflicts of interest to declare that are relevant to the content of this article.

Data availability

The dataset of Pluck and Ruales-Chieruzzi (2021) analyzed during the current study is available in the PsychArchive repository, https://doi.org/10.23668/psycharchives.2897. All data generated by the simulations in this study are included in this article and its supplementary information files.

Publisher's Note

Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
==== Refs
References

Augustin T Neyman–Pearson testing under interval probability by globally least favorable pairs: Reviewing Huber–Strassen theory and extending it to general interval probability [Imprecise probability models and their applications] Journal of Statistical Planning and Inference 2002 105 1 149 173 10.1016/S0378-3758(01)00208-7
Augustin T Coolen FP De Cooman G Troffaes MC Introduction to imprecise probabilities 2014 Hoboken Wiley
Bahadur RR On Fisher’s bound for asymptotic variances The Annals of Mathematical Statistics 1964 35 4 1545 1552 10.1214/aoms/1177700378
Berger JO Robust Bayesian analysis: Sensitivity to the prior Journal of Statistical Planning and Inference 1990 25 3 303 328 10.1016/0378-3758(90)90079-A
Bernardo JM Smith AFM Bayesian theory 1994 Hoboken Wiley
Buckley JJ Fuzzy statistics 2004 Berlin, Heidelberg Springer
Burin DI Jorge RE Arizaga RA Paulsen JS Estimation of premorbid intelligence: The word accentuation test—Buenos Aires version Journal of Clinical and Experimental Neuropsychology 2000 22 5 677 685 10.1076/1380-3395(200010)22:5;1-9;FT677 11094402
Cameron A Trivedi P Microeconometrics: Methods and applications 2005 Cambridge Cambridge University Press
Cassidy R Manski CF Tuberculosis diagnosis and treatment under uncertainty Proceedings of the National Academy of Sciences of the United States of America 2019 116 46 22990 22997 10.1073/pnas.1912091116 31662476
Cattell RB Theory of fluid and crystallized intelligence: A critical experiment Journal of Educational Psychology 1963 54 1 1 10.1037/h0046743
Chaudhuri S Handcock MS Rendall MS Generalized linear models incorporating population level information: An empirical-likelihood based approach Journal of the Royal Statistical Society. Series B (Statistical Methodology) 2008 70 2 311 328 10.1111/j.1467-9868.2007.00637.x 22740776
Del Ser T González-Montalvo J-I Martinez-Espinosa S Delgado-Villapalos C Bermejo F Estimation of premorbid intelligence in Spanish people with the word accentuation test and its application to the diagnosis of dementia Brain and Cognition 1997 33 3 343 356 10.1006/brcg.1997.0877 9126399
Efron B Tibshirani RJ An introduction to the bootstrap 1993 New York, NY Chapman & Hall
Garthwaite PH Kadane JB O’Hagan A Statistical methods for eliciting probability distributions Journal of the American Statistical Association 2005 100 470 680 701 10.1198/016214505000000105
Hansen LP Large sample properties of generalized method of moments estimators Econometrica 1982 50 4 1029 1054 10.2307/1912775
Hausman JA Specification tests in econometrics Econometrica 1978 46 6 1251 1271 10.2307/1913827
Hellerstein JK Imbens GW Imposing moment restrictions from auxiliary data by weighting The Review of Economics and Statistics 1999 81 1 1 14 10.1162/003465399557860
Higgins JP Thomas J Chandler J Cumpston M Li T Page MJ Welch VA Cochrane handbook for systematic reviews of interventions 2019 2 Hoboken Wiley
Huber PJ Robust statistics 1981 Hoboken Wiley
Imbens GW Lancaster T Combining micro and macro data in microeconometric models The Review of Economic Studies 1994 61 4 655 680 10.2307/2297913
Insua DR Ruggeri F Robust Bayesian analysis 2000 New York Springer
Jann, M. (2023). Testing the coherence of data and external intervals via an imprecise Sargan–Hansen test. In International symposium on imprecise probability: Theories and applications (pp. 249–258).
Kadane JB Wolfson LJ Experiences in elicitation Journal of the Royal Statistical Society. Series D (The Statistician) 1998 47 1 3 19
Kwakernaak H Fuzzy random variables—I. Definitions and theorems Information Sciences 1978 15 1 1 29 10.1016/0020-0255(78)90019-1
Lele SR Das A Elicited data and incorporation of expert opinion for statistical inference in spatial studies Mathematical Geology 2000 32 465 487 10.1023/A:1007525900030
Manski CF Identification problems in the social sciences Sociological Methodology 1993 23 1 56 10.2307/271005
Manski CF Partial identification of probability distributions 2003 Berlin Springer
Manski CF Pepper JV Deterrence and the death penalty: Partial identification analysis using repeated cross sections Journal of Quantitative Criminology 2013 29 1 123 141 10.1007/s10940-012-9172-z
Meyers JE Zellinger MM Kockler T Wagner M Miller RM A validated seven-subtest short form for the Wais-IV Applied Neuropsychology: Adult 2013 20 4 249 256 10.1080/09084282.2012.710180 23530602
Newey WK McFadden D Chapter 36 large sample estimation and hypothesis testing 1994 Amsterdam Elsevier
Owen AB Empirical likelihood ratio confidence intervals for a single functional Biometrika 1988 75 2 237 249 10.1093/biomet/75.2.237
Page MJ McKenzie JE Bossuyt PM Boutron I Hoffmann TC Mulrow CD Shamseer L Tetzlaff JM Akl EA Brennan SE Chou R Glanville J Grimshaw JM Hróbjartsson A Lalu MM Li T Loder EW Mayo-Wilson E McDonald S Moher D The PRISMA 2020 statement: An updated guideline for reporting systematic reviews PLOS Medicine 2021 18 3 1 15 10.1371/journal.pmed.1003583
Peng P Wang T Wang C Lin X A meta-analysis on the relation between fluid intelligence and reading/mathematics: Effects of tasks, age, and social economics status Psychological Bulletin 2019 145 2 189 236 10.1037/bul0000182 30652909
Pluck G Lexical reading ability predicts academic achievement at university level Cognition, Brain, Behavior 2018 22 3 175 196
Pluck, G. (2020a). Datasets for: Estimation of premorbid intelligence and executive cognitive functions with lexical reading tasks. 10.23668/psycharchives.2897
Pluck, G. (2020b). A lexical decision task to measure crystallized-verbal ability in spanish. Revista Latinoamericana de Psicologia, 52, 1–10.
Pluck G Ruales-Chieruzzi CB Estimation of premorbid intelligence and executive cognitive functions with lexical reading tasks Psychology and Neuroscience 2021 14 358 10.1037/pne0000264
R Core Team. (2022). R: A language and environment for statistical computing. R Foundation for Statistical Computing. Vienna, Austria. https://www.Rproject.org/
Sargan JD The estimation of economic relationships using instrumental variables Econometrica 1958 26 3 393 415 10.2307/1907619
Spiess M A mixed approach for the estimation of probit models with correlated responses: Some finite sample results Journal of Statistical Computation and Simulation 1998 61 1–2 39 59 10.1080/00949659808811901
Spiess M Jordan P Wendt M Simplified estimation and testing in unbalanced repeated measures designs Psychometrika 2019 84 1 212 235 10.1007/s11336-018-9620-2 29736784
Steffen A Thom J Jacobi F Holstiege J Bätzing J Trends in prevalence of depression in Germany between 2009 and 2017 based on nationwide ambulatory claims data Journal of Affective Disorders 2020 271 239 247 10.1016/j.jad.2020.03.082 32479322
Vaart, A. W. (1998). M–and z-estimators. In Asymptotic statistics (pp. 41– 84). Cambridge University Press. 10.1017/CBO9780511802256.006
Walter G Augustin T Imprecision and prior-data conflict in generalized Bayesian inference Journal of Statistical Theory and Practice 2009 3 1 255 271 10.1080/15598608.2009.10411924
Weichselberger K The theory of interval-probability as a unifying concept for uncertainty International Journal of Approximate Reasoning 2000 24 2 149 170 10.1016/S0888-613X(00)00032-3
Weichselberger, K. (2001). Elementare grundbegriffe einer allgemeineren wahrschein-lichkeitsrechnung I: Intervallwahrscheinlichkeit als umfassendes konzept (Vol. 1). Berlin Heidelberg: Springer.
Weiss RH Cft 20-r: Grundintelligenztest skala 2-revision 2006 Gottingen Hogrefe
Weiss RH Cft 20-r mit ws: Grundintelligenztest skala 2-revision (cft 20-r) mit wortschatztest und zahlenfolgentest-revision (ws/zf-r) 2019 2 Gottingen Hogrefe
White H A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity Econometrica 1980 48 4 817 838 10.2307/1912934
Winman A Hansson P Juslin P Subjective probability intervals: How to reduce overconfidence by interval evaluation Journal of Experimental Psychology: Learning, Memory, and Cognition 2004 30 6 1167 15521796
Zadeh LA Fuzzy sets Information and Control 1965 8 3 338 353 10.1016/S0019-9958(65)90241-X
Zeileis A Econometric computing with HC and HAC covariance matrix estimators Journal of Statistical Software 2004 11 10 1 17 10.18637/jss.v011.i10
Zeileis A Köll S Graham N Various versatile variances: An object oriented implementation of clustered covariances in R Journal of Statistical Software 2020 95 1 1 36 10.18637/jss.v095.i01
Zhong B Rao JNK Empirical likelihood inference under stratified random sampling using auxiliary population information Biometrika 2000 87 4 929 938 10.1093/biomet/87.4.929
