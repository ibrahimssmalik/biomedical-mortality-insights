
==== Front
Sensors (Basel)
Sensors (Basel)
sensors
Sensors (Basel, Switzerland)
1424-8220
MDPI

10.3390/s24113303
sensors-24-03303
Article
Crossing-Point Estimation in Human–Robot Navigation—Statistical Linearization versus Sigma-Point Transformation
Palm Rainer 1*
Lilienthal Achim J. 2
Cheneler David Academic Editor
Monk Stephen Academic Editor
1 Center for Applied Autonomous Sensor Systems (AASS), Department of Technology, Örebro University, SE-701 82 Örebro, Sweden
2 Technical University Munich (TUM), 80333 Munich, Germany; achim.j.lilienthal@tum.de
* Correspondence: rub.palm@t-online.de
22 5 2024
6 2024
24 11 330320 3 2024
16 5 2024
17 5 2024
© 2024 by the authors.
2024
https://creativecommons.org/licenses/by/4.0/ Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).
Interactions between mobile robots and human operators in common areas require a high level of safety, especially in terms of trajectory planning, obstacle avoidance and mutual cooperation. In this connection, the crossings of planned trajectories and their uncertainty based on model fluctuations, system noise and sensor noise play an outstanding role. This paper discusses the calculation of the expected areas of interactions during human–robot navigation with respect to fuzzy and noisy information. The expected crossing points of the possible trajectories are nonlinearly associated with the positions and orientations of the robots and humans. The nonlinear transformation of a noisy system input, such as the directions of the motion of humans and robots, to a system output, the expected area of intersection of their trajectories, is performed by two methods: statistical linearization and the sigma-point transformation. For both approaches, fuzzy approximations are presented and the inverse problem is discussed where the input distribution parameters are computed from the given output distribution parameters.

human–robot interaction
Gaussian noise
sigma-point transformation
unscented Kalman filter
European Union101017274 This work has received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreement No. 101017274 (DARKO).
==== Body
pmc1. Introduction

The planning and performing of mobile robot tasks in the presence of human operators while sharing the same workspace requires a high level of stability and safety. Research activities regarding navigation, obstacle avoidance, adaptation and collaboration between robots and human agents have been widely reported [1,2]. Multiple target tracking for robots using higher control levels in a control hierarchy are discussed in [3,4]. A human-friendly interaction between robots and humans can be obtained by human-like sensor systems [5]. A prominent role in robot navigation is the trajectory-crossing problem of robots and humans [6,7] and corresponding fuzzy solutions [8]. Motivations for a fuzzy solution of the intersection problem are manifold. One point is an uncertain measurement of the position and orientation of the human agent, because of which the use of a fuzzy signal and an adequate fuzzy processing seems natural [9,10]. Another aspect is the need for decreasing the computing effort in the case of complex calculations during a very small time interval. System uncertainties and observation noise lead to uncertainties of the intersection estimations.

The objective of this work is the formulation of the crossing/intersection problem by taking into account the uncertainties in human–robot systems, including sensors and motor characteristics. An important aspect is to define permissible uncertainties in a human–robot system for a given uncertainty at a possible intersection of their trajectories. Taking into account the nonlinearities, this is performed by the differential approach and a following analysis of the regarding Gaussian distributions. This approach is compared with the sigma-point transformation, which represents a simplification of the computation and a qualitative extension of the analysis regarding the statistics of the random variables. For broader areas of possible intersections, both methods are extended to fuzzy regions together with different numbers and shapes of fuzzy sets. The most important contributions are as follows:An investigation of uncertainties of possible intersection areas originating from sensor noise or system uncertainties.

A direct and inverse transformation of the error variables at the intersection areas for two input variables (orientation angles) and two output variables (intersection coordinates).

An extension of the method from two to six input variables (two orientation angles and four position coordinates).

An exploration of the formulations of fuzzy versions.

A formulation of the problem by the sigma-point transformation and corresponding comparison of the two methods.

This paper deals with the one-robot one-human trajectory-crossing problem, where small uncertainties in the position and orientation may lead to high uncertainties at the intersection points. The position and orientation of the human and robot are nonlinearly coupled but can be linearized. In the following, the linear part of the nonlinear system is considered in the analysis reported for small variations in the input [11]. Then, the “direct task” is described, meaning that the parameters of the input distribution are transformed to the output distribution parameters. The “inverse task” is also solved, meaning that for the defined output distribution parameters the input parameters are calculated. In this paper, two methods are outlined:The statistical linearization, which linearizes the nonlinearity around the operating area at the intersection. The means and standard deviations on the input parameters positions (orientations) are transformed through the linearized nonlinear system to obtain the means and standard deviations of the output parameters (the position of intersection).

The sigma-point transformation, which calculates the so-called sigma points of the input distribution, including the mean and covariance of the input. The sigma points are directly propagated through the nonlinear system [12,13,14] to obtain the means and covariance of the output and, with this, the standard deviations of the output (the position of intersection). The advantage of the sigma-point transformation is that it captures the first- and second-order statistics of a random variable, whereas the statistical linearization approximates a random variable only by its first order. However, the computational complexity of the extended Kalman filter (EKF, differential approach) and unscented Kalman filter (UKF, sigma-point approach) is of the same order [13].

This paper is organized as follows. Section 2 describes the related work already conducted on unscented Kalman filters in mobile robot applications. In Section 3, the general intersection problem and its analytical approach is described. Section 4 deals with the transformation/conversion of Gaussian distributions for a two-input–two-output system and for a six-input–two-output system plus the corresponding inverse and fuzzy solutions. In Section 5, the sigma-point approach plus inverse and fuzzy solutions are addressed. Section 6 presents simulations of the statistical linearization and the sigma-point transformation to show the quality of the input–output conversion of the distributions and the impact of different resolutions of fuzzy approximations on the accuracy of the random variable intersection. Finally, Section 7 concludes this paper with a discussion of the two different approaches and a comparison of the methods.

2. Related Work

The crossing problem for mobile robots has been especially dealt with by [6,7]. Both publications deal with the so-called rendezvous problem whereby the key point is the trajectory planning under time constraints, taking into account the dynamics of the contributing robots. Uncertainties of possible intersection areas that come from sensor noise or system uncertainties are not discussed deeply. A fuzzy-adaptive extended Kalman filter (FAEKF) for the real-time attitude estimation of a mobile robot is proposed in [15] where fuzzy IF–THEN rules-based adaption laws modify the noise covariance matrices of the filter. However, the use of unscented Kalman filters or sigma-point transformation has not been discussed. For the estimation of landmarks, a simultaneous localization and mapping (SLAM) method is presented by [16] where an iterated sigma-point FastSLAM (ISP-FastSLAM) algorithm is proposed to minimize statistical linearization errors through the Gaussian–Newton iteration. A further application is presented by [17] where a walking robot uses sigma-point transformation for state estimation to guarantee stability in the system’s hybrid dynamics, which contains continuous and switching parts during movement. In [18], a vision-based SLAM system uses both extended Kalman filters (EKFs) and sigma-point Kalman filter (SPKF) algorithms and showed its superiority over the EKF. The pose estimation of mobile robots is discussed in [19] whereby several filter techniques like the Kalman filter (EKF), the unscented Kalman filter (UKF) and several variants of the particle filter (PF) are compared. It turns out that the UKF (also the sigma-point approach) exhibits almost the same computational cost. In [20], the inter-robot and robot–target correlations are discussed, and unscented transformation-based collaborative self-localization and a target tracking algorithm between robots are proposed. A tutorial on different approaches to exploit the structure of a system’s state and measurement models to reduce the computational demand of the algorithms is presented by [21]. In this publication, the computational complexity of different state estimation algorithms is presented, showing the superiority of the sigma-point transformation algorithms.

In all these publications, the problem of obstacle avoidance and/or the crossing problem in the presence of human actors are not taken into account, because of which the present paper is a further contribution to the robot–human interaction problem.

3. Computation of Intersections

The problem can be stated as follows:

A robot and human agent move in a common area according to their tasks or intentions. To avoid collisions, possible intersections of the paths of the agents should be predicted for both the trajectory planning and on-line interactions. To accomplish this, the positions, orientations and intended movements of the robot and human should be estimated as accurately as needed.

In this connection, uncertainties and noise on the random variables’ position/orientation xR, xH, ϕR and ϕH of the robot and human have a great impact on the calculation of the expected intersection position xc. The random variable xc is calculated as the crossing point of the extension of the orientation or velocity vectors of the robot and human, which may change during motion depending on the task and current interaction. The task is to calculate the intersection and its uncertainty in the presence of the known uncertainties of the acting agent robot and human.

System noise wR and wH for the robot and human can be obtained from experiments. The noise wc of the “virtual” intersection is composed of the nonlinear transformed noise wR and wH and some additional noise vc that may come from uncertainties of the nonlinear computation of the intersection position xc (see Figure 1). In the following, the geometrical relations are described as well as the fuzzy approximations and nonlinear transformations of the random variables xR, xH, ϕR and ϕH.

3.1. Geometrical Relations

Let the y-axis of the mobile coordinate frame of the robot and human be aligned with their directions of motion. Furthermore, let the orientation angles ϕR and ϕH of the robot and human be measured from the x-axis of the base frame counterclockwise. Let the intersection (xc,yc) of the two linear trajectories xR(t) and xH(t) in a plane be described by the following relations (see Figure 2):(1) xH=xR+dRHcos(ϕR+δR)yH=yR+dRHsin(ϕR+δR)xR=xH+dRHcos(ϕH+δH)yR=yH+dRHsin(ϕH+δH)

where xH=(xH,yH) and xR=(xR,yR) are the positions of the human and robot and ϕH and ϕR are their orientation angles, and δH and δR are the positive angles measured from the y coordinates counterclockwise. The angle at the intersection is β˜=π−δR−δH. The variables xH, xR, ϕR, ϕHδH and ϕHδR; distance dRH; and angle γ are assumed to be measurable. Angle γ is a bearing angle for the robot-to-human direction measured in base coordinates. If ϕH is not directly measurable, then it can be computed by (2) ϕH=arcsin((yH−yR)/dRH)−δH+π

The coordinates xc and yc of the intersection are computed straightforwardly by [8] (3) xc=A−BtanϕR−tanϕHyc=AtanϕH−BtanϕRtanϕR−tanϕHA=xRtanϕR−yRB=xHtanϕH−yH

Rewriting (3) leads to (4) xc=xRtanϕRG−yR1G−xHtanϕHG−yH1Gyc=xRtanϕRtanϕHG−yRtanϕHG−xHtanϕHtanϕRG−yHtanϕRGG=tanϕR−tanϕH

After rearranging (4), we observe that xc=(xc,yc)T is linear in xRH=(xR,yR,xH,yH)T (5) xc=ARH·xRH

where ARH=f(ϕR,ϕH)=1GtanϕR−1−tanϕH1tanϕRtanϕH−tanϕH−tanϕRtanϕHtanϕR

This notation is of advantage for further computations, such as the fuzzification of the intersection problem and the transformation of the error distributions.

3.2. Computation of Intersections—Fuzzy Approach

The fuzzy solution presented in the following is a combination of classical analytical (crisp) methods and rule-based methods in the sense of a Takagi–Sugeno fuzzy rule base. An appropriate choice of the number of fuzzy sets and corresponding fuzzy rules depends strongly on the specific application. In the present case, fuzzy sets are used as the approximation of nonlinear functions. In the following, we introduce a fuzzy rule-based approximation of (5) with n×n fuzzy rules Ri,j (6) Ri,j:IFϕR=ΦRiANDϕH=ΦHjTHENxc=ARHi,j·xRH

n—the number of fuzzy terms, ΦRi and ΦHj for ϕR and ϕH, with the result (7) xc=∑i,jwi(ϕR)wj(ϕH)·ARHi,j·xRH

i,j=1…n, wi(ϕR),wj(ϕH)∈[0,1] are normalized membership functions with ∑iwi(ϕR)=1 and ∑jwj(ϕH)=1.

Let the universes of discourse for ϕR and ϕH be ϕR,ϕH∈[0,360]. Furthermore, let these universes of discourse be divided into n partitions (for example, 6) of 60, which leads to 6×6 fuzzy rules. The corresponding membership functions are shown in Figure 3. It turns out that this resolution leads to a poor fuzzy approximation. The approximation quality can be improved by increasing the number of fuzzy sets, which however results in a quadratic increase in the number of fuzzy rules. To avoid an “explosion” of the number of fuzzy rules being computed in one time step, a set of sub-areas covering a small number of rules for each sub-area is defined. Based on the measurements of ϕR and ϕH, the appropriate sub-area is selected together with a corresponding set of rules (see Figure 4, sub-area AR,AH). With this, the number of rules to be activated at one time step of calculation is low, although the total number of rules can be high. At the borderlines between the sub-areas, abrupt changes may occur, which can be avoided by overlapping the sub-areas.

3.3. Differential Approach

The positions and orientations of robots and humans are usually corrupted with noise originated from system uncertainties, sensor errors and motor characteristics. These uncertainties become apparent in uncertainties in the crossing/intersection areas of the trajectories of the robot and human. The analysis of uncertainty and noise at xc generated by the noise at ϕR, ϕH and xRH=(xR,yR,xH,yH)T requires a linearization of (4) around the operating points and with this a differential strategy. Let, for simplification, only the orientation angles ϕR and ϕH be corrupted with noise. In Section 4.3, the positions xRH=(xR,yR,xH,yH)T are taken into account, too.

Differentiating (4) with xRH=const. yields (8) dxc=J˜·dŒdŒ=(dϕRdϕH)T;J˜=J˜11J˜12J˜21J˜22

where J˜11=−tanϕH1tanϕH−1xRHG2·cos2ϕRJ˜12=tanϕR−1−tanϕR1xRHG2·cos2ϕHJ˜21=J˜11·tanϕHJ˜22=J˜12·tanϕR

The following sections deal with the accuracy of the computed intersection in the case of noisy orientation information (see Figure 5).

4. Transformation of Gaussian Distributions

4.1. General Assumptions

Consider a nonlinear system (9) z=F(x)

where the random variables x=(x1,x2)T denote the input, z=(z1,z2)T denotes the output and F denotes a nonlinear transformation. The distribution of the uncorrelated Gaussian distributed components x1 and x2 is described by (10) fx1,x2=12πσx1σx2exp(−12(ex12σx12+ex22σx22))

where ex1=x1−x1¯, with x1¯—the mean (x1) and σx1—the standard deviation x1, and ex2=x2−x2¯, with x2¯—the mean (x2) and σx2—the standard deviation x2.

The goal is as follows: Given the nonlinear transformation (9) and the distribution (10), compute the output signals z1 and z2 and their distributions together with their standard deviations and the correlation coefficient. Linear systems transform Gaussian distributions linearly such that the output signals are also Gaussian-distributed. This does not apply for nonlinear systems, but if the input standard deviation is small enough, then a local linear transfer function can be built for which the outputs are Gaussian-distributed. Suppose the input standard deviations are small with respect to the nonlinear function, then the output distribution can be written as follows:(11) fz1,z2=12πσz1σz21−ρz122·exp(−12(1−ρz122)(ez12σz12+ez22σz22−2ρz12ez1ez2σz1σz2))

ρz12—the correlation coefficient.

4.2. Statistical Linearization, Two Inputs–Two Outputs

Let the nonlinear transformation F be described by two smooth transfer functions (see block scheme Figure 6) (12) z1=f1(x1,x2)z2=f2(x1,x2)

where (x1,x2)=(ϕR,ϕH) and (z1,z2)=(xc,yc).

The linearization of (12) yields (13) dz=J˜·dxorez=J˜·ex

with (14) ez=(ez1,ez2)Tandex=(ex1,ex2)Tdz=(dz1,dz2)Tanddx=(dx1,dx2)T

(15) J˜=∂f1/∂x1,∂f1/∂x2∂f2/∂x1,∂f2/∂x2

4.2.1. Output Distribution

To obtain the density fz1,z2 (11) of the output signal, we invert (15) and substitute the entries of ex into (10). J˜ is invertible if it is positive definite with |J˜|>0. Otherwise, there exist singularities due to different constellations of the position vector xRH and/or the orientations ϕR and ϕH. To find all the singularities requires a further analysis, which is not the content of this paper. However, a simple heuristic leads us to some obvious situations: If ϕR=ϕH or ϕR=ϕH+π, then the human and robot would move in parallel either in the same or the opposite direction. On the other hand, one may also obtain diverging trajectories with no crossing. (16) ex=J·ez

with J=J˜−1 and (17) J=J11J12J21J22=jxzjyz

where jxz=(J11,J12) and jyz=(J21,J22). The entries Jij are the result of the inversion of J˜. From this substitution, we obtain (18) fx1,x2=Kx1,x2·exp(−12·ezT·(jx1,zT,jx2,zT)·Sx−1·jx1,zjx2,z·ez)

where Kx1,x2=12πσx1σx2 and (19) Sx−1=1σx12,00,1σx22

The exponent of (18) is rewritten into (20) xpo=−12·(1σx12(ez1J11+ez2J12)2+1σx22(ez1J21+ez2J22)2)

and furthermore (21) xpo=−12·[ez12(J112σx12+J212σx22)+ez22(J122σx12+J222σx22)+2·ez1ez2(J11J12σx12+J21J22σx22)]

Let (22) A=(J112σx12+J212σx22);B=(J122σx12+J222σx22)C=(J11J12σx12+J21J22σx22)

then a comparison of xpo in (21) and the exponent in (11) yields (23) 1(1−ρz122)1σz12=A;1(1−ρz122)1σz22=B−2ρz12(1−ρz122)1σz1σz2=2C

The standard deviations σz1 and σz2 and the correlation coefficient ρz12 yield (24) ρz12=−CAB1σz12=A−C2B;1σz22=B−C2A

The result is as follows: If the parameter of the input distribution and the transfer function F(x,y) are known, then the output distribution parameters can be computed straightforwardly.

4.2.2. Fuzzy Solution

To save computing costs in real time, we create a TS fuzzy model that is represented by the rules Rij. (25) Rij:IFx1=X1iANDx2=X2i

THENρz12=−CijAijBijAND1σz12=Aij−Cij2Bij;AND1σz22=Bij−Cij2Aij

where X1i,X2i are fuzzy terms for x1,x2, and Aij,Bij,Cij are functions of the predefined variables x1=x1i and x2=x2i.

From (25), we derive (26) ρz12=−∑ijwi(x1)wj(x2)CijAijBij1σz12=∑ijwi(x1)wj(x2)(Aij−Cij2Bij)1σz22=∑ijwi(x1)wj(x2)(Bij−Cij2Aij)

wi(x1)∈[0,1] and wj(x2)∈[0,1] are the weighting functions with ∑iwi(x1)=1, ∑jwj(x2)=1.

4.2.3. Inverse Solution

The previous paragraph discussed the direct transformation task: Let the distribution parameters of the input variable be defined and find the corresponding output parameters. However, it might also be useful to solve the inverse task: Given the output parameters (standard deviation and correlation coefficient), find the corresponding input parameters. This solution of the inverse task is similar to those discussed in Section 4.2. The starting points are equations (10) and (11), which describe the distributions of the inputs and outputs, respectively. Then, we substitute (13) into (10) and rename the resulting exponent xpoz into xpox and discuss the exponent xpox (27) xpox=−12(1−ρz122)(exTJ˜TSz−1J˜ex−2ρz12ez1ez2σz1σz2)

with Sx−1=1σz12,00,1σz22

Now, comparing (27) with the exponent of (10) of the input density, we find that the mixed term in (27) must be zero, from which we obtain the correlation coefficient ρz12 and with this the standard deviations of the inputs (28) ρz12=(J˜11J˜12σz12+J˜21J˜22σz22)σz1σz2(J˜11J˜22+J˜12J˜21)1σx2=(J˜112σz12+J˜212σz22−2ρz12σz1σz2J˜11J˜21)/(1−ρz122)1σy2=(J˜122σz12+J˜222σz22−2ρz12σz1σz2J˜12J˜22)/(1−ρz122)

The detailed development can be found in [22].

4.3. Six Inputs–Two Outputs

Consider again the nonlinear system (29) xc=F(x)

In the previous subsections, we assumed the positions xR and xH not to be corrupted with noise. However, taking into account the positions to be random variables, the number of inputs is 6 so that the input vector yields x=(x1,x2,x3,x4,x5,x6)T or x=(ϕR,ϕH,xR,yR,xH,yH) with the output vector xc=(xc,yc)T.

Furthermore, let the uncorrelated Gaussian-distributed inputs x1…x6 be described by the 6-dim density (30) fxi=1(2π)6/2|Sx|1/2exp(−12(exTSx−1ex))

where ex=(ex1,ex2,…,ex6)T; ex=x−x¯, x¯—the mean(x) and Sx—the covariance matrix. Sx=σx120…00σx22…0…………0…0σx62

According to (11), the output density is described by (31) fxc,yc=12πσxcσyc1−ρ2·exp(−12(1−ρ2)(excTSc−1exc−2ρexceycσxcσyc))

ρ—the correlation coefficient, exc=(exc,eyc)T.

After some calculations [23], we find for ρ, 1σxc2 and 1σyc2 (32) ρ=−CAD1σxc2=A−C2D;1σyc2=D−C2A

with (33) A=∑i=161σxi2Ji12;B=∑i=161σxi2Ji1Ji2C=∑i=161σxi2Ji1Ji2;D=∑i=161σxi2Ji22

This is the counterpart to the 2-dim input case (24).

4.3.1. Inverse Solution

An inverse solution cannot be uniquely computed due to the undetermined character of the 6-input–2-output system. Therefore, from the required variances at the intersection position (output), the corresponding variances for the positions and orientations of the robot–human or robot–robot (input) cannot be concluded.

4.3.2. Fuzzy Approach

The steps to the fuzzy approach are very similar to those of the 2-input case:- Define the operation points xi=(x1,x2,x3,x4,x5,x6)iT;

- Compute Ai, Bi and Ci at xi=(x1,x2,x3,x4,x5,x6)iT from (33);

- Formulate the fuzzy rules Ri according to (25) and (26), i=1…n.

The number n of rules is computed as follows:

With l=6—the number of fuzzy terms and k=6—the number of inputs, we obtain n=lk=66—the number of rules.

This number of rules is unacceptably high. To limit n to an adequate number, one has to limit the number of inputs and/or fuzzy terms to look for the most influential variables either in a heuristic or systematic way [24]. This however is not the issue to be discussed in this paper.

5. Sigma-Point Transformation

In the following, the estimation/identification of the standard deviations of possible intersection coordinates of trajectories for both the robot–robot and human–robot combinations by means of the sigma-point technique is discussed. The following method is based on the unscented Kalman filter technique where the intersections cannot be directly measured but predicted/computed only. Nevertheless, it is possible to compute the variance of the predicted events, such as possible collisions or planned rendezvous situations, by a direct propagation of statistical parameters—the sigma points—through the nonlinear geometrical relation, which is a result of the crossing of two trajectories. Let x=(x1,x2)T—the input vector and xc=(xc1,xc2)T—the output vector where for the special case (x1,x2)T=(ϕR,ϕH)T and (xc1,xc2)T=(xc,yc)T. The nonlinear relation between x and xc is given by (34) (34) xc=F(x)

For the discrete case, we obtain for the state xc (35) xc(k)=F(x(k−1)+w(k−1))

and for the measured output zc(k) (36) zc(k)=h(xc)(k)+v(k))

where w and v are the system noise and measurement noise, respectively. h(xc) is the output nonlinearity. Furthermore, let there be the following: x¯(k)—the mean at time tk;

P(k)—the covariance matrix;

x0—the initial state with the known mean μ0=E(x0);

P0(k)=E[(x0−μ0)(x0−μ0)T].

5.1. Selection of Sigma Points

Sigma points are the selected parameters of a given error distribution of a random variable. Sigma points lie along the major eigen-axes of the covariance matrix of the random variable. The height of each sigma point (see Figure 7) represents its relative weight Wj used in the following selection procedure.

Let X(k−1) be a set of 2n+1 sigma points where n is the dimension of the state space (in our example, n=2). (37) X(k−1)={(xj(k−1),Wj)|j=0…2n}

Consider the following selection of sigma points (38) x0(k−1)=x¯(k−1)−1<W0<1W0=λn+λ;λ=α2(n+κ)−n

xi(k−1)=x¯(k−1)+(n1−W0P(k−1));i=1…nxi(k−1)=x¯(k−1)−(n1−W0P(k−1));i=(n+1)…2n

(39) Wj=1−W02n

under the following condition (40) ∑j=02nWj=1

α and κ are scaling factors. A usual choice is α=10−2 and κ=0. n1−W0P(k−1) is the row/column of the matrix square root of n1−W0P. The square root of a matrix P is the solution S for P=S·S, which is obtained by Cholesky factorization.

5.2. Model Forecast Step

To go on with the UKF, the following step is devoted to the model forecast. In this way, the sigma points xj(k) are propagated through the nonlinear process model (41) xcf,j(k)=F(xj(k−1))

where the superscript f means “forecast”. From these transformed and forecasted sigma points, the mean and covariance for the forecast value of xc(k) are (42) xcf(k)=∑j=02nWjxcf,j(k)Pf(k)=∑j=02nWj(xcf,j(k)−xcf(k))(xcf,j(k)−xcf(k))T

5.3. Measurement Update Step

In this step, the sigma points are propagated through the nonlinear observation model (43) zcf,j(k)=h(xcj(k−1))

from which we obtain the mean and covariance (innovation covariance) (44) zcf(k−1)=∑j=02nWjzcf,j(k−1)Cov(z˜cf(k−1))=∑j=02nWj(zcf,j(k−1)−zcf(k−1))×(zcf,j(k−1)−zcf(k−1))T+R(k)

and the cross-covariance (45) Cov(x˜cf(k),z˜cf(k−1))=∑j=02nWj(xcf,j(k)−xcf(k))(zcf,j(k−1)−zcf(k−1))T

5.4. Data Assimilation Step

In this step, the forecast information is combined with the new information from the output z(k) from which we obtain, with the Kalman filter, gain K (46) x^c(k)=xcf(k)+K(k)(zc(k)−zcf(k−1))

The gain K is given by (47) K(k)=Cov(x˜cf(k),z˜cf(k−1))·Cov−1(z˜cf(k−1))

and the posterior covariance is updated by (48) P(k)=Pf(k)−K(k)·Cov(z˜cf(k−1))KT(k)

Usually, it is sufficient to compute the mean and variance for the output/state xc of the nonlinear static system F(x). In this case, it is possible to stop further computing at Equation (42), meaning to rather calculate the transformed sigma points xcf,j and develop the specific output means and variances from (41) and (42). In this connection, it is enough to substitute the covariance matrix Q into (38) instead of P. One advantage of the sigma-point approach prior to statistical linearization is the easy scalability to multi-dimensional random variables.

For the intersection problem, there are 2 cases:The 2 inputs, 2 outputs (2 orientation angles and 2 crossing coordinates);

The 6 inputs, 2 outputs (2 orientation angles and 4 position coordinates, and 2 crossing coordinates).

For the statistical linearization (method 1), the step from the 2 inputs–2 outputs case to the (6,2)-case is computationally more costly than that for the sigma-point approach (method 2), (see Equations (20)–(24) versus Equations (37) and (40)–(42)).

5.5. Sigma Points—Fuzzy Solutions

In order to lower the computing effort, the application of the TS fuzzy interpolation may be a solution, which will be shown in the following. Having a look at the two-dimensional problem, we can see a nonlinear propagation of the input sigma points through a nonlinear function F. Let xj be the two-dimensional “input” sigma points (49) xj=(x1j,x2j)T

or for the special case “intersection” (50) xj=(ϕRj,ϕHj)T

The propagation through F leads to the “output” sigma points (51) xcf,j(k)=F(xj(k−1))

or for the special case (52) xcf,j(k)=F(x1j(k−1),x2j(k−1))=F(ϕRj(k−1),ϕHj(k−1))

The special nonlinear function F is described by (see (5)) (53) xc=ARH(ϕR,ϕH)·xRH

where ARH is a nonlinear matrix (6) linearly combined with the position vector xRH=(xR,yR,xH,yH)T.

A fuzzification aims at ARH:(54) Ffuzz(ϕR,ϕH)=ARHfuzz·xRH=∑l1,l2mwl1(ϕR)wl2(ϕH)·ARH(ϕRl1,ϕHl2)·xRH

Applied to the sigma points (ϕRj,ϕHj), we obtain a TS fuzzy model described by the following rules Rl1,l2 (55) Rl1,l2:

IFϕRj=ΦRjl1ANDϕHj=ΦHjl2THENxcf,j=ARH(ϕRl1,j,ϕHl2,j)·xRH

where ΦRjl1,ΦHjl2 are fuzzy terms for ϕRj,ϕHj; the matrices ARH are functions of the predefined variables ϕRj and ϕHj. This set of rules leads to the result (56) xcf,j=Ffuzz(ϕRj,ϕHj)=∑l1,l2mwl1(ϕRj)wl2(ϕHj)·ARH(ϕRl1,j,ϕHl2,j)·xRH

wl1(ϕRj)∈[0,1] and wl2(ϕHj)∈[0,1] are weighting functions with ∑l1wl1=1, ∑l2wl2=1. The advantage of this approach is that the l1×l2 matrices ARHl1,l2,j=ARH(ϕRl1,j,ϕHl2,j) can be computed off-line. Then, the calculation of the mean and covariance matrix is obtained by (57) xcf(k)=∑j=02nWjxcf,j(k)Pf(k)=∑j=02nWjx˜cf,j(k)(x˜cf,j(k))Tx˜cf,j=xcf,j−xcf

From the covariance Pf, the variances σcxx,σcyy,σcxy can be obtained (58) σcxx=E((xcf−x¯cf)2))σcyy=E((ycf−y¯cf)2))σcxy=σcyx=E((xcf−x¯cf)·(ycf−y¯cf))

5.6. Inverse Solution

The inverse solution for the sigma-point approach is much easier to obtain than that for the statistical linearization method. Starting from Equation (34), we build the inverse function (59) x=F−1(xc)

on the condition that F−1 exists. Then, the covariance matrix P is defined in correspondence to the required variances σcxx,σcyy and σcxy. The following steps correspond to Equations (34)–(42). The position vector xRH is assumed to be known. The inversion of F requires a linearization of xRH and a starting point to obtain a stable convergence to the inverse F−1. The result is the mean x and the covariance Q at the input. A reliable inversion is only possible for the 2-input–2-output case.

5.7. Six-Inputs–Two-Outputs

This case works exactly as the 2-input–2-output case along with Equations (34)–(42) due to the fact that the computation of the sigma points (38)–(40) and the propagation through the nonlinearity F automatically include the input and output dimensions.

6. Simulation Results

The following simulations show the results of the uncertainties of the predicted intersections based on statistical linearization and sigma-point transformation. For both methods, identical parameters are employed for comparison reasons (see Figure 2). The position/orientation of the robot and human are given by the following: xR=(xR,yR)T=(2,0)Tm;

xH=(xH,yH)T=(4,10)Tm;

ϕR=1.78 rad = 102°;

ϕH=3.69 rad = 212°.

ϕR and ϕH are corrupted by Gaussian noise with standard deviations (std) of σϕR=σx1=0.02 rad, (=1.1°), and σϕH=σx2=0.02 rad, (=1.1°).

6.1. Statistical Linearization

Table 1 shows a comparison of the non-fuzzy method with the fuzzy approach using sectors of 60°,30°,15°,7.5° of the unit circle for the orientations of the robot and human. The notations in Table 2 are as follows: σxc—std-computed, σxm—std-measured, etc. As expected, we see that higher resolutions lead to a better match between the fuzzy and analytical approach. Furthermore, the match between the measured and calculated values depends on the form of membership functions (MFS). For example, low input standard deviations (0.02 rad) show a better match for Gaussian membership functions, and higher input standard deviations (0.05 rad = 2.9°) require Gaussian bell-shaped membership functions, which comes from different smoothing effects (see columns 4 and 5 in Table 2).

A comparison of the control surfaces and corresponding measurements xcm,ycm (black and red dots) is depicted in Figure 8, Figure 9 and Figure 10. Figure 8 shows the control surface of xc and yc for the non-fuzzy case (4). The control surfaces of the fuzzy approximations (7) for the 30° and 7.5° sectors are shown in Figure 9 and Figure 10. The resolution 30° (Figure 9) shows a very high deviation compared to the non-fuzzy approach (Figure 8), which decreases further down to the resolution 7.5° (Figure 10). This explains the high differences between the measured and computed standard deviations and correlation coefficients, in particular for sector sizes of 30° and higher.

6.2. Sigma-Point Method

Two-inputs–two-outputs:

The simulation of the sigma-point method is based on a Matlab implementation of an unscented Kalman filter by [25]. The first example deals with the 2-inputs–2-outputs case in which only the orientations are taken into account, but the disturbances of the positions of the robot and human are not part of the sigma-point calculation. A comparison between the computed and measured covariance shows a very good match. The same holds for the standard deviations σxc,σyc. A comparison with the statistical linearization shows a good match as well (see Table 2, rows 1 and 2).

A view at the sigma points presents the following results: Figure 11 shows the two-dimensional distribution of the orientation angles (ϕR, ϕH) and the corresponding sigma points s1,…,s5 where s1 denotes the mean value. Figure 12 shows the two-dimensional distribution of the intersection coordinates (xc,yc) with the sigma points S1,…,S5. S1 denotes the mean value and S1,…,S5 are distributed in such a way that the si are transformed into Si, i=1…5. From both figures, an optimal selection of both s1,…,s5 and S1,…,S5 can be observed, which results in a good match of the computed and measured standard deviations σxc.

Six-inputs–two-outputs:

The 6-inputs–2-outputs example shows that the additional consideration of 4 input position coordinates with σxR=0.02 leads to similar results both for the computed and measured covariances and between the sigma-point method and statistical linearization (see P(7,7)=σxc2, P(8,8)=σyc2 and covar(7,7)=σxm2, covar(8,8)=σym2, and σxc2—computed, and σxm2—the measured variation). Table 2 shows the covariance submatrix considering the output positions only.

Computed covariance:(60) P=10−1×0.004−0.000−0.0000.000−0.000−0.000−0.030−0.018−0.0000.0040.000−0.000−0.000−0.0000.003−0.017−0.0000.0000.0040.000−0.000−0.0000.0040.0020.000−0.0000.0000.004−0.000−0.0000.0010.000−0.000−0.000−0.000−0.0000.0040.0000.000−0.002−0.000−0.000−0.000−0.0000.0000.004−0.0010.004−0.0300.0030.0040.0010.000−0.0010.2350.127−0.018−0.0170.0020.000−0.0020.0040.1270.165σxc=0.153,σyc=0.122

Measured covariance: (61) covar=10−1×0.0040.0000.0000.0000.000−0.000−0.028−0.0200.0000.0040.0000.0010.000−0.0000.000−0.0200.0000.0000.004−0.0000.001−0.0010.0030.0010.0000.001−0.0000.004−0.000−0.000−0.000−0.0030.0000.0000.001−0.0000.005−0.000−0.001−0.006−0.000−0.000−0.001−0.000−0.0000.005−0.0000.005−0.0280.0000.003−0.000−0.001−0.0000.2130.131−0.020−0.0200.001−0.003−0.0060.0050.1310.182σxc=0.145,σyc=0.134

Two-inputs–two-outputs, direct and inverse solution

The next example shows the computation of the direct and inverse cases. In the direct case, we obtain again similar values between the computed and measured covariances and, with this, the standard deviations. The results of the inverse solution lead to similar values of the original inputs (orientations x1=ϕR,x2=ϕH) (see Table 2). The simulations of the fuzzy versions showed the same similarities and can therefore be left out here.

Two-inputs–two-outputs, moving robot–human

The next example deals with the robot and human in motion. Figure 13 shows the positions and orientations of the robot and human at selected time steps t1…t5 and the development of the corresponding intersections xc.

Figure 14 shows the corresponding time plot. The time steps t1…t5 are taken at 0.58 s, …,4.58 s with a time distance of 1s, which is 25 time steps of 0.04 s each. The robot and human start at xR=(xR,yR)T=(2,0)Tm

xH=(xH,yH)T=(4,10)Tm

with the velocities

x˙R(k)=−0.21 m/s;

y˙R(1)=+0.24 m/s;

x˙H(k)=−0.26 m/s;

y˙H(1)=−0.24 m/s.

k is the time step.

Figure 14 Time plot, robot and human.

The x components of the velocities x˙R(k) and x˙H(k) stay constant during the whole simulation.

The y components change their velocities with constant factors y˙R(k+1)=KR·y˙R(k)y˙H(k+1)=KH·y˙H(k)

where KR=1.2 and KH=0.9. The orientation angles start with the following: ϕR=1.78 rad;

ϕH=3.69 rad.

They change their values every second according to the direction of motion.

From both plots, one observes an expected decrease in the output standard deviations for a mutual decrease in their distances to the specific intersection and a good match between the computed and measured values xc (see Table 3). With the information about the distance of the robot and the standard deviation from and at the expected intersection, respectively, it becomes possible to plan either an avoidance strategy or mutual cooperation between the robot and human.

7. Summary and Conclusions

The content of this work is the prediction of encounter situations of mobile robots and human agents in shared areas by analyzing planned/intended trajectories in the presence of uncertainties and system and observation noise. In this context, the problem of intersections of trajectories with respect to system uncertainties and Gaussian noise of the position and orientation of the agents involved is discussed. The problem is addressed by two methods: the statistical linearization of distributions and the sigma-point transformation of the distribution parameters. The positions and orientations of the robot and human are corrupted with Gaussian noise represented by the parameters’ mean and standard deviation. The goal is to calculate the mean and standard deviation/variation at the intersection via the nonlinear relation between the positions/orientations of the robot and human, on the one hand, and the position of the intersection of their intended trajectories, on the other hand.

This analysis is realized by the statistical linearization of the nonlinear relation between the statistics of the robot and human (input) and the statistics of the intersection (output). The output results are the mean and standard deviation of the intersection as functions of the input parameters’ mean and standard deviation of the positions and orientations of robot and human. This work is first carried out for two-input–two-output relations (two orientations of the robot–human and two intersection coordinates) and then for six inputs–two outputs (two orientations and four position coordinates of the robot–human and two intersection coordinates). These cases were extended to their fuzzy versions by different Takagi–Sugeno (TS) fuzzy approximations and compared with the non-fuzzy case. Up to a certain resolution, the approximation works as accurately as the original non-fuzzy version. For the two-input–two-output case, an inverse solution is derived, except for the six-input–two-output case because of the undetermined nature of the differential input–output relation.

The sigma-point transformation aims at transforming/propagating distribution parameters—the sigma points—directly through nonlinearities. The transformed sigma points are then converted into the distribution parameters’ mean and covariance matrix. The sigma-point transformation is closely connected to the unscented Kalman filter, which is used in the example of the robot and human in motion. The specialty of the example is a computed virtual system output (“observation”)—the intersection of two intended trajectories—where the corresponding output uncertainty is a sum of the transformed position/orientation noise and the computational uncertainty from the fuzzy approximation. In total, the comparison between the computed and measured covariances shows a very good match and the comparison with the statistical linearization shows good coincidences as well. Both the sigma-point transformation and the differential statistical linearization scales for more than two variables linearly. Their computational complexity is in the same order [13]. However, if the model is nonlinear, then the differential linearization (EKF) serves as the first-order or second-order approximating estimator. If the system is highly nonlinear, the EKF may diverge and the sigma-point approach produces typically better results. In summary, a prediction of the accuracy of human–robot trajectories using the methods presented in this work increases the performance of human–robot collaboration and human safety. In future work, this method can be used for robot–human scenarios in factory workshops and for robots working in complicated environments like rescue operations in cooperation with human operators.

Author Contributions

R.P. developed the methods and implemented the simulation programs. A.J.L. conceived the project and gave advice and support. All authors have read and agreed to the published version of the manuscript.

Institutional Review Board Statement

Not applicable.

Informed Consent Statement

Not applicable.

Data Availability Statement

Data are contained within the article.

Conflicts of Interest

The authors declare that they have no competing interests.

Figure 1 Intersection principle.

Figure 2 Human–robot scenario: geometry.

Figure 3 Membership functions for ΔϕR,ΔϕH=0−360°.

Figure 4 Fuzzy sectors.

Figure 5 Intersection with noisy orientations.

Figure 6 Differential transformation.

Figure 7 Sigma points for a 2-dim Gaussian random variable.

Figure 8 Control surface non-fuzzy, units of ϕR and ϕH in rad.

Figure 9 Control surface fuzzy, 30°, units of ϕR and ϕH in rad.

Figure 10 Control surface fuzzy, 7.5°, units of ϕR and ϕH in rad.

Figure 11 Sigmapoints, input, units of ϕR and ϕH in rad.

Figure 12 Sigmapoints, output.

Figure 13 Moving robot and human.

sensors-24-03303-t001_Table 1 Table 1 Standard deviations and fuzzy and non-fuzzy results.

Input Std	0.02 Gauss, Bell Shaped (GB)	Gauss	0.05 GB	
sector size/°	60°	30°	15°	7.5°	7.5°	7.5°	
non-fuzz σxc	0.143	0.140	0.138	0.125	0.144	0.366	
fuzz σxc	0.220	0.184	0.140	0.126	0.144	0.367	
non-fuzz σxm	0.160	0.144	0.138	0.126	0.142	0.368	
fuzz σxm	0.555	0.224	0.061	0.225	0.164	0.381	
non-fuzz σyc	0.128	0.132	0.123	0.114	0.124	0.303	
fuzz σyc	0.092	0.087	0.120	0.112	0.122	0.299	
non-fuzz σym	0.134	0.120	0.123	0.113	0.129	0.310	
fuzz σym	0.599	0.171	0.034	0.154	0.139	0.325	
non-fuzz ρxyc	0.576	0.541	0.588	0.561	0.623	0.669	
fuzz ρxyc	−0.263	0.272	0.478	0.506	0.592	0.592	
non-fuzz ρxym	0.572	0.459	0.586	0.549	0.660	0.667	
fuzz ρxym	0.380	0.575	0.990	0.711	0.635	0.592	

sensors-24-03303-t002_Table 2 Table 2 Covariances, standard deviations—computed and measured.

Outputs	Covariance, Computed	Covariance, Measured	σxc, Comp/Meas	σyc, Comp/Meas	
2 inputs	P=0.02130.01140.01140.0159	covar=0.02640.01460.01460.0166	0.145/0.144	0.126/0.134	
2 inputs, stat. lin.	-	-	0.144/0.142	0.124/0.129	
6 inputs	P=0.02350.01270.01270.0165	covar=0.02130.01310.01310.0182	0.135/0.145	0.122/0.134	
Direct solution	P=0.02340.01330.01330.0151	covar=0.02640.01460.01460.0166	0.152/0.162	0.128/128	
Inverse solution	P=10−3×0.46660.05220.05220.4744	covar=10−3×0.4841−0.0190−0.01900.396	0.0215/0.0220	0.0217/0.0190	

sensors-24-03303-t003_Table 3 Table 3 Covariances, standard deviations—computed and measured, moving robot–human.

Outputs	Covariance, Computed	Covariance, Measured	σxc, Comp/Meas	σyc, Comp/Meas	
t1	P=0.02200.00170.00170.0163	covar=0.0246−0.0002−0.00020.0202	0.148/0.156	0.127/0.142	
t2	P=0.01980.00230.00230.0138	covar=0.02220.00180.00180.0153	0.140/0.148	0.117/0.123	
t3	P=0.01680.00300.00300.0107	covar=0.01400.00400.00400.0088	0.129/0.118	0.103/0.093	
t4	P=0.01510.00290.00290.0083	covar=0.01270.00140.00140.0073	0.122/0.112	0.091/0.085	
t5	P=0.01250.00230.00230.0061	covar=0.01020.00300.00300.0056	0.112/0.101	0.078/0.074	

Disclaimer/Publisher’s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.
==== Refs
References

1. Khatib O. Real-time obstacle avoidance for manipulators and mobile robots Proceedings of the IEEE International Conference on Robotics and Automation St. Louis, MI, USA 25–28 March 1985 500505
2. Firl J. Probabilistic Maneuver Recognition in Traffic Scenarios Ph.D. Thesis KIT Karlsruhe Institute of Technology Karlsruhe, Germany 2014
3. Luo W. Xing J. Milan A. Zhang X. Liu W. Zhao X. Kim T. Multiple object tracking: A literature review Artif. Intell. 2021 293 103448 10.1016/j.artint.2020.103448
4. Chen J. Wang C. Chou C. Multiple target tracking in occlusion area with interacting object models in urban environments Robot. Auton. Syst. 2018 103 68 82 10.1016/j.robot.2018.02.004
5. Kassner M. Patera W. Bulling A. Pupil: An open source platform for pervasive eye tracking and mobile gaze-based interaction Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing Seattle, DC, USA 13–17 September 2014 1151 1160
6. Bruce J. Wawer J. Vaughan R. Human-robot rendezvous by co-operative trajectory signals Proceedings of the 10th ACM/IEEE International Conference on Human-Robot Interaction Workshop on Human-Robot Teaming Portland, OR, USA 2–5 March 2015 1 2
7. Kunwar F. Benhabib B. Advanced predictive guidance navigation for mobile robots: A novel strategy for rendezvous in dynamic settings Intern. J. Smart Sens. Intell. Syst. 2008 1 858 890 10.21307/ijssis-2017-325
8. Palm R. Lilienthal A. Fuzzy logic and control in human-robot systems: Geometrical and kinematic considerations Proceedings of the WCCI 2018: 2018 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) Rio de Janeiro, Brazil 8–13 July 2018 827 834
9. Palm R. Driankov D. Fuzzy inputs Fuzzy Sets and Systems—Special Issue on Modern Fuzzy Control IEEE Piscataway, NJ, USA 1994 315 335
10. Foulloy L. Galichet S. Fuzzy control with fuzzy inputs IEEE Trans. Fuzzy Syst. 2003 11 437 449 10.1109/TFUZZ.2003.814831
11. Banelli P. Non-linear transformations of gaussians and gaussian-mixtures with implications on estimation and information theory IEEE Trans. Inf. Theory 2013
12. Julier S.J. Uhlmann J.K. Unscented filtering and nonlinear estimation Proc. IEEE 2004 92 401 422 10.1109/JPROC.2003.823141
13. Merwe R.v.d. Wan E. Julier S.J. Sigma-point kalman filters for nonlinear estimation and sensor-fusion: Applications to integrated navigation Proceedings of the AIAA 2004, Guidance, Navigation and Control Conference Portland, OR, USA 28 June–1 July 2004
14. Terejanu G.A. Unscented Kalman Filter Tutorial Department of Computer Science and Engineering University at Buffalo Buffalo, NY, USA 2011
15. Odry Á. Kecskes I. Sarcevic P. Vizvari Z. Toth A. Odry P. A novel fuzzy-adaptive extended kalman filter for real-time attitude estimation of mobile robots Sensors 2020 20 803 10.3390/s20030803 32024177
16. Song Y. Song Y. Li Q. Robust iterated sigma point fastslam algorithm for mobile robot simultaneous localization and mapping Chin. J. Mech. Eng. 2011 24 693 10.3901/CJME.2011.04.693
17. Bittler J. Bhounsule P.A. Hybrid unscented kalman filter: Application to the simplest walker Proceedings of the 3rd Modeling, Estimation and Control Conference MECC Lake Tahoe, NV, USA 2–5 October 2023
18. Alireza S.D. Shahri M. Vision based simultaneous localization and mapping using sigma point kalman filter Proceedings of the 2011 IEEE International Symposium on Robotic and Sensors Environments (ROSE) Montreal, QC, Canada 17–18 September 2011
19. Xue Z. Schwartz H. A comparison of several nonlinear filters for mobile robot pose estimation Proceedings of the 2013 IEEE International Conference on Mechatronics and Automation (ICMA) Kagawa, Japan 4–7 August 2013
20. Lyu Y. Pan Q. Lv J. Unscented transformation-based multi-robot collaborative self-localization and distributed target tracking Appl. Sci. 2019 9 903 10.3390/app9050903
21. Raitoharju M. Piche R. On computational complexity reduction methods for kalman filter extensions IEEE Aerosp. Electron. Syst. Mag. 2019 34 2 19 10.1109/MAES.2019.2927898
22. Palm R. Lilienthal A. Uncertainty and fuzzy modeling in human-robot navigation Proceedings of the 11th Joint International Computer Conference (IJCCI 2019) Vienna, Austria 17–19 September 2019 296 305
23. Palm R. Lilienthal A. Fuzzy geometric approach to collision estimation under gaussian noise in human-robot interaction Proceedings of the Computational Intelligence: 11th International Joint Conference, IJCCI 2019 Vienna, Austria 17–19 September 2019 Springer Cham, Switzerland 191 221
24. Schaefer J. Strimmer K. A shrinkage to large scale covariance matrix estimation and implications for functional genomics Stat. Appl. Genet. Mol. Biol. 2005 4 32 10.2202/1544-6115.1175 16646851
25. Cao Y. Learning the Unscented Kalman Filter 2021 Available online: https://www.mathworks.com/matlabcentral/fileexchange/18217-learning-the-unscented-kalman-filter (accessed on 14 May 2024)
