
==== Front
Sci Rep
Sci Rep
Scientific Reports
2045-2322
Nature Publishing Group UK London

63611
10.1038/s41598-024-63611-w
Article
Estimation of the amount of pear pollen based on flowering stage detection using deep learning
Endo Keita keita_endo@ieee.org

1
Hiraguri Takefumi 1
Kimura Tomotaka 2
Shimizu Hiroyuki 1
Shimada Tomohito 3
Shibasaki Akane 4
Suzuki Chisa 3
Fujinuma Ryota 5
Takemura Yoshihiro 6
1 https://ror.org/05h68bp56 grid.444271.0 0000 0001 2183 810X Nippon Institute of Technology, Saitama, 345-8501 Japan
2 https://ror.org/01fxdkm29 grid.255178.c 0000 0001 2185 2753 Faculty of Science and Engineering, Doshisha University, Kyoto, 610-0321 Japan
3 Saitama Agricultural Technology Research Center, Saitama, 346-0037 Japan
4 Saitama Agriculture and Forestry Promotion Center, Saitama, 330-0074 Japan
5 DKK Co., Ltd., Tokyo, 100-0005 Japan
6 https://ror.org/024yc3q36 grid.265107.7 0000 0001 0663 5064 Faculty of Agriculture, Tottori University, Tottori, 680-8550 Japan
7 6 2024
7 6 2024
2024
14 131636 2 2024
30 5 2024
© The Author(s) 2024
https://creativecommons.org/licenses/by/4.0/ Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.
Pear pollination is performed by artificial pollination because the pollination rate through insect pollination is not stable. Pollen must be collected to secure sufficient pollen for artificial pollination. However, recently, collecting sufficient amounts of pollen in Japan has become difficult, resulting in increased imports from overseas. To solve this problem, improving the efficiency of pollen collection and strengthening the domestic supply and demand system is necessary. In this study, we proposed an Artificial Intelligence (AI)-based method to estimate the amount of pear pollen. The proposed method used a deep learning-based object detection algorithm, You Only Look Once (YOLO), to classify and detect flower shapes in five stages, from bud to flowering, and to estimate the pollen amount. In this study, the performance of the proposed method was discussed by analyzing the accuracy and error of classification for multiple flower varieties. Although this study only discussed the performance of estimating the amount of pollen collected, in the future, we aim to establish a technique for estimating the time of maximum pollen collection using the method proposed in this study.

Subject terms

Computer science
Image processing
Machine learning
Agroecology
Bio-Oriented Technology Research Advancement Institution(BRAIN)JPJ011397 issue-copyright-statement© Springer Nature Limited 2024
==== Body
pmcIntroduction

Among fruit trees, pears, except for some pear varieties, are characterized by self-incompatibility and require pollen from other varieties to bear fruit. For pollination, planting several adjacent pear varieties is desirable to create a pollinating environment in which insects (honeybees) can be used as vectors. However, the flowering period of pears is from late March to early April, and insect activity often decreases when temperatures are low and rainfall continues during this period, resulting in unstable pollination and fruit set. Therefore, growers use artificial pollination as a reliable method of stabilizing fruit sets1–3. Artificial pollination requires pollen collection and preparation by growers. Pollen collection requires long hours of manual labor because pollen is collected from flowering pear branches at high elevations using stepladders. As a result, the percentage of imported pollen has recently increased. However, the high cost of purchasing imported pollen and the inability to secure sufficient amounts can significantly reduce production4,5. To address these problems, improving the efficiency of pollen collection and strengthening the systems and mechanisms of domestic supply and demand is essential.

Smart agricultural methods incorporating Artificial Intelligence (AI) and other information technologies are being actively promoted in Japan by the government, academia, and the private sector to reduce the labor required to support farming operations, grow high-quality crops, and increase production6. Smart agriculture is also beginning to be defined as a new technology that extends information and communication field technologies such as the Internet of Agro-Things (IoAT) and Agro-Cyber Physical Systems (A-CPS) to agriculture7–9. For example, AI-based optimal irrigation control technology has been proposed and tested for the cultivation of tomatoes with high sugar content10–12. Another example of a practical application is hydroponic cultivation used in plant factories, which is useful for cultivation conditions that can be largely artificially controlled, such as optimizing light intensity using LED artificial lighting13–15. In addition, studies are being conducted on robots that assist in the cultivation of crops in place of humans to save labor. Applications of robot-assisted cultivation technology, such as the automation of pesticide applications for pest control16–18 and crop harvesting19–21. However, robots will be required to make decisions and perform analyses instead of human operators. Recently, AI-based image analysis has attracted considerable attention, and various image analysis technologies have been used22–24.

In this study, we proposed an AI pear pollen amount estimation technology using deep learning, a type of AI, to maximize the collection of pear pollen and mechanize the pollen collection process. As part of the technique for estimating when the maximum amount of pollen can be collected, this study described a technique for calculating the amount of pollen that can be collected using deep learning to determine the shape of a pear flower on an image of a blooming branch. We used You Only Look Once (YOLO)25–27 for classifying and detecting the shape of each flower using deep learning. YOLO is an object-detection algorithm based on deep learning that uses neural networks to analyze images. First, an image of a branch with flowers was captured using a camera, and the captured image was resized to simplify analysis using deep learning. Next, small square grid cells were created in the resized image and trained to classify objects using the grid cells. As a previous study, there is a paper28 that estimates the peak flowering period of pear blossoms based on temperature changes. However, there are no studies that estimate pollen amounts or the optimal pollen collection time using AI. In the aforementioned paper28 estimating the peak flowering period of pear blossoms based on temperature changes, accumulation is done based on temperature changes, making real-time corrections impossible. On the other hand, with the method of this study, estimation can be conducted in real-time by capturing images every day while making adjustments. In this study, we report on the development of an AI pear pollen amount estimation technology that estimates the amount of pollen that can be collected based on the number of flowers per flower shape classified by deep learning and the amount of pollen collected per flower calculated by actually collecting pollen from each flower shape. We also report on the evaluation of the estimation accuracy of the developed AI pear pollen amount estimation technology.

Methodology

YOLO was used to identify pear flower shapes and estimate the amount of pollen. Pollen samples were collected from different flower shapes, and the amount of pollen collected per flower for each flower shape was calculated. The number of flowers of each flower shape detected by YOLO was multiplied by the amount of pollen collected per flower for each flower shape and added to estimate the total amount of pollen.

Pollen collection according to flower shape

Flowers were classified into five shapes, from bud to post-bloom as flowering stages, as shown in Fig. 1. The flowering stages were:“immature stage”, “balloon shape stage”, “blooming stage”, and “blooming end stage”, in which the pollen had fallen off after blooming, and “other”, in which the sides and back of the flower were shown and the “blooming stage” and “blooming end stage” were indistinguishable. “Blooming stage” and “blooming end stage” both have flowers in full bloom, but the anthers of the stamens were red in the “blooming stage”, whereas the anthers of the stamens turned black or brown in the“blooming end stage”.

In Table 1, flowers of three pear varieties, Chojuro, Shinko, and Nepal, were collected for each flowering stage in 100 flower × 3 replications, and the pollen amount collected per flower was calculated from the total pollen amount and the number of flowers in each flowering stage. As an example, the standard deviation of Chojuro was 9.428×10-6 for Early, 1.247×10-5 for Best, and 1.247×10-5 for Late for each flowering stage, indicating that the variation was small enough to calculate the pollen amount per flower with 100 flowers × 3 replications. To collect and weigh pollen from flowers, collected flowers were placed in anther-extracting machine, petals were removed, and anthers were sieved to remove only stamens. A high precision anther-extracting machine was then used to remove impurities. Anthers collected by these procedures were placed in an anther opening machine and weighed after anther opening. The amount of pollen collected per flower was 0 mg at the “blooming end stage” because pollen was almost impossible to collect due to pollen bursting. Specifically, the “blooming end stage” was excluded from the estimated pollen amount, although it was included in the five types of classification even if pollen could not be collected. The amount of pollen collected per flower in “other” was calculated variably based on the ratio of the “blooming stage” to the “blooming end stage” in the image taken. The effective pollen amount in Table 1 is the pollen amount that takes into account the viability of pollen per flowering stage by calculating the fruiting rate, which is the probability of successful pollination by artificial pollination using pollen from each collected flowering stage, and multiplying the pollen amount per flower by the fruiting rate. The amount of pollen collected per flower at each stage was the highest in the balloon-shaped flowering stage, although it varied depending on the species. Based on these results, the “immature stage” was called “Early”, the “balloon shape stage” was “Best”, the “blooming stage” was “Late”, the “blooming end stage” was “Too late”, and flowers that could not be distinguished between the “blooming stage” and the “blooming end stage” were “Other”. The AI pollen amount estimation by AI was performed using pollen amount data per flower, as shown in Table 1. However, because the proportion of flowering stages and the number of flowers differed for each flower cluster or branch, we developed an AI that could identify the number of flowers at each flowering stage by training image data obtained randomly from branches during the flowering stage using YOLO.Figure 1 Flowering stages of pear flowers.

Table 1 Amount of pollen collected per flower at each flowering stage of each variety.

Flowering stage	Amount of pollen collected per flower (mg)	Effective pollen amount (mg)	
Chojuro	Shinko	Nepal	Chojuro	Shinko	Nepal	
Early	0.367	0.960	0.902	0.201	0.671	0.428	
Best	0.757	1.347	1.137	0.386	0.871	0.795	
Late	0.387	0.720	1.141	0.257	0.545	0.783	
Too late	0	0	0	0	0	0	

Flowering stage classification method using YOLO

YOLO, an object-detection algorithm based on deep learning, was used as the AI method. The number of images of flowers captured at random was 1271, and the flowering stage was learned by annotating the images. For annotation, flower parts were extracted from the image data of flower clusters and branches, and five types of labels (“Early”, “Best”, “Late” ,“Too late”, and “Other”) were assigned to each flowering stage. The annotated image data were used for training using YOLO.

The flower detection and flowering stage identification algorithm using YOLO are illustrated in Fig. 2. To perform object detection, YOLO identified the flowers that appeared in an image. The detection procedure consisted of inputting an image captured by a camera, detecting objects using AI image analysis, and outputting the detection results. Specifically, the results of where the “Early” object in the image was reflected were output almost in real time. First, the input image was divided into small squares (grid cells). Each of these squares was further populated with rectangular bounding boxes. The area enclosed by the bounding boxes was then identified as a background or object. The degree of discrimination between the background and the object was quantified in the range 0≦confidence≦1. In contrast, each segment divided by a small square was determined by the class to which it belonged. In the example shown in the figure,“Early” is yellow, “Best” is orange, “Late” is pink, “Too late” is red, “Other” is yellowish green, and the rest of the background is gray, for a total of six to classify. Based on these results, a Non-Maximum Suppression (NMS) method was used to extract bounding boxes that were prominently classified into different classes (labels). First, NMS selected the box with the highest confidence level for each class. Subsequently, the Intersection over Union (IoU) of the overlap between the bounding box and other bounding boxes was checked, and bounding boxes that overlapped by more than a certain percentage were eliminated to complete flower detection and shape identification using YOLO.

In this study, 1017 of the 1271 images were used for training and 254 for validation and testing. The image size was 640 × 640 pixels. The pear varieties in the images were mainly Chojuro, Hosui, Shinko, and Matsushima and were used for training. The batch size for training was set to 16, and 400 epochs to obtain sufficient discrimination accuracy. The YOLOv8n model was used as the training model base, and Adam was used as the optimizer. The number of flowers at each flowering stage was determined by inputting test image data into the model trained under these conditions. The amount of pollen per branch or flower cluster was calculated based on these results. Based on the amount of pollen collected per flower obtained in Table 1 and the YOLO detection results, we calculated “the number of flowers detected by YOLO” × “the amount of pollen collected per flower” for each flowering stage and added them together to obtain the estimated pollen amount. To estimate the overall pollen amount from the entire tree, one can take multiple photos and derive the estimated pollen amount from the sum of the detected results.Figure 2 Flower detection and flowering stage identification algorithm using YOLO.

Ethics declarations

The use of plants in this study complied with relevant institutional, national, and international guidelines and legislation.

Results

Evaluation of the YOLOv8 training model

Figure 3 shows various evaluations of the YOLOv8 model trained on the flowering stages of pears. Fig. 3a is a graph of the loss rate for detection boxes (box loss). For example, the detection box is illustrated in Fig. 2 when each flower was detected. Fig. 3b is a graph of the loss rate for detection classes (class loss). These two graphs show that as the training progresses, the slope of val, which is the evaluation when the validation image is detected, becomes gentler, indicating that the training is converging. In addition, the values of train, which was the evaluation when the training image was detected, and val, which was the evaluation when the validation image was detected, were close. Therefore, training was completed normally without overfitting. At 380 epochs, Early Stopping was performed to prevent overfitting, and the training was completed. Figure 3c shows the mAP50 (mean Average Precision)29–31 graph. mAP is an index used to evaluate the accuracy of object detection, such as YOLO. The mAP50 was 0.76 at the 330th epoch; therefore, the training model at the 330th epoch was used to estimate the amount of pollen.Figure 3 Various evaluations of the training model of YOLOv8. (a) Loss rate for detection frame. (b) Loss rate for detection class. (c) mAP50.

Example of detection results and detection accuracy for each flowering stage using YOLOv8

Figure 4 shows an example of the detection results of each flowering stage using YOLOv8. “Early” was detected with a yellow frame, “Best” with an orange frame, “Late” with a pink frame, “Too late” with a red frame, and “Other” with a yellow-green frame. The images of the detection results shown in Fig. 4 show that the labels “Early”, “Best”, “Late”, “Too late”, and “Other” were displayed and accurately classified. Figure 5 shows the detection results when flowering stages were mixed. Table 2 lists the results of the accuracy rate calculations for the image shown in Fig. 5, which includes a mixture of “Late”, “Too late”, and “Other”, a mixture of “Early” and “Best”, and an only “Early”. The accuracy rate was calculated as the ratio of the number of correct flowering stage identifications to the number of flowers detected in the image. The flowering stage classifier developed by YOLO can classify flowers with mixed flowering stages with an accuracy of over 80%. However, under the mixed condition of “Late”, “Too late”, and “Other”, the shape of “Late” and “Too late” were almost the same, and the only difference in classification was the color of the anthers, which may have affected the accuracy of classification. However, if the shapes were evidently different, classification could be performed with high accuracy. Figure 6 shows the detection accuracy of YOLOv8 when classifying the flowering stages for 254 images, which were selected for testing and validation of the training model and classification accuracy out of the 1271 images used to create the training model. The validation and test images include images of multiple fields and varieties, as well as evaluations of different environmental conditions. Figure 6 evaluates the classification accuracy, such as the accuracy rate for each flowering stage, the percentage of misclassified flowering stages, and the detection accuracy, such as the degree to which flowers in each flowering stage are detected. The vertical columns in Fig. 6 show the correct (True) flowering stages, and the horizontal rows show the flowering stages estimated by YOLOv8 (Predicted). The flowers at each flowering stage are shown in the vertical columns; the flowering stage classified by YOLOv8 is shown in the horizontal rows, and the proportion is shown at the intersection of the vertical and horizontal columns. Therefore, the yellow box, where the True and Predicted flowering stages coincide, indicates the accuracy rate for each flowering stage. The accuracy rate for each flowering stage, “Early” and “Late”, were 80% and 86%, respectively, which was a high accuracy rate. In contrast, the accuracy rates for “Best” and “Other” were low at 69% and 54%. For the “Best” column, there was an 18% rate of misclassifying “Best” as “Early”. This suggests that the similarity of the flower shape between “Best” and “Early” may have caused the misclassification, resulting in a lower accuracy rate for “Best”. The background frame indicates the percentage of undetectable flowers not included in the evaluation in Table 2. From the ratio of “Early”, “Too late”, and “Other” backgrounds, the accuracy rate decreased due to a higher proportion of flowers not being detected than to misclassification of the flowering stage. In particular, the decrease in the accuracy rate for “Other” is considered to be due to the aforementioned large percentage of undetected flowers. To solve these problems, the detection accuracy can be improved by increasing the number of training images by extracting image data that are difficult to misclassify or detect. A solution to the problem of improving detection accuracy will be addressed in future work.Figure 4 Example of detection results of each flowering stage using YOLOv8.

Figure 5 YOLOv8 detection results for images with mixed flowering stages. (a) Late, Too late and Other mixed. (b) Early and Best mixed. (c) Early.

Table 2 Accuracy rate for the images in Fig. 5.

Accuracy rate (%)	
Late, Too late and Other mixed	Early and Best mixed	Early	
82.05	89.47	100	

Figure 6 Detection accuracy for each flowering stage.

Example of pollen amount estimation results

Figure 7 shows an image of flowering stages detected by YOLOv8 using the 330th epoch model described above. For example, the flowering stage was detected in an image of a branch of the Chojuro pear variety. “Early” was detected in yellow, “Best” in orange, “Late” in pink, “Too late” in red, and “Other” in yellow-green. The flowering stage was generally correctly detected from the images of the detection result. In addition, the reliability of the output next to the label was generally high, and the flowering stage could be detected.

Table 3 lists the results of the pollen amount estimation for the detection results shown in Fig. 7. The estimated pollen amount was obtained by calculating “the number of flowers detected by YOLOv8” × “the amount of pollen collected per flower” for each flowering stage and adding up the results of the calculations for each stage. The detection results are presented in Fig. 7, and the estimated pollen amount was 18.102 mg. In contrast, the measured amount of pollen collected from flowers on the branch was 55.0 mg. Although it is desirable for the estimated pollen amount to be the same as the actual pollen amount, the comparison showed an error. The causes of these errors are discussed in the following sections.Figure 7 Image of flowering stages detected by YOLOv8.

Table 3 Results of estimating pollen amount for Fig. 7.

Flowering stage	Number of flowers detected by YOLOv8	Amount of pollen collected per flower (mg)	Estimated pollen amount by YOLOv8 (mg)	
Early	13	0.367	4.771	
Best	9	0.757	6.813	
Late	16	0.387	6.192	
Too late	3	0.000	0	
Other	1	Late and Too late ratio to be determined	0.326	
Sum total	42		18.102	

Discussion

The causes of the errors between the estimated and actual pollen amounts can be summarized into the following three categories: #1 Error due to the amount of pollen collected per flower.

The error is because the average amount of pollen collected per flower was not collected from a sufficient number of pear flowers and also due to the misclassification of flowers into each flowering stage by the human eye

#2 Error due to inability to detect flowers hidden behind branches.

﻿Cameras can only take flat images; therefore, if a flower is hidden behind a branch or stem, it will not appear in the image, and YOLOv8 cannot detect it, causing errors.

#3 Error due to YOLOv8’s decision accuracy.

These errors are caused by flowers that could not be detected by YOLOv8 and the misclassification of flowering stages by YOLOv8.

Accuracy of pollen amount estimation

To evaluate the accuracy of pollen estimation, we discuss the causes of the error between the estimated and actual pollen amounts described above.

Considering #1 in the previous section. For the branches depicted in Fig. 7, “the actual number of flowers” × “the amount of pollen collected per flower” was calculated to be 27.65 mg. This value should be the same as the actual pollen amount of 55.0 mg but with an error. Therefore, an error occurred in the amount of pollen collected per flower. Because the amount of pollen collected per flower could not be corrected in this experiment, the error in the estimated pollen amount was calculated using Formula (1), which considers the error in the amount of pollen collected per flower.1 Error in estimated pollen amount(%)=-1-Estimated pollen amount by YOLOv8Actual number of flowers times Pollen collected per flower×100=-1-Number of flowers detected by YOLOv8Actual number of flowers×100

Pollen amounts were estimated by preparing at least 10 images for each of the three varieties (Chojuro, Shinko, and Nepal), with one flowering branch as the subject, and the actual number of flowers was recorded for each. The error in the estimated pollen amount was calculated by substituting the number of flowers detected by YOLOv8 and the actual number of flowers visually observed, as described above, into Formula (1).

The errors in the estimated pollen amounts are listed in Table 4, and #2 in the previous section is discussed. Table 4 shows that the errors in the pollen amount estimates varied from − 18.02% to − 37.70%, depending on the variety. The average error for the three varieties was − 27.89%. The error in the estimated pollen amount was negative, indicating that the pollen amount estimated by YOLOv8 was less than “the actual number of flowers” × “the amount of pollen collected per flower”. Figure 8 shows a graph comparing the estimated pollen amount and “the actual number of flowers” × “the amount of pollen collected per flower” for each branch of each variety. Figure 8 shows that the error in the estimated pollen amount varied from branch to branch. Therefore, the error in the estimated pollen amount was considered to be caused by the fact that flowers hidden behind the branches could not be detected because they were not captured in the image. Figure 9 shows an example of a flower hidden behind a branch or stem. The purple circle in Fig. 9 shows that the branch or stem obstructs the flower and cannot be detected. Therefore, considering the camera’s viewing angle and assuming that the flowers are hidden at approximately 45°–90°, an error of approximately 12.5–25% is considered reasonable. Therefore, the error could be eliminated by multiplying the estimated pollen amount by 1.125–1.25, which is a parameter for flowers hidden behind the flowers. In this case, the error can be reduced to − 2.89 to − 15.39% by considering the flower parameters hidden behind the pollen.

We considered #3 in the previous section as the cause of the remaining error. The judgment accuracy of YOLOv8 was determined by calculating the accuracy rate using Formula (2).2 Accuracy rate(%)=Number of flowers judged correctly by YOLOv8Number of flowers detected by YOLOv8×100

YOLOv8 was used to detect the flowering stage in 35-pear flower images. Table 5 lists the accuracy rate for determining the correct flowering stage using (2). Table 5 shows that the accuracy rate varied from 81.481 to 87.903% depending on the variety. The average result for the five varieties was 83.407%, indicating that the flowering stage was detected with high accuracy. However, as the percentage was not 100%, it was considered that some errors occurred in the estimated pollen amounts owing to the accuracy of YOLOv8’s judgment. Table 6 shows the results of the comparison between the percentage of the actual number of flowers per flowering stage and the percentage of the number of flowers estimated by YOLOv8. The reason why “Other” was not included in the measured data was that the actual flower counts were always classified as either “Late” or “Too late” when sorted by the human eye. Table 6 shows that some flowers could not be detected because the number of flowers detected by YOLOv8 was lower than the actual number. However, by comparing the percentage of each flowering stage in the measured data with the percentage of each flowering stage in the YOLOv8 estimate, the error was small, ranging from − 7.1 to 3.9%. In particular, the error for the “Best” flowering stage was 0.4%, indicating that the detection rate for the flowering stage with the most pollen available was correct. Therefore, although the present estimation cannot accurately estimate the pollen amount, it is possible to estimate the day of maximum pollen amount by following the daily transition of pollen amount because the detection rate of each flowering stage was close to the actual measurement value. Therefore, the AI pear pollen amount estimation technology developed in this study can estimate the best time to collect the maximum amount of pollen from pear branches before collection, which is the ultimate goal of the study.Table 4 Error in pollen amount estimated by YOLOv8.

All varieties	Chojuro	Shinko	Nepal	
− 27.89 (%)	− 27.94 (%)	− 18.02 (%)	− 37.70 (%)	

Figure 8 Comparison of estimated pollen amount and actual number of flowers × amount of pollen collected per flower. (a) Chojuro. (b) Shinko. (c) Nepal. (d) Total of 3 varieties.

Figure 9 Examples of flowers hidden behind branches and stems.

Table 5 Average accuracy rate for YOLOv8.

All varieties	Chojuro	Shinko	Nepal	Matsushima	Yokoyama	
83.407 (%)	83.396 (%)	87.903 (%)	84.314 (%)	81.494 (%)	81.481 (%)	

Table 6 Comparison of flowering stage percentage between actual measured value and estimated value by YOLOv8.

Flowering stage	Actual measured values collected	Estimated values by YOLOv8	Error rate (%)	
Number of flowers	Pollen amount (mg)	Percentage of flowering stages (%)	Number of flowers	Pollen amount (mg)	Percentage of flowering stages (%)	
Early	19	6.973	30.6	13	4.771	31.0	0.4	
Best	13	9.841	21.0	9	6.813	21.4	0.4	
Late	28	10.836	45.2	16	6.192	38.1	−7.1	
Too late	2	0	3.2	3	0	7.1	3.9	
Other				1	0.326	2.4		
Sum total	62	27.650		42	18.102			

Conclusion

In this study, we developed an AI pear pollen amount estimation technology using YOLO to estimate the amount of pollen that can be collected from pear flowers and evaluated its estimation accuracy. We considered three reasons for the error between the pollen amount estimated by YOLOv8 and the actual pollen amount measured: an error in the actual amount of pollen collected per flower, an error owing to the inability to detect flowers hidden behind branches, and an error owing to the accuracy of YOLOv8’s judgment. In the process of evaluating the estimation accuracy, we found that YOLOv8 could estimate the general amount of pollen by considering the error in the actual amount of pollen collected per flower and by parameterizing the flowers hidden behind the branches. Because the percentage of each flowering stage estimated by YOLOv8 was close to the percentage of each flowering stage measured, the accuracy of the AI pear pollen amount estimation technology was high enough to establish the elemental technology for estimating the best time to collect the maximum pollen amount.

In the future, we aim to establish an algorithm that predicts the optimal timing for pollen collection using AI pear pollen amount estimation in combination with trends in temperature change and flowering stages.

Acknowledgements

This research was supported by the Development and Improvement Program of Strategic Smart Agricultural Technology Grant (JPJ011397) from the Project of the Bio-Oriented Technology Research Advancement Institution (BRAIN).

Author contributions

K.E. developed the proposed method and performed the experiments. T.H. conceived the study. K.E. and T.H. wrote the manuscript. T.S., A.S. and C.S. assisted with the pollen amount data collection and experiments. R.F. assisted with image data collection and development of the proposed method. T.K., H.S. and Y.T. supervised the study. All the authors have reviewed the manuscript and approved its submission.

Data availibility

The datasets used and/or analysed during the current study available from the corresponding author on reasonable request.

Competing interests

The authors declare no competing interests.

Publisher's note

Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
==== Refs
References

1. Nam Ki-Woong Moon Byung-Woo Yoon Deok-Hoon Morphological characteristics and germination and fertilization abilities of five pollen varieties for ‘Niitaka’ Pear (Pyrus pyrifolia Nakai) artificial pollination Horticult. Sci. Technol. 2019 37 6 687 695 10.7235/HORT.20190069
2. Sakamoto, D., Hayama, H., Ito,A., Kashimura, Y., Moriguchi, T. & Nakamura, Y. Spray pollination as a labor-saving pollination system in Japanese pear (Pyrus pyrifolia (Burm.f.) Nakai): Development of the suspension medium. Sci. Horticult. 119(3), 280–285. 10.1016/j.scienta.2008.08.009 (2009).
3. Franco-Mora O Tanabe K Tamura F Itai A Effects of putrescine application on fruit set in ‘Housui’ Japanese pear (Pyrus pyrifolia Nakai) Sci. Horticult. 2005 104 3 265 273 10.1016/j.scienta.2004.10.005
4. Lee Hyo-Jeong Jeong Rae-Dong Metatranscriptomic analysis of plant viruses in imported Pear and Kiwifruit pollen Plant Pathol. J. 2022 38 3 220 228 10.5423/PPJ.OA.03.2022.0047 35678055
5. Shibasaki A Shimada T Kondo S Ohara H Ohkawa K Varietal tolerance of pear flower pollen to low-temperatures treatment during pollen development and damage inhibition by coffee extract Hortic. J. 2023 92 2 151 161 10.2503/hortj.QH-030
6. Ministry of Agriculture, Forestry and Fisheries of JAPAN. https://www.maff.go.jp/e/index.html (2021).
7. Mohanty SP Internet-of-agro-things (IoAT) makes smart agriculture IEEE Consum. Electron. Mag. 2021 10 4 4 5 10.1109/MCE.2021.3074775
8. Mitra, A., Vangipuram, Sukrutha L. T., Bapatla, Anand K., Bathalapalli, Venkata K. V. V., Mohanty, S. P., Kougianos, E. & Ray, C. Everything You wanted to Know about Smart Agriculture. arXiv 10.48550/arXiv.2201.04754 (2022) .
9. Udutalapally V Mohanty SP Pallagani V Khandelwal V sCrop: A novel device for sustainable automatic disease prediction, crop selection, and irrigation in internet-of-agro-things for smart agriculture IEEE Sens. J. 2020 21 16 17525 17538 10.1109/JSEN.2020.3032438
10. Kamarudin MH Ismail ZH Saidi NB Deep learning sensor fusion in plant water stress assessment: A comprehensive review MDPI 2021 11 4 1403 10.3390/app11041403
11. Wakamori K Mizuno R Nakanishi G Mineno H Multimodal neural network with clustering-based drop for estimating plant water stress Comput. Electron. Agric. 2020 168 105118 10.1016/j.compag.2019.105118
12. Hemming S Feije de Zwart A Elings A Petropoulou I. Righini Cherry tomato production in intelligent greenhouses-sensors and AI for Control of Climate, irrigation, crop yield, and quality MDPI Sens. 2020 20 22 6430 10.3390/s20226430
13. Srivani, P., Yamuna Devi C. & Manjula, S.H. A Controlled environment agriculture with hydroponics: variants, parameters, methodologies and challenges for smart farming. In 2019 IEEE ICINPRO. 10.1109/ICInPro47689.2019.9092043 (2019).
14. Pinho P Jokinen K Halonen L The influence of the LED light spectrum on the growth and nutrient uptake of hydroponically grown lettuce Light. Res. Technol. 2016 10.1177/1477153516642269
15. Promratrak, L. The effect of using LED lighting in the growth of crops hydroponics. Int. J. Smart Grid Clean Energy. 6(2), 133–140. 10.12720/sgce.6.2.133-140 (2017).
16. Endo, K., Kimura, T., Itoh, N. & Hiraguri, T. Semantic segmentation based field detection using drones. In 2022 IEEE ICCE-TW. 10.1109/ICCE-Taiwan55306.2022.9869088 (2022).
17. Hafeez, A., Husain, M. A., Singh, S. P., Chauhan, A. & Mohd. Tauseef Khan, N. Kumar, A. Chauhan, S.K. Soni.,. Implementation of drone technology for farm monitoring & pesticide spraying: A review. Inf. Process. Agric. 10(2), 192–203. 10.1016/j.inpa.2022.02.002 (2023).
18. Chen Ching-Ju Huang Ya-Yu Li Yuan-Shuo Chen Ying-Cheng Identification of fruit tree pests with deep learning on embedded drone to achieve accurate pesticide spraying IEEE Access 2021 9 21986 21997 10.1109/ACCESS.2021.3056082
19. Onishi Y An automated fruit harvesting robot by using deep learning ROBOMECH J. 2019 10.1186/s40648-019-0141-2
20. Zhang K Lammers K Chu P Li Z Lu R System design and control of an apple harvesting robot Mechatronics 2021 79 102644 10.1016/j.mechatronics.2021.102644
21. Jun J Kim J Seol J Kim J Il Son H Towards an efficient tomato harvesting robot: 3D perception, manipulation, and end-effector IEEE Access 2021 9 17631 17640 10.1109/ACCESS.2021.3052240
22. Hiraguri T Kimura T Endo K Ohya T Takanashi T Shimizu H Shape classification technology of pollinated tomato flowers for robotic implementation Sci. Rep. 2023 13 2159 10.1038/s41598-023-27971-z 36750598
23. Fukuyama E Kimura T Itoh N Hiraguri T Study of flower image classification using deep learning to support agricultural pollination IEEE ICCE-TW 2021 2021 1 2 10.1109/ICCE-TW52618.2021.9603106
24. Sinha BB Dhanalakshmi R Recent advancements and challenges of Internet of Things in smart agriculture: A survey Future Gener. Comput. Syst. 2022 126 169 184 10.1016/j.future.2021.08.006
25. Redmon, J., Farhadi, A. YOLOv3: An incremental improvement (2018). arXiv 10.48550/arXiv.1804.02767 .
26. Redmon J Farhadi A YOLO9000: Better, faster, stronger IEEE CVPR 2017 2017 6517 6525 10.1109/CVPR.2017.690
27. Redmon J Divvala S Girshick R Farhadi A You only look once: Unified, real-time object detection IEEE CVPR 2016 2016 779 788 10.1109/CVPR.2016.91
28. Sugiura T Honjo H A dynamic model for predicting the flowering date developed using an endodormancy break model and a flower bud development model in Japanese pear J. Agric. Meteorol. 1997 52 5 897 900 10.2480/agrmet.52.897
29. Everingham M Gool LV Christopher KI Williams J Winn A. Zisserman The PASCAL visual object classes (VOC) challenge Int. J. Comput. Vis. 2010 88 303 338 10.1007/s11263-009-0275-4
30. Casas GG Automatic detection and counting of stacked eucalypt timber using the YOLOv8 model MDPI For. 2023 14 12 2369 10.3390/f14122369
31. Zabulis, L., Augustauskas, R., LeleÅ¡ius,D. & Lipnickas, A. YOLO-based detection of drilled blind holes in laminated panels with template similarity assessment. In 2023 IEEE 12th International Conference on IDAACS. 10.1109/IDAACS58523.2023.10348673 (2023).
